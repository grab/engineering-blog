<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Building a Spark observability product with StarRocks: Real-time and historical performance analysis</title>
    <meta name="description" content="Discover how Grab revolutionised its Spark observability with StarRocks! We transformed our monitoring capabilities by moving from a fragmented system to a unified, high-performance platform. Learn about our journey from the initial Iris tool to a robust solution that tackles limitations with real-time and historical data analysis, all powered by StarRocks. Explore the architecture, data model, and advanced analytics that enable us to provide deeper insights and recommendations for optimising Spark jobs at Grab.">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Open Graph -->
    <meta property="og:url" content="https://engineering.grab.com/building-a-spark-observability">
    <meta property="og:title" content="Building a Spark observability product with StarRocks: Real-time and historical performance analysis">
    <meta property="og:description" content="Discover how Grab revolutionised its Spark observability with StarRocks! We transformed our monitoring capabilities by moving from a fragmented system to a unified, high-performance platform. Learn about our journey from the initial Iris tool to a robust solution that tackles limitations with real-time and historical data analysis, all powered by StarRocks. Explore the architecture, data model, and advanced analytics that enable us to provide deeper insights and recommendations for optimising Spark jobs at Grab.">
    <meta property="og:site_name" content="Grab Tech">
    <meta property="og:type" content="article">
    <meta property="og:image" content="https://engineering.grab.com/img/spark-observability-image/cover.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">

    <!-- Favicons -->
    <link rel="icon" href="/favicon.ico">
    <link rel="apple-touch-icon" href="/apple-touch-icon.png">

    <!-- CSS -->
    <link href="//fonts.googleapis.com/css?family=Droid+Serif:400,400i,700,700i" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap-theme.min.css">
    <script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="https://engineering.grab.com/building-a-spark-observability">

    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS for Official Grab Tech Blog" href="/feed.xml">
    <!-- OneTrust Cookies Consent Notice start for grab.com -->
    <script type="text/javascript" src="https://cdn-apac.onetrust.com/consent/a3be3527-7455-48e0-ace6-557ddbd506d5/OtAutoBlock.js" ></script>
    <script src="https://cdn-apac.onetrust.com/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="a3be3527-7455-48e0-ace6-557ddbd506d5" ></script>
    <script type="text/javascript">
    function OptanonWrapper() { }
    </script>
    <!-- OneTrust Cookies Consent Notice end for grab.com -->
  </head>

  <body>
    <header class="site-header">
  <div class="wrapper-navbar">
    <div class="site-title-wrapper">
      <div class="row site-title-wrapper-inner">
        <div class="col-xs-1 visible-xs hamburger-nav" id="mobile-menu-btn">
          <div class="menu-btn"></div>
        </div>
        <div class="col-sm-3 col-xs-3">
          <div class="site-title-container">
            <a class="site-title" href="/"></a>
            <span class="site-subtitle">&nbsp;Tech Blog</span>
          </div>
        </div>
        <div class="col-sm-9 col-xs-8 text-right">
          <ul class="nav-category hidden-xs">
            
              
              <li>
                <a href="/categories/engineering/">Engineering</a>
              </li>
            
              
              <li>
                <a href="/categories/data-science/">Data Science</a>
              </li>
            
              
              <li>
                <a href="/categories/design/">Design</a>
              </li>
            
              
              <li>
                <a href="/categories/product/">Product</a>
              </li>
            
              
              <li>
                <a href="/categories/security/">Security</a>
              </li>
            
          </ul>
          <div class="site-search text-right">
            <form action="/search.html" role="search" class="search-form">
  <div class="search-icon"> </div>
  <input type="search" name="q" class="search-text" placeholder="Search...">
  <button class="search-submit"><i class="fa fa-chevron-right"></i></button>
</form>
    

          </div>
        </div>
      </div>
      <!--  Only visible on mobile view -->
      <div class="mobile-menu-container">
        <ul class="mobile-menu">
          
            
            <li>
              <a href="/categories/engineering/">Engineering</a>
            </li>
          
            
            <li>
              <a href="/categories/data-science/">Data Science</a>
            </li>
          
            
            <li>
              <a href="/categories/design/">Design</a>
            </li>
          
            
            <li>
              <a href="/categories/product/">Product</a>
            </li>
          
            
            <li>
              <a href="/categories/security/">Security</a>
            </li>
          
        </ul>
      </div>
    </div>
  </div>
</header>
<script src="/js/main.js"></script>

    <div class="page-content">
      
<div class="wrapper">
  <div class="post">
    <header class="post-header">
      <img src="/img/spark-observability-image/cover.png" class="post-cover-photo" alt="Building a Spark observability product with StarRocks: Real-time and historical performance analysis cover photo">
      
        
          <a class="post-category" href="/categories/engineering/">Engineering </a>
      
        
          &middot;
        
          <a class="post-category" href="/categories/data-analytics/">Data Analytics </a>
      

      <h1 class="post-title">Building a Spark observability product with StarRocks: Real-time and historical performance analysis</h1>
      
      <div class="post-meta">
        <div class="row">
          <div class="col-xs-12">
            <div class="post-author-thumbnail-container">
              
                
                
                  <img class="post-author-thumbnail-large img-circle" src="/img/authors/huong-vuong.png">
                
              
                
                
                  <img class="post-author-thumbnail-large img-circle" src="/img/authors/hainam-cao.jpg">
                
              
            </div>

            <div class="post-meta-text-container">
              <span class="post-author-large">
                
                  
                  
                    
                    <a href="/authors#huong-vuong">Huong Vuong</a>
                  
                
                  
                  
                    
                      &middot;
                    
                    <a href="/authors#hainam-cao">Hai Nam Cao</a>
                  
                
              </span>
              <span class="post-date-large">6 Mar 2025 | 25 min read</span>
            </div>
          </div>
        </div>
      </div>

    </header>
    <div class="wrapper-content">
      <article class="post-content">
        <h1 id="introduction">Introduction</h1>

<p>At Grab, we’ve been working to perfect our Spark observability tools. Our initial solution, Iris, was developed to provide a custom, in-depth observability tool for Spark jobs. As described in our previous <a href="https://engineering.grab.com/iris">blog post</a>, Iris collects and analyses metrics and metadata at the job level, providing insights into resource usage, performance, and query patterns across our Spark clusters.</p>

<p>Iris addresses a critical gap in Spark observability by providing real-time performance metrics at the Spark application level. Unlike traditional monitoring tools that typically provide metrics only at the EC2 instance level, Iris dives deeper into the Spark ecosystem. It bridges the observability gap by making Spark metrics accessible through a tabular dataset, enabling real-time monitoring and historical analysis. This approach eliminates the need to parse complex Spark event log JSON files, which users are often unable to access when they need immediate insights. Iris empowers users with on-demand access to comprehensive Spark performance data, facilitating quicker decision-making and more efficient resource management.</p>

<p>Iris served us well, offering basic dashboards and charts that helped our teams understand trends, discover issues, and debug their Spark jobs. However, as our needs evolved and usage grew, we began to encounter limitations:</p>

<ol>
  <li>
    <p><strong>Fragmented user experience and access control</strong>: Observability data is split between Grafana (real-time) and Superset (historical), forcing users to switch platforms for a complete view. The complex Grafana dashboards, while powerful, were challenging for non-technical users. The lack of granular permissions hindered wider adoption. We needed a unified, user-friendly interface with role-based access to serve all Grabbers effectively.</p>
  </li>
  <li>
    <p><strong>Operational overhead:</strong> Our data pipeline for offline analytics includes multiple hops and complex transformations.</p>
  </li>
  <li>
    <p><strong>Data management:</strong> We faced challenges managing real-time data in InfluxDB alongside offline data in our data lake, particularly with string-type metadata.</p>
  </li>
</ol>

<p>These challenges and the need for a centralised, user-friendly web application prompted us to seek a more robust solution. Enter StarRocks – a modern analytical database that addresses many of our pain points:</p>

<table class="table" border="1">
  <thead>
    <tr>
      <th>Pain points with InfluxDB</th>
      <th>StarRocks solution</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Limited SQL compatibility: Requires use of Flux query language instead of full SQL</td>
      <td>Full MySQL-compatible SQL support, enabling seamless integration with existing tools and skills</td>
    </tr>
    <tr>
      <td>Complex data ingestion pipeline: Requires external agents like Telegraf to consume Kafka and insert into InfluxDB</td>
      <td>Direct Kafka ingestion, eliminating the need for intermediate agents and simplifying the data pipeline</td>
    </tr>
    <tr>
      <td>Limited pre-aggregation capabilities: Aggregation is limited to time windows and indexed columns, not string columns</td>
      <td>Flexible materialised views supporting complex aggregations on any column type, improving query performance</td>
    </tr>
    <tr>
      <td>Poor support for metadata and joins: Designed primarily for numerical time series data, with slow performance on string data and joins</td>
      <td>Efficient handling of both time-series and string-type metadata in a single system, with optimised join performance</td>
    </tr>
    <tr>
      <td>Difficult integration with data lake: There is no official way to backup or stream data directly to the datalake, requiring separate pipelines</td>
      <td>Native S3 integration for easy backup and direct data lake accessibility, eliminating the need for separate ingestion pipelines</td>
    </tr>
    <tr>
      <td>Performance issues with high cardinality data: Indexing unique identifiers (like app\_id) causes huge indexes and slow queries</td>
      <td>Optimised for high cardinality data, allowing efficient querying on unique identifiers without performance degradation</td>
    </tr>
  </tbody>
</table>

<p>In this blog post, we will dive into leveraging StarRocks to build the next generation of the Spark observability platform. We will explore the architecture, data model, and key features that are helping us overcome previous limitations and provide more value to Spark users at Grab.</p>

<h1 id="system-architecture-overview">System architecture overview</h1>

<p>In the journey to enhance user experience, we’ve made substantial changes to the architecture, moving from the Telegraf/InfluxDB/Grafana (TIG) stack to a more streamlined and powerful setup centered around StarRocks. This new architecture addresses the previous challenges and provides a more unified, flexible, and efficient solution.</p>

<div class="post-image-section"><figure>
  <img src="/img/spark-observability-image/figure-1-new-iris-architecture-with-starrocks-integration.png" alt="" style="width:80%" /><figcaption align="middle">Figure 1. New Iris architecture with StarRocks integration</figcaption>
  </figure>
</div>

<p>Key components of the new architecture:</p>

<ol>
  <li><strong>StarRocks database</strong>
    <ul>
      <li>Replaces InfluxDB for both real-time and historical data storage</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Supports complex queries on metrics and metadata tables</li>
</ul>

<ol>
  <li><strong>Direct Kafka ingestion</strong>
    <ul>
      <li>StarRocks ingests data directly from Kafka, eliminating Telegraf</li>
    </ul>
  </li>
  <li><strong>Custom web application (Iris UI)</strong>
    <ul>
      <li>Replaces Grafana dashboards</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Centralised, flexible interface with custom API</li>
</ul>

<ol>
  <li><strong>Superset integration</strong>
    <ul>
      <li>Maintained and now connected directly to StarRocks</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Provides real-time data access, consistent with the custom web app</li>
</ul>

<ol>
  <li><strong>Simplified offline data process</strong>
    <ul>
      <li>Scheduled backups from StarRocks to S3 directly</li>
    </ul>
  </li>
</ol>

<ul>
  <li>Replaces previous complex data lake pipelines</li>
</ul>

<p>Key improvements:</p>

<ol>
  <li>
    <p><strong>Unified data store:</strong> Single source for real-time and historical data</p>
  </li>
  <li>
    <p><strong>Streamlined data flow:</strong> A simplified pipeline reduces latency and failure points</p>
  </li>
  <li>
    <p><strong>Flexible visualisation:</strong> Custom web app with intuitive, role-specific interfaces</p>
  </li>
  <li>
    <p><strong>Consistent real-time access:</strong> Across both custom app and Superset</p>
  </li>
  <li>
    <p><strong>Simplified backup and data lake integration:</strong> Direct S3 backups</p>
  </li>
</ol>

<h1 id="data-model-and-ingestion">Data model and ingestion</h1>

<p>The Iris observability system is designed to monitor both job executions and ad-hoc cluster usage, encompassing what we call “cluster observation”. This model accounts for two scenarios:</p>

<ul>
  <li>
    <p><strong>Adhoc use:</strong> Pre-created clusters shared among team users</p>
  </li>
  <li>
    <p><strong>Job execution:</strong> New clusters are created for each job submission</p>
  </li>
</ul>

<h2 id="key-design-points">Key design points</h2>

<p>For each cluster, we capture both metadata and metrics:</p>

<table class="table" border="1">
  <thead>
    <tr>
      <th>Key point </th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td> <b>Linkage</b></td>
      <td>We use <b>worker\_uuid</b> to link metadata with worker metrics <b>app_id</b> to link metadata with Spark event metrics.</td>
    </tr>
    <tr>
      <td><b>Granularity</b></td>
      <td>Worker metrics are captured every 5 seconds, linked by worker_uuid. Spark events are captured as they occur, linked by app_id. Metadata can be captured multiple times.</td>
    </tr>
    <tr>
      <td><b>Flexibility</b></td>
      <td>This schema allows for queries at various levels: Individual worker level, job level, cluster level.</td>
    </tr>
    <tr>
      <td><b>Historical analysis</b></td>
      <td>The design enables insights from historical runs, such as: Auto-scaling behaviour, maximum worker count per job, maximum or average memory usage over time.</td>
    </tr>
  </tbody>
</table>

<h2 id="schemas">Schemas</h2>

<p>Let’s break down our table schemas:</p>

<h3 id="cluster-metadata">Cluster metadata</h3>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">CREATE</span> <span class="n">TABLE</span> <span class="err">`</span><span class="n">cluster_worker_metadata_raw</span><span class="err">`</span> <span class="p">(</span>
        <span class="err">`</span><span class="n">report_date</span><span class="err">`</span> <span class="n">date</span>  <span class="n">NOT</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Report date"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">platform</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="n">NOT</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Platform"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">worker_uuid</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Worker UUID (Iris UUID)"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">worker_role</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Worker role"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">epoch_ms</span><span class="err">`</span> <span class="n">bigint</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Event Time"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">cluster_id</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Cluster ID"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">job_id</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"User Job ID"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">run_id</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"User Job Run ID"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">job_owner</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"User Job Owner"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">app_id</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Spark Application ID"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">spark_ui_url</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Spark UI URL"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">driver_log_location</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">256</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Spark Driver Log Location"</span><span class="p">,</span>
        <span class="o">--</span> <span class="n">other</span> <span class="n">relevant</span> <span class="n">metadata</span> <span class="n">fields</span>
    <span class="p">)</span>
    <span class="n">ENGINE</span><span class="o">=</span><span class="n">OLAP</span>
    <span class="n">DUPLICATE</span> <span class="nf">KEY</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">worker_uuid</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">worker_role</span><span class="err">`</span><span class="p">)</span>
    <span class="n">PARTITION</span> <span class="n">BY</span> <span class="n">RANGE</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">)()</span>
    <span class="n">DISTRIBUTED</span> <span class="n">BY</span> <span class="n">HASH</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">)</span>
    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"replication_num"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
    <span class="p">);</span>
</code></pre></div></div>

<h3 id="cluster-worker-metrics">Cluster worker metrics</h3>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">CREATE</span> <span class="n">TABLE</span> <span class="err">`</span><span class="n">cluster_worker_metrics_raw</span><span class="err">`</span> <span class="p">(</span>
        <span class="err">`</span><span class="n">report_date</span><span class="err">`</span> <span class="n">date</span> <span class="n">NOT</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Report date"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">platform</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="n">NOT</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Platform"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">worker_uuid</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Worker UUID"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">worker_role</span><span class="err">`</span> <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Worker Role"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">epoch_ms</span><span class="err">`</span> <span class="n">bigint</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"EpochMillis"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">cpus</span><span class="err">`</span> <span class="n">bigint</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Worker CPU Cores"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">memory</span><span class="err">`</span> <span class="n">bigint</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Worker Memory"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">bytes_heap_used</span><span class="err">`</span> <span class="kt">double</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Byte Heap Used"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">bytes_non_heap_used</span><span class="err">`</span> <span class="kt">double</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Byte Non Heap Used"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">gc_collection_time</span><span class="err">`</span> <span class="kt">double</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"GC Collection Time"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">cpu_time</span><span class="err">`</span> <span class="kt">double</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"CPU Time"</span><span class="p">,</span>
        <span class="o">--</span> <span class="n">other</span> <span class="n">relevant</span> <span class="n">metrics</span> <span class="n">fields</span>
    <span class="p">)</span>
    <span class="n">ENGINE</span><span class="o">=</span><span class="n">OLAP</span>
    <span class="n">DUPLICATE</span> <span class="nf">KEY</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">worker_uuid</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">worker_role</span><span class="err">`</span><span class="p">)</span>
    <span class="n">PARTITION</span> <span class="n">BY</span> <span class="n">RANGE</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">)()</span>
    <span class="n">DISTRIBUTED</span> <span class="n">BY</span> <span class="n">HASH</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">)</span>
    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"replication_num"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
    <span class="p">);</span>
</code></pre></div></div>

<h3 id="cluster-spark-metrics">Cluster spark metrics</h3>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">CREATE</span> <span class="n">TABLE</span> <span class="err">`</span><span class="n">cluster_spark_metrics_raw</span><span class="err">`</span>
    <span class="p">(</span>
        <span class="err">`</span><span class="n">report_date</span><span class="err">`</span>                 <span class="n">date</span>           <span class="n">NOT</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Report date"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">platform</span><span class="err">`</span>                    <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>   <span class="n">NOT</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Platform"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">app_id</span><span class="err">`</span>                      <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>   <span class="n">NOT</span> <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Spark Application ID"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">app_attempt_id</span><span class="err">`</span>              <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span> <span class="n">DEFAULT</span> <span class="sc">'1'</span> <span class="n">COMMENT</span> <span class="s">"Spark Application ID"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">measure_name</span><span class="err">`</span>                <span class="n">varchar</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>   <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"The spark measure name"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">epoch_ms</span><span class="err">`</span>                    <span class="n">bigint</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>     <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"EpochMillis"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">records_read</span><span class="err">`</span>                <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Records Read"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">records_written</span><span class="err">`</span>             <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Records Written"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">bytes_read</span><span class="err">`</span>                  <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Bytes Read"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">bytes_written</span><span class="err">`</span>               <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Bytes Written"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">memory_bytes_spilled</span><span class="err">`</span>        <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Memory Bytes Spilled"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">disk_bytes_spilled</span><span class="err">`</span>          <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Disk Bytes Spilled"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">shuffle_total_bytes_read</span><span class="err">`</span>    <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Shuffle Total Bytes Read"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">shuffle_total_bytes_written</span><span class="err">`</span> <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Shuffle Total Bytes Written"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">total_tasks</span><span class="err">`</span>                 <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Stage Total Tasks"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">shuffle_write_time</span><span class="err">`</span>          <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Shuffle Write Time"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">shuffle_fetch_wait_time</span><span class="err">`</span>     <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Shuffle Fetch Waiting Time"</span><span class="p">,</span>
        <span class="err">`</span><span class="n">result_serialization_time</span><span class="err">`</span>   <span class="kt">double</span>         <span class="nb">NULL</span> <span class="n">COMMENT</span> <span class="s">"Result Serialization Time"</span><span class="p">,</span>
        <span class="o">--</span> <span class="n">other</span> <span class="n">relevant</span> <span class="n">metrics</span> <span class="n">fields</span>
    <span class="p">)</span>
    <span class="n">ENGINE</span> <span class="o">=</span> <span class="n">OLAP</span>
    <span class="n">DUPLICATE</span> <span class="nf">KEY</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">app_id</span><span class="err">`</span><span class="p">,</span> <span class="err">`</span><span class="n">app_attempt_id</span><span class="err">`</span><span class="p">)</span>
    <span class="n">PARTITION</span> <span class="n">BY</span> <span class="n">RANGE</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">)()</span>
    <span class="n">DISTRIBUTED</span> <span class="n">BY</span> <span class="n">HASH</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">)</span>
    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"replication_num"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
    <span class="p">);</span>
</code></pre></div></div>

<h2 id="data-ingestion-from-kafka-to-starrocks">Data ingestion from Kafka to StarRocks</h2>

<p>We use StarRocks’ routine load feature to ingest data directly from Kafka into our tables. Refer to the StarRocks documentation: <a href="https://docs.starrocks.io/docs/loading/RoutineLoad/">Load data using routine load</a>.</p>

<p>Here is a simple example of creating a routine load job for cluster worker metrics:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">CREATE</span> <span class="n">ROUTINE</span> <span class="n">LOAD</span> <span class="n">iris</span><span class="p">.</span><span class="n">routetine_cluster_worker_metrics_raw</span> <span class="n">ON</span> <span class="n">cluster_worker_metrics_raw</span>
    <span class="nf">COLUMNS</span><span class="p">(</span><span class="n">platform</span><span class="p">,</span> <span class="n">worker_uuid</span><span class="p">,</span> <span class="n">worker_role</span><span class="p">,</span> <span class="n">epoch_ms</span><span class="p">,</span> <span class="n">cpus</span><span class="p">,</span> <span class="err">`</span><span class="n">memory</span><span class="err">`</span><span class="p">,</span> <span class="n">bytes_heap_used</span><span class="p">,</span> <span class="n">bytes_non_heap_used</span><span class="p">,</span> <span class="n">gc_collection_time</span><span class="p">,</span> <span class="n">report_date</span><span class="o">=</span><span class="n">date</span><span class="p">(</span><span class="n">from_unixtime</span><span class="p">(</span><span class="n">epoch_ms</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">)))</span>
    <span class="n">WHERE</span> <span class="n">ISNOTNULL</span><span class="p">(</span><span class="n">platform</span><span class="p">)</span>
    <span class="n">PROPERTIES</span>
    <span class="p">(</span>
        <span class="s">"desired_concurrent_number"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
        <span class="s">"format"</span> <span class="o">=</span> <span class="s">"json"</span><span class="p">,</span>
    <span class="s">"jsonpaths"</span> <span class="o">=</span> <span class="s">"[</span><span class="se">\"</span><span class="s">$.platform</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.workerUuid</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.workerRole</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.epochMillis</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.cpuCores</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.memory</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.heapMemoryTotalUsed</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.nonHeapMemoryTotalUsed</span><span class="se">\"</span><span class="s">,</span><span class="se">\"</span><span class="s">$.gc-collectionTime</span><span class="se">\"</span><span class="s">]"</span>
    <span class="p">)</span>
    <span class="n">FROM</span> <span class="n">KAFKA</span>
    <span class="p">(</span>
        <span class="s">"kafka_broker_list"</span> <span class="o">=</span><span class="s">"broker:9092"</span><span class="p">,</span>
        <span class="s">"kafka_topic"</span> <span class="o">=</span> <span class="s">"&lt;worker metrics topic&gt;"</span><span class="p">,</span>
        <span class="s">"property.kafka_default_offsets"</span> <span class="o">=</span> <span class="s">"OFFSET_END"</span>
    <span class="p">);</span>
</code></pre></div></div>

<p>This configuration sets up continuous data ingestion from the specified Kafka topic into our cluster_worker_metrics table, with JSON parsing.</p>

<p>For monitoring the routine, StarRocks provides built-in tools to monitor the status/error log of routine load jobs. Example query to check load:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">SHOW</span> <span class="n">ROUTINE</span> <span class="n">LOAD</span> <span class="n">WHERE</span> <span class="n">NAME</span> <span class="o">=</span> <span class="s">"iris.routetine_cluster_worker_metrics_raw"</span><span class="p">;</span>
</code></pre></div></div>

<h2 id="handle-both-real-time-and-historical-data-in-the-unified-system">Handle both real-time and historical data in the unified system</h2>

<p>The new Iris system uses StarRocks to efficiently manage both real-time and historical data. We have implemented three key features to achieve this:</p>

<ol>
  <li>
    <p>StarRocks’ <strong>routine load</strong> enables near real-time data ingestion from Kafka. Multiple load tasks concurrently consume messages from different topic partitions, resulting in data appearing in Iris tables within seconds of collection. This quick ingestion keeps our monitoring capabilities current, providing users with up-to-date information about their Spark jobs.</p>
  </li>
  <li>
    <p>For historical analysis, StarRocks serves as a <strong>persistent dataset</strong>, storing metadata and job metrics with a time-to-live of over 30 days. This allows us to perform analysis based on the last 30 days of job runs directly in StarRocks, which is significantly faster than using offline data in our data lake.</p>
  </li>
  <li>
    <p>We’ve also implemented <strong>materialised views</strong> in StarRocks to pre-calculate and aggregate data for each job run. These views combine information from metadata, worker metrics, and Spark metrics, creating ready-to-use summary data. This approach eliminates the need for complex join operations when users access the job run summary screen in the UI, improving response times for both SQL queries and API access.</p>
  </li>
</ol>

<p>This setup offers substantial improvements over our previous InfluxDB-based system. As a time-series database, InfluxDB makes complex queries and joins challenging. It also lacked support for materialised views, making it difficult to create pre-built job-run summaries. Previously, we had to query our data lake using Spark and Presto to view historical runs for a particular job over the last 30 days, which was slower than directly querying in StarRocks.</p>

<p>By combining real-time ingestion, persistent storage, and materialised views, Iris now provides a unified, efficient platform for both immediate monitoring and in-depth historical analysis of Spark jobs.</p>

<h1 id="query-performance-and-optimisation">Query performance and optimisation</h1>

<p>StarRocks has significantly improved our query performance for Spark observability. Here are some key aspects of our optimisation strategy.</p>

<h2 id="materialised-views">Materialised views</h2>

<p>As mentioned, we leverage StarRocks’ materialised views to pre-aggregate job run summaries. This approach significantly reduces query complexity and improves response times for common UI operations. Materialised views combine data from metadata, worker metrics, and Spark metrics tables, thus eliminating the need for complex joins during query execution. This is particularly beneficial for our job-run summary screen, where pre-calculated aggregations can be retrieved instantly, improving both speed and user experience.</p>

<p>Here’s an example</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">CREATE</span> <span class="n">MATERIALIZED</span> <span class="n">VIEW</span> <span class="n">job_runs_001</span>
    <span class="n">PARTITION</span> <span class="n">BY</span> <span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">)</span>
    <span class="n">DISTRIBUTED</span> <span class="n">BY</span> <span class="n">HASH</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">)</span>
    <span class="n">REFRESH</span> <span class="n">ASYNC</span>
    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"auto_refresh_partitions_limit"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
        <span class="s">"partition_ttl"</span> <span class="o">=</span> <span class="s">"33 DAY"</span>
    <span class="p">)</span>
    <span class="n">AS</span>
    <span class="n">select</span> <span class="n">m</span><span class="p">.</span><span class="n">report_date</span>                                                                     
    <span class="n">as</span> <span class="n">report_date</span><span class="p">,</span>
        <span class="n">m</span><span class="p">.</span><span class="n">platform</span><span class="p">,</span>
        <span class="n">m</span><span class="p">.</span><span class="n">job_id</span><span class="p">,</span>
        <span class="n">m</span><span class="p">.</span><span class="n">run_id</span><span class="p">,</span>
        <span class="n">m</span><span class="p">.</span><span class="n">app_id</span><span class="p">,</span>
        <span class="n">m</span><span class="p">.</span><span class="n">app_attempt_id</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">COALESCE</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">cluster_id</span><span class="p">,</span> <span class="n">m</span><span class="p">.</span><span class="n">cluster_name</span><span class="p">))</span>                                 <span class="n">as</span> <span class="n">cluster_id</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">cluster_name</span><span class="p">)</span>                                                         <span class="n">as</span> <span class="n">cluster_name</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">job_name</span><span class="p">)</span>                                                             <span class="n">as</span> <span class="n">job_name</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">job_owner</span><span class="p">)</span>                                                            <span class="n">as</span> <span class="n">job_owner</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">m</span><span class="p">.</span><span class="n">job_client</span><span class="p">)</span>                                                           <span class="n">as</span> <span class="n">job_client</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">CASE</span> <span class="n">WHEN</span> <span class="n">m</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="err">'</span><span class="n">driver</span><span class="err">'</span> <span class="n">THEN</span> <span class="n">m</span><span class="p">.</span><span class="n">spark_ui_url</span> <span class="n">END</span><span class="p">)</span>             <span class="n">as</span> <span class="n">spark_ui_url</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">CASE</span> <span class="n">WHEN</span> <span class="n">m</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="err">'</span><span class="n">driver</span><span class="err">'</span> <span class="n">THEN</span> <span class="n">m</span><span class="p">.</span><span class="n">spark_history_url</span> <span class="n">END</span><span class="p">)</span>        <span class="n">as</span> <span class="n">spark_history_url</span><span class="p">,</span>
        <span class="n">ANY_VALUE</span><span class="p">(</span><span class="n">CASE</span> <span class="n">WHEN</span> <span class="n">m</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="err">'</span><span class="n">driver</span><span class="err">'</span> <span class="n">THEN</span> <span class="n">m</span><span class="p">.</span><span class="n">driver_log_location</span> <span class="n">END</span><span class="p">)</span>      <span class="n">as</span> <span class="n">driver_log_location</span><span class="p">,</span>
        <span class="n">COUNT</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">worker_uuid</span><span class="p">)</span>                                                              <span class="n">as</span> <span class="n">total_instances</span><span class="p">,</span>
        <span class="n">from_unixtime</span><span class="p">(</span><span class="n">MIN</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">start_time</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">,</span> <span class="err">'</span><span class="n">yyyy</span><span class="o">-</span><span class="n">MM</span><span class="o">-</span><span class="n">dd</span> <span class="n">HH</span><span class="o">:</span><span class="n">mm</span><span class="o">:</span><span class="n">ss</span><span class="err">'</span><span class="p">)</span>                    <span class="n">as</span> <span class="n">start_time</span><span class="p">,</span>
        <span class="n">from_unixtime</span><span class="p">(</span><span class="n">MAX</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">end_time</span><span class="p">)</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">,</span> <span class="err">'</span><span class="n">yyyy</span><span class="o">-</span><span class="n">MM</span><span class="o">-</span><span class="n">dd</span> <span class="n">HH</span><span class="o">:</span><span class="n">mm</span><span class="o">:</span><span class="n">ss</span><span class="err">'</span><span class="p">)</span>                      <span class="n">as</span> <span class="n">end_time</span><span class="p">,</span>
        <span class="n">COALESCE</span><span class="p">((((</span><span class="n">MAX</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">end_time</span><span class="p">)</span> <span class="o">-</span> <span class="n">MIN</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">start_time</span><span class="p">))</span> <span class="o">+</span> <span class="mi">120000</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1000</span> <span class="o">*</span> <span class="mi">3600</span><span class="p">)),</span> <span class="mi">0</span><span class="p">)</span>   <span class="n">as</span> <span class="n">job_hour</span><span class="p">,</span>
        <span class="n">SUM</span><span class="p">(</span><span class="n">COALESCE</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">machine_hour</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>                                                  <span class="n">as</span> <span class="n">machine_hour</span><span class="p">,</span>
        <span class="n">SUM</span><span class="p">(</span><span class="n">COALESCE</span><span class="p">(</span><span class="n">d</span><span class="p">.</span><span class="n">cpu_hour</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>                                                      <span class="n">as</span> <span class="n">cpu_hour</span><span class="p">,</span>
        <span class="n">MAX</span><span class="p">(</span><span class="n">COALESCE</span><span class="p">(</span><span class="n">CASE</span> <span class="n">WHEN</span> <span class="n">d</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="err">'</span><span class="n">driver</span><span class="err">'</span> <span class="n">THEN</span> <span class="n">d</span><span class="p">.</span><span class="n">cpu_utilization</span> <span class="n">END</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>   <span class="n">as</span> <span class="n">driver_cpu_utilization</span><span class="p">,</span>
        <span class="n">MAX</span><span class="p">(</span><span class="n">COALESCE</span><span class="p">(</span><span class="n">CASE</span> <span class="n">WHEN</span> <span class="n">d</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="err">'</span><span class="n">driver</span><span class="err">'</span> <span class="n">THEN</span> <span class="n">d</span><span class="p">.</span><span class="n">memory_utilization</span> <span class="n">END</span><span class="p">,</span>
                        <span class="mi">0</span><span class="p">))</span>                                                                  <span class="n">as</span> <span class="n">driver_memory_utilization</span><span class="p">,</span>
        <span class="n">MAX</span><span class="p">(</span><span class="n">COALESCE</span><span class="p">(</span><span class="n">CASE</span> <span class="n">WHEN</span> <span class="n">d</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="err">'</span><span class="n">executor</span><span class="err">'</span> <span class="n">THEN</span> <span class="n">d</span><span class="p">.</span><span class="n">cpu_utilization</span> <span class="n">END</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span> <span class="n">as</span> <span class="n">worker_cpu_utilization</span><span class="p">,</span>
        <span class="n">MAX</span><span class="p">(</span><span class="n">COALESCE</span><span class="p">(</span><span class="n">CASE</span> <span class="n">WHEN</span> <span class="n">d</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="err">'</span><span class="n">executor</span><span class="err">'</span> <span class="n">THEN</span> <span class="n">d</span><span class="p">.</span><span class="n">memory_utilization</span> <span class="n">END</span><span class="p">,</span>
                        <span class="mi">0</span><span class="p">))</span>                                                                  <span class="n">as</span> <span class="n">worker_memory_utilization</span><span class="p">,</span>
        <span class="o">--</span> <span class="n">other</span> <span class="n">relevant</span> <span class="n">metrics</span> <span class="n">fields</span>
    <span class="n">from</span> <span class="n">iris</span><span class="p">.</span><span class="n">cluster_worker_metadata_view_001</span> <span class="n">m</span>
            <span class="n">left</span> <span class="n">join</span> <span class="n">iris</span><span class="p">.</span><span class="n">cluster_worker_metrics_view_006</span> <span class="n">d</span>
                    <span class="n">on</span> <span class="n">d</span><span class="p">.</span><span class="n">report_date</span> <span class="o">&gt;=</span> <span class="n">m</span><span class="p">.</span><span class="n">report_date</span> <span class="n">and</span> <span class="n">d</span><span class="p">.</span><span class="n">platform</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">platform</span> <span class="n">and</span> <span class="n">d</span><span class="p">.</span><span class="n">worker_uuid</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">worker_uuid</span> <span class="n">and</span>
                        <span class="n">d</span><span class="p">.</span><span class="n">worker_role</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="n">worker_role</span>
    <span class="n">where</span> <span class="n">m</span><span class="p">.</span><span class="n">job_id</span> <span class="n">is</span> <span class="n">not</span> <span class="n">null</span>
    <span class="n">group</span> <span class="n">by</span> <span class="n">m</span><span class="p">.</span><span class="n">report_date</span><span class="p">,</span>
            <span class="n">m</span><span class="p">.</span><span class="n">platform</span><span class="p">,</span>
            <span class="n">m</span><span class="p">.</span><span class="n">job_id</span><span class="p">,</span>
            <span class="n">m</span><span class="p">.</span><span class="n">run_id</span><span class="p">,</span>
            <span class="n">m</span><span class="p">.</span><span class="n">app_id</span><span class="p">,</span>
            <span class="n">m</span><span class="p">.</span><span class="n">app_attempt_id</span><span class="p">;</span>
</code></pre></div></div>

<p>StarRocks offers powerful and flexible materialised view capabilities that significantly enhance our query performance and data management in Iris. Here are three key features we leverage:</p>

<h3 id="sync-and-async">SYNC and ASYNC</h3>

<p>StarRocks supports both SYNC and ASYNC materialised views. We primarily use ASYNC views as they allow us to join multiple underlying tables, which is crucial for our job-run summaries. We can configure these views to refresh:</p>

<ul>
  <li>
    <p>Immediately when downstream tables are updated.</p>
  </li>
  <li>
    <p>At set intervals (e.g., every 1 minute). This flexibility allows us to balance data freshness with system performance.</p>
  </li>
</ul>

<p>Example setting:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">REFRESH</span> <span class="n">ASYNC</span> <span class="n">START</span><span class="p">(</span><span class="err">'</span><span class="mi">2022</span><span class="o">-</span><span class="mi">09</span><span class="o">-</span><span class="mo">01</span> <span class="mi">10</span><span class="o">:</span><span class="mo">00</span><span class="o">:</span><span class="mo">00</span><span class="err">'</span><span class="p">)</span> <span class="n">EVERY</span> <span class="p">(</span><span class="n">interval</span> <span class="mi">1</span> <span class="n">day</span><span class="p">)</span>
</code></pre></div></div>

<p>For more details on supported features and settings, refer to the StarRocks documentation: <a href="https://docs.starrocks.io/docs/using_starrocks/async_mv/Materialized_view/">Materialised view</a>.</p>

<h3 id="partition-ttl">Partition TTL</h3>

<p>We utilise the partition Time To Live (TTL) feature for materialised views. This allows us to control the amount of historical data stored in the views, typically setting it to 33 days. This ensures that the views remain performant and do not consume excessive storage while still providing quick access to recent historical data.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"partition_ttl"</span> <span class="o">=</span> <span class="s">"33 DAY"</span>
    <span class="p">)</span>
</code></pre></div></div>

<h3 id="selective-partition-refresh">Selective partition refresh</h3>

<p>StarRocks allows us to refresh only specific partitions of a materialised view instead of the entire dataset. We take advantage of this by configuring our views to refresh only the most recent partitions (e.g., the last few days) where new data is typically added. This approach significantly reduces the computational overhead of keeping our materialised views up-to-date, especially for large historical datasets.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"auto_refresh_partitions_limit"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></div>

<h2 id="partitioning">Partitioning</h2>

<p>Our tables are partitioned by date, allowing for efficient pruning of historical data. This partitioning strategy is crucial for queries that focus on recent job runs or specific time ranges. By quickly eliminating irrelevant partitions, we significantly reduce the amount of data scanned for each query, leading to faster execution times.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">PARTITION</span> <span class="n">BY</span> <span class="n">RANGE</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">)()</span>
    <span class="n">DISTRIBUTED</span> <span class="n">BY</span> <span class="n">HASH</span><span class="p">(</span><span class="err">`</span><span class="n">report_date</span><span class="err">`</span><span class="p">,</span><span class="err">`</span><span class="n">platform</span><span class="err">`</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="dynamic-partitioning">Dynamic partitioning</h2>

<p>We utilise StarRocks’ dynamic partitioning feature to automatically manage our partitions. This ensures that new partitions are created as fresh data arrives and old partitions are dropped when data expires. Dynamic partitioning helps maintain optimal query performance over time without manual intervention, which is especially important for our continuous data ingestion process.</p>

<p>Here’s an example of how we configure dynamic partitioning for a 33-day retention period:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"dynamic_partition.enable"</span> <span class="o">=</span> <span class="s">"true"</span><span class="p">,</span>
        <span class="s">"dynamic_partition.time_unit"</span> <span class="o">=</span> <span class="s">"DAY"</span><span class="p">,</span>
        <span class="s">"dynamic_partition.start"</span> <span class="o">=</span> <span class="s">"-33"</span><span class="p">,</span>
        <span class="s">"dynamic_partition.end"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
        <span class="s">"dynamic_partition.prefix"</span> <span class="o">=</span> <span class="s">"p"</span><span class="p">,</span>
        <span class="s">"dynamic_partition.buckets"</span> <span class="o">=</span> <span class="s">"32"</span><span class="p">,</span>
        <span class="s">"dynamic_partition.history_partition_num"</span> <span class="o">=</span> <span class="s">"30"</span>
    <span class="p">);</span>
</code></pre></div></div>

<p>To verify that dynamic partitioning is working correctly and to monitor the state of your partitions, you can use the following SQL command:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">SHOW</span> <span class="n">PARTITIONS</span> <span class="n">FROM</span> <span class="n">iris</span><span class="p">.</span><span class="n">cluster_worker_metrics_raw</span><span class="p">;</span>
</code></pre></div></div>

<p>This command provides a summary of all partitions for the specified table (in this case, iris.cluster_worker_metrics_raw). The output includes valuable information such as:</p>

<ul>
  <li>
    <p>The total number of partitions</p>
  </li>
  <li>
    <p>The date range covered by each partition</p>
  </li>
  <li>
    <p>Row count per partition</p>
  </li>
  <li>
    <p>Size of each partition</p>
  </li>
</ul>

<p>While dynamic partitioning keeps the most recent 33 days of data readily available in StarRocks for fast querying, we’ve implemented a strategy to retain older data for long-term analysis.</p>

<p>We use a daily cron job to back up data older than 30 days to Amazon S3. This ensures we maintain historical data without impacting the performance of our primary StarRocks cluster.</p>

<p>Here’s an example of the backup query we use:</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">INSERT</span> <span class="n">INTO</span>
        <span class="n">FILES</span><span class="p">(</span>
            <span class="s">"path"</span> <span class="o">=</span> <span class="s">"{s3backUpPath}/{table_name}/"</span><span class="p">,</span>
            <span class="s">"format"</span> <span class="o">=</span> <span class="s">"parquet"</span><span class="p">,</span>
            <span class="s">"compression"</span> <span class="o">=</span> <span class="s">"zstd"</span><span class="p">,</span>
            <span class="s">"partition_by"</span> <span class="o">=</span> <span class="s">"report_date"</span><span class="p">,</span>
            <span class="s">"aws.s3.region"</span> <span class="o">=</span> <span class="s">"ap-southeast-1"</span>
        <span class="p">)</span>
        <span class="n">SELECT</span> <span class="o">*</span> <span class="n">FROM</span> <span class="n">iris</span><span class="p">.{</span><span class="n">table_name</span><span class="p">}</span> <span class="n">WHERE</span> <span class="n">report_date</span> <span class="n">between</span> <span class="err">'</span><span class="p">{</span><span class="n">start_date</span><span class="p">}</span><span class="err">'</span> <span class="n">and</span> <span class="err">'</span><span class="p">{</span><span class="n">end_date</span><span class="p">}</span><span class="err">'</span><span class="p">;</span>
</code></pre></div></div>

<p>After backing up to S3, we map this data to a data lake table, enabling us to query historical data beyond the 33-day window in StarRocks when needed, without affecting the performance of our primary observability system.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">df_snapshot</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">f</span><span class="s">"{s3backUpPath}/{table_name}"</span><span class="p">)</span>

    <span class="cp"># do the transformation if needed here
</span>
    <span class="n">df_snapshot</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">"delta"</span><span class="p">).</span><span class="n">mode</span><span class="p">(</span><span class="s">"overwrite"</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">"partitionOverwriteMode"</span><span class="p">,</span> <span class="s">"dynamic"</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">"mergeSchema"</span><span class="p">,</span> <span class="s">"true"</span><span class="p">).</span><span class="n">partitionBy</span><span class="p">(</span><span class="s">"report_date"</span><span class="p">).</span><span class="n">save</span><span class="p">(</span><span class="n">f</span><span class="s">"{s3SinkPath}/{table_name}"</span><span class="p">)</span>

    <span class="o">%</span><span class="n">sql</span>
    <span class="n">CREATE</span> <span class="n">TABLE</span> <span class="n">IF</span> <span class="n">NOT</span> <span class="n">EXISTS</span> <span class="n">iris</span><span class="p">.{</span><span class="n">table_name</span><span class="p">}</span>
    <span class="n">USING</span> <span class="n">DELTA</span>
    <span class="n">LOCATION</span> <span class="err">'</span><span class="p">{</span><span class="n">s3SinkPath</span><span class="p">}</span><span class="o">/</span><span class="p">{</span><span class="n">table_name</span><span class="p">}</span><span class="err">'</span>
</code></pre></div></div>

<h2 id="data-replication">Data replication</h2>

<p>StarRocks uses data replication across multiple nodes, which is crucial for both fault tolerance and query performance. This strategy allows parallel query execution speeding up data retrieval. It’s particularly beneficial for our front-end queries, where low latency is crucial for user experience. This approach aligns with best practices seen in other distributed database systems like Cassandra, DynamoDB, and MySQL’s master-slave architecture.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">PROPERTIES</span> <span class="p">(</span>
        <span class="s">"replication_num"</span> <span class="o">=</span> <span class="s">"3"</span><span class="p">,</span>
    <span class="p">);</span>
</code></pre></div></div>

<h1 id="unified-web-application">Unified web application</h1>

<p>We’ve developed a comprehensive web application for Iris, consisting of both backend and frontend components. This unified interface offers users a seamless experience for monitoring and analysing Spark jobs.</p>

<h2 id="backend">Backend</h2>

<ul>
  <li>
    <p>Built using Golang, our backend service connects directly to the StarRocks database.</p>
  </li>
  <li>
    <p>It queries data from both raw tables and materialised views, leveraging the optimised data structures we’ve set up in StarRocks.</p>
  </li>
  <li>
    <p>The backend handles authentication and authorisation, ensuring that users have appropriate access to job data.</p>
  </li>
</ul>

<h2 id="frontend">Frontend</h2>

<p>The frontend offers several key screens to show:</p>

<ul>
  <li>
    <p>List of job runs</p>
  </li>
  <li>
    <p>Job status</p>
  </li>
  <li>
    <p>Job metadata</p>
  </li>
  <li>
    <p>Driver log</p>
  </li>
  <li>
    <p>Spark UI</p>
  </li>
  <li>
    <p>Statistics on resource usage and cost</p>
  </li>
</ul>

<p>Here is an example of the job overview screen, which displays key summary information: total number of runs, job owner details, performance trends, and cost analysis charts. This comprehensive view provides users with a quick snapshot of their Spark job’s overall health and resource utilisation.</p>

<div class="post-image-section"><figure>
  <img src="img/spark-observability-image/figure-2-example-of-job-overview screen.png" alt="" style="width:80%" /><figcaption align="middle">Figure 2: Example of job overview screen</figcaption>
  </figure>
</div>

<h1 id="advanced-analytics-and-insights">Advanced analytics and insights</h1>

<p>One of the key features we’ve implemented in Iris is the ability to perform analytics on historical job runs to capture trends. This feature leverages the power of StarRocks and our data model to provide users with valuable insights and recommendations. Here’s how we’ve implemented it:</p>

<h2 id="historical-run-analysis">Historical run analysis</h2>

<p>We’ve created a materialised view that aggregates job run data over the last 30 days. This view likely includes metrics such as count of runs, p95 values for various resource utilisation, etc.</p>

<div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="n">CREATE</span> <span class="n">MATERIALIZED</span> <span class="n">VIEW</span> <span class="n">job_run_summaries_001</span>
    <span class="n">REFRESH</span> <span class="n">ASYNC</span> <span class="n">EVERY</span><span class="p">(</span><span class="n">INTERVAL</span> <span class="mi">1</span> <span class="n">DAY</span><span class="p">)</span>
    <span class="n">AS</span>
    <span class="n">select</span> <span class="n">platform</span><span class="p">,</span>
        <span class="n">job_id</span><span class="p">,</span>
        <span class="n">count</span><span class="p">(</span><span class="n">distinct</span> <span class="n">run_id</span><span class="p">)</span>                                <span class="n">as</span> <span class="n">count_run</span><span class="p">,</span>
        <span class="n">ceil</span><span class="p">(</span><span class="n">percentile_approx</span><span class="p">(</span><span class="n">total_instances</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">))</span>        <span class="n">as</span> <span class="n">p95_total_instances</span><span class="p">,</span>
        <span class="n">ceil</span><span class="p">(</span><span class="n">percentile_approx</span><span class="p">(</span><span class="n">worker_instances</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">))</span>       <span class="n">as</span> <span class="n">p95_worker_instances</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">job_hour</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>                     <span class="n">as</span> <span class="n">p95_job_hour</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">machine_hour</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>                 <span class="n">as</span> <span class="n">p95_machine_hour</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">cpu_hour</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>                     <span class="n">as</span> <span class="n">p95_cpu_hour</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">worker_gc_hour</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>               <span class="n">as</span> <span class="n">p95_worker_gc_hour</span><span class="p">,</span>
        <span class="n">ceil</span><span class="p">(</span><span class="n">percentile_approx</span><span class="p">(</span><span class="n">driver_cpus</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">))</span>            <span class="n">as</span> <span class="n">p95_driver_cpus</span><span class="p">,</span>
        <span class="n">ceil</span><span class="p">(</span><span class="n">percentile_approx</span><span class="p">(</span><span class="n">worker_cpus</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">))</span>            <span class="n">as</span> <span class="n">p95_worker_cpus</span><span class="p">,</span>
        <span class="n">ceil</span><span class="p">(</span><span class="n">percentile_approx</span><span class="p">(</span><span class="n">driver_memory_gb</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">))</span>       <span class="n">as</span> <span class="n">p95_driver_memory_gb</span><span class="p">,</span>
        <span class="n">ceil</span><span class="p">(</span><span class="n">percentile_approx</span><span class="p">(</span><span class="n">worker_memory_gb</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">))</span>       <span class="n">as</span> <span class="n">p95_worker_memory_gb</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">driver_cpu_utilization</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>       <span class="n">as</span> <span class="n">p95_driver_cpu_utilization</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">worker_cpu_utilization</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>       <span class="n">as</span> <span class="n">p95_worker_cpu_utilization</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">driver_memory_utilization</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>    <span class="n">as</span> <span class="n">p95_driver_memory_utilization</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">worker_memory_utilization</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>    <span class="n">as</span> <span class="n">p95_worker_memory_utilization</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">total_gb_read</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>                <span class="n">as</span> <span class="n">p95_gb_read</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">total_gb_written</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>             <span class="n">as</span> <span class="n">p95_gb_written</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">total_memory_gb_spilled</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>      <span class="n">as</span> <span class="n">p95_memory_gb_spilled</span><span class="p">,</span>
        <span class="n">percentile_approx</span><span class="p">(</span><span class="n">disk_spilled_rate</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span>            <span class="n">as</span> <span class="n">p95_disk_spilled_rate</span>
    <span class="n">from</span> <span class="n">iris</span><span class="p">.</span><span class="n">job_runs</span>
    <span class="n">where</span> <span class="n">report_date</span> <span class="o">&gt;=</span> <span class="n">current_date</span> <span class="o">-</span> <span class="n">interval</span> <span class="mi">30</span> <span class="n">day</span>
    <span class="n">group</span> <span class="n">by</span> <span class="n">platform</span><span class="p">,</span> <span class="n">job_id</span><span class="p">;</span>
</code></pre></div></div>

<p>Using this aggregated data, we can identify trends in job performance and resource usage over time, such as increasing run times or spikes in resource consumption.</p>

<h2 id="recommendation-api">Recommendation API</h2>

<p>Based on trend analysis insights, we’ve built a recommendation API that suggests optimizations, such as adjusting resource allocations, identifying potential bottlenecks, or proposing schedule changes to optimise cost and performance.</p>

<h3 id="frontend-integration">Frontend integration</h3>

<p>The recommendations generated by our API are integrated into the Iris front end. Users can view these recommendations directly in the job overview or details screens, offering actionable insights to improve Spark jobs.</p>

<p>Here is an example: in a job with consistently low resource utilisation (less than 25% over time), our system suggests reducing the worker size by half to optimise costs.</p>

<div class="post-image-section"><figure>
  <img src="/img/spark-observability-image/figure-3-example-of-job-with-low-resource-utilisation.png" alt="" style="width:80%" /><figcaption align="middle">Figure 3. Example of job with low resource utilisation.</figcaption>
  </figure>
</div>

<h3 id="slackbot-integration">Slackbot integration</h3>

<p>To make these insights more accessible, we’ve integrated the recommendation system with a SpellVault app (a GenAI platform at Grab). This allows users to interact with the recommendation system directly from Slack, allowing them to stay informed about job performance and potential optimisations without constantly checking the Iris web interface.</p>

<div class="post-image-section"><figure>
  <img src="/img/spark-observability-image/figure-4-example-of-integration-with-spellvault.png" alt="" style="width:80%" /><figcaption align="middle">Figure 4. Example of integration with SpellVault.</figcaption>
  </figure>
</div>

<h1 id="migration-and-adoption">Migration and adoption</h1>

<h2 id="migration-strategy">Migration strategy</h2>

<ul>
  <li>
    <p>Fully migrating real-time CPU/Memory charts from Grafana to the new Iris UI</p>
  </li>
  <li>
    <p>Will deprecate the Grafana dashboard after migration</p>
  </li>
  <li>
    <p>Retaining Superset for platform metrics and specific BI needs</p>
  </li>
</ul>

<h2 id="user-onboarding-and-feedback">User onboarding and feedback</h2>

<p>Iris deployed within the One DE app, centralising access to data engineering tools. The feedback button in the UI allows users to submit comments easily.</p>

<h1 id="lessons-learned-and-future-roadmap">Lessons learned and future roadmap</h1>

<h2 id="lessons-learned">Lessons learned</h2>

<ul>
  <li>
    <p><strong>Unified data store:</strong> Using StarRocks as a single source for both real-time and historical data has significantly improved query performance and streamlined our architecture.</p>
  </li>
  <li>
    <p><strong>Materialised views:</strong> Leveraging StarRocks’ materialised views for pre-aggregations has significantly enhanced query response times, especially for common UI operations.</p>
  </li>
  <li>
    <p><strong>Dynamic partitioning:</strong> Implementing dynamic partitioning has helped in maintaining optimal performance as data volumes grow, automatically managing data retention.</p>
  </li>
  <li>
    <p><strong>Direct Kafka ingestion:</strong> StarRocks’ ability to ingest data directly from Kafka has streamlined our data pipeline, reducing latency and complexity.</p>
  </li>
  <li>
    <p><strong>Flexible data model:</strong> Compared to the previous time-series-focused InfluxDB, the StarRocks relational model enables more complex queries and simplifies metadata handling.</p>
  </li>
</ul>

<h2 id="future-roadmap">Future roadmap</h2>

<ol>
  <li>
    <p><strong>Enhanced recommendations:</strong> Expand the recommendation system to include more in-depth suggestions, such as identifying potential bottlenecks and recommending Spark configurations to add or remove from jobs. These recommendations, aimed at improving runtime and cost performance, will leverage the detailed Spark metrics and event data we’re already collecting.</p>
  </li>
  <li>
    <p><strong>Advanced analytics:</strong> Leverage the comprehensive Spark metrics data to provide deeper insights into job performance and resource utilisation.</p>
  </li>
  <li>
    <p><strong>Integration expansion:</strong> Enhance Iris integration with other internal tools and platforms to increase adoption and ensure a seamless experience across the data engineering ecosystem.</p>
  </li>
  <li>
    <p><strong>Machine learning integration:</strong> Explore the possibility of incorporating machine learning models for predictive analytics on Spark performance.</p>
  </li>
  <li>
    <p><strong>Scalability improvements:</strong> Continue to optimise the system to handle increasing data volumes and user loads as adoption grows.</p>
  </li>
  <li>
    <p><strong>User experience enhancements:</strong> Continuously improve the Iris application’s UI/UX based on user feedback to make it more intuitive and informative.</p>
  </li>
</ol>

<h1 id="conclusion">Conclusion</h1>

<p>The journey of building the Iris web application, powered by StarRocks, has been transformative for our Spark observability capabilities at Grab. This evolution was driven by the need for a user-friendly, centralised platform for Spark monitoring and logging.</p>

<p>By leveraging StarRocks’ capabilities, we’ve created a unified interface that seamlessly handles both real-time and historical data. This has allowed us to consolidate previously fragmented tools like Grafana and Superset into a single, cohesive platform. The ability to capture and analyse job metadata and metrics in one place has been crucial, enabling us to implement effective showback/chargeback mechanisms at the job level.</p>

<p>Looking ahead, we’re excited about the potential for more advanced analytics and machine learning-driven insights. The lessons learned from this project will guide our approach to building robust, scalable, and user-friendly data tools at Grab.</p>

<h1 id="join-us">Join us</h1>

<p>Grab is a leading superapp in Southeast Asia, operating across the deliveries, mobility and digital financial services sectors. Serving over 800 cities in eight Southeast Asian countries, Grab enables millions of people everyday to order food or groceries, send packages, hail a ride or taxi, pay for online purchases or access services such as lending and insurance, all through a single app. Grab was founded in 2012 with the mission to drive Southeast Asia forward by creating economic empowerment for everyone. Grab strives to serve a triple bottom line – we aim to simultaneously deliver financial performance for our shareholders and have a positive social impact, which includes economic empowerment for millions of people in the region, while mitigating our environmental footprint.</p>

<p>Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, <a href="https://grab.careers/">join our team</a> today!</p>

      </article>
      <div>
        
          <div class="post-tags">
  
  
    <a href="/tags#data-engineering" class="label tags-label">Data Engineering</a>
  
    <a href="/tags#generative-ai" class="label tags-label">Generative AI</a>
  
    <a href="/tags#llm" class="label tags-label">LLM</a>
  
    <a href="/tags#real-time-analytics" class="label tags-label">Real-time Analytics</a>
  
    <a href="/tags#spark-observability" class="label tags-label">Spark Observability</a>
  
    <a href="/tags#starrocks" class="label tags-label">StarRocks</a>
  
    <a href="/tags#system-architecture" class="label tags-label">System Architecture</a>
  
</div>

        
        <br>
      </div>
      <div class="sharing-links text-right">
  Share on &nbsp;
  <a href="https://twitter.com/intent/tweet?text=Building a Spark observability product with StarRocks: Real-time and historical performance analysis&url=https://engineering.grab.com/building-a-spark-observability&via=grabengineering&related=grabengineering" class="btn btn-sm btn-share btn-share-twitter" rel="nofollow" target="_new" title="Share on Twitter" onclick="onShareButtonClick(this); return false;"><i class="fa fa-lg fa-twitter"></i>&nbsp; Twitter</a>
  <a href="https://facebook.com/sharer.php?u=https://engineering.grab.com/building-a-spark-observability" class="btn btn-sm btn-share btn-share-facebook" rel="nofollow" target="_new" title="Share on Facebook" onclick="onShareButtonClick(this); return false;"><i class="fa fa-lg fa-facebook"></i>&nbsp; Facebook</a>
  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://engineering.grab.com/building-a-spark-observability&title=Building a Spark observability product with StarRocks: Real-time and historical performance analysis
&summary=Discover how Grab revolutionised its Spark observability with StarRocks! We transformed our monitoring capabilities by moving from a fragmented system to a unified, high-performance platform. Learn about our journey from the initial Iris tool to a robust solution that tackles limitations with real-time and historical data analysis, all powered by StarRocks. Explore the architecture, data model, and advanced analytics that enable us to provide deeper insights and recommendations for optimising Spark jobs at Grab.&source=Grab Tech" class="btn btn-sm btn-share btn-share-linkedin" rel="nofollow" target="_new" title="Share on LinkedIn" onclick="onShareButtonClick(this); return false;"><i class="fa fa-lg fa-linkedin"></i>&nbsp; LinkedIn</a>
</div>
<script>
  function onShareButtonClick(button) {
    var width = 600;
    var height = 600;
    var left = (window.screen.width / 2) - (width / 2);
    var top = (window.screen.height / 2) - (height / 2);
    window.open(button.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=' + height + ',width=' + width + ',top=' + top + ',left=' + left);
    return false;
  }
</script>

      <hr class="section-divider">

      <br/>
      <!-- 
        <div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    this.page.url = 'https://engineering.grab.com/building-a-spark-observability';
    this.page.identifier = '/building-a-spark-observability';
  };
  (function() {
    var d = document, s = d.createElement('script');
    s.src = '//grabengineering.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

       -->

    </div>
  </div>
</div>

    </div>
    <div class="progress-wrap">
    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98" />
    </svg>
    <i class="fa fa-chevron-up btt-btn"></i>
</div>
    <footer class="site-footer">
  <div class="wrapper">
    <div class="row">
      <div class="col-sm-6 col-xs-12">
        <h2 class="footer-heading">Grab Tech</h2>
        <ul class="social-media-list">
  
    <li>
      <a href="https://github.com/grab" target="_blank" rel="nofollow noreferrer">
        <i class="fa fa-github fa-lg"></i>
      </a>
    </li>
  
  
    <li>
      <a href="https://www.linkedin.com/company/grabapp" target="_blank" rel="nofollow noreferrer">
        <i class="fa fa-linkedin fa-lg"></i>
      </a>
    </li>
  
  <li>
    <a href="https://engineering.grab.com/feed.xml" target="_blank">
      <i class="fa fa-rss fa-lg"></i>
    </a>
  </li>
</ul>

        <div>
          <script src="//platform.linkedin.com/in.js" type="text/javascript"> lang: en_US</script>
          <script type="IN/FollowCompany" data-id="5382086" data-counter="right"></script>
        </div>        
        <br>
      </div>
      <div class="col-sm-6 col-xs-12 hiring-section">
        <h2 class="footer-heading">Join Us</h2>
        <p class="text">
          Want to join us in our mission to revolutionize transportation?
        </p>
        <a class="btn" href="https://grab.careers" target="_blank">View open positions</a>

      </div>
    </div>
    
  <!-- Google Tag Manager -->
  <script>
    (function (w, d, s, l, i) {
      w[l] = w[l] || [];
      w[l].push({
        'gtm.start': new Date().getTime(),
        event: 'gtm.js'
      });
      var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s),
        dl = l != 'dataLayer' ? '&l=' + l : '';
      j.async = true;
      j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
      f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-T3CT72T');
  </script>
  <!-- End Google Tag Manager -->

  <!-- Old script 
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'GTM-T3CT72T', 'auto');
    ga('send', 'pageview');
  </script> -->
<!-- End of olf script -->


  </body>
</html>
