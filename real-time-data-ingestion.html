<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Real-time data ingestion in Grab</title>
    <meta name="description" content="When it comes to data ingestion, there are several prevailing issues that come to mind: data inconsistency, integrity and maintenance. Find out how the Caspian team leveraged real-time data ingestion to help address these pain points.">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Open Graph -->
    <meta property="og:url" content="https://engineering.grab.com/real-time-data-ingestion">
    <meta property="og:title" content="Real-time data ingestion in Grab">
    <meta property="og:description" content="When it comes to data ingestion, there are several prevailing issues that come to mind: data inconsistency, integrity and maintenance. Find out how the Caspian team leveraged real-time data ingestion to help address these pain points.">
    <meta property="og:site_name" content="Grab Tech">
    <meta property="og:type" content="article">
    <meta property="og:image" content="https://engineering.grab.com/img/real-time-data-ingestion/cover.jpg">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">

    <!-- Favicons -->
    <link rel="icon" href="/favicon.ico">
    <link rel="apple-touch-icon" href="/apple-touch-icon.png">

    <!-- CSS -->
    <link href="//fonts.googleapis.com/css?family=Droid+Serif:400,400i,700,700i" rel="stylesheet">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap-theme.min.css">
    <script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
    <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="https://engineering.grab.com/real-time-data-ingestion">

    <!-- RSS -->
    <link rel="alternate" type="application/rss+xml" title="RSS for Official Grab Tech Blog" href="/feed.xml">
    <!-- OneTrust Cookies Consent Notice start for grab.com -->
    <script type="text/javascript" src="https://cdn-apac.onetrust.com/consent/a3be3527-7455-48e0-ace6-557ddbd506d5/OtAutoBlock.js" ></script>
    <script src="https://cdn-apac.onetrust.com/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="a3be3527-7455-48e0-ace6-557ddbd506d5" ></script>
    <script type="text/javascript">
    function OptanonWrapper() { }
    </script>
    <!-- OneTrust Cookies Consent Notice end for grab.com -->
  </head>

  <body>
    <header class="site-header">
  <div class="wrapper-navbar">
    <div class="site-title-wrapper">
      <div class="row site-title-wrapper-inner">
        <div class="col-xs-1 visible-xs hamburger-nav" id="mobile-menu-btn">
          <div class="menu-btn"></div>
        </div>
        <div class="col-sm-3 col-xs-3">
          <div class="site-title-container">
            <a class="site-title" href="/"></a>
            <span class="site-subtitle">&nbsp;Tech Blog</span>
          </div>
        </div>
        <div class="col-sm-9 col-xs-8 text-right">
          <ul class="nav-category hidden-xs">
            
              
              <li>
                <a href="/categories/engineering/">Engineering</a>
              </li>
            
              
              <li>
                <a href="/categories/data-science/">Data Science</a>
              </li>
            
              
              <li>
                <a href="/categories/design/">Design</a>
              </li>
            
              
              <li>
                <a href="/categories/product/">Product</a>
              </li>
            
              
              <li>
                <a href="/categories/security/">Security</a>
              </li>
            
          </ul>
          <div class="site-search text-right">
            <form action="/search.html" role="search" class="search-form">
  <div class="search-icon"> </div>
  <input type="search" name="q" class="search-text" placeholder="Search...">
  <button class="search-submit"><i class="fa fa-chevron-right"></i></button>
</form>
    

          </div>
        </div>
      </div>
      <!--  Only visible on mobile view -->
      <div class="mobile-menu-container">
        <ul class="mobile-menu">
          
            
            <li>
              <a href="/categories/engineering/">Engineering</a>
            </li>
          
            
            <li>
              <a href="/categories/data-science/">Data Science</a>
            </li>
          
            
            <li>
              <a href="/categories/design/">Design</a>
            </li>
          
            
            <li>
              <a href="/categories/product/">Product</a>
            </li>
          
            
            <li>
              <a href="/categories/security/">Security</a>
            </li>
          
        </ul>
      </div>
    </div>
  </div>
</header>
<script src="/js/main.js"></script>

    <div class="page-content">
      
<div class="wrapper">
  <div class="post">
    <header class="post-header">
      <img src="/img/real-time-data-ingestion/cover.jpg" class="post-cover-photo" alt="Real-time data ingestion in Grab cover photo">
      
        
          <a class="post-category" href="/categories/engineering/">Engineering </a>
      
        
          &middot;
        
          <a class="post-category" href="/categories/data-science/">Data Science </a>
      

      <h1 class="post-title">Real-time data ingestion in Grab</h1>
      
      <div class="post-meta">
        <div class="row">
          <div class="col-xs-12">
            <div class="post-author-thumbnail-container">
              
                
                
                  <img class="post-author-thumbnail-large img-circle" src="/img/authors/shuguang-xiang.jpg">
                
              
                
                
                  <img class="post-author-thumbnail-large img-circle" src="/img/authors/irfan-hanif.png">
                
              
                
                
                  <img class="post-author-thumbnail-large img-circle" src="/img/authors/feng-cheng.png">
                
              
            </div>

            <div class="post-meta-text-container">
              <span class="post-author-large">
                
                  
                  
                    
                    <a href="/authors#shuguang-xiang">Shuguang Xiang</a>
                  
                
                  
                  
                    
                      &middot;
                    
                    <a href="/authors#irfan-hanif">Irfan Hanif</a>
                  
                
                  
                  
                    
                      &middot;
                    
                    <a href="/authors#feng-cheng">Feng Cheng</a>
                  
                
              </span>
              <span class="post-date-large">14 Mar 2022 | 10 min read</span>
            </div>
          </div>
        </div>
      </div>

    </header>
    <div class="wrapper-content">
      <article class="post-content">
        <p>Typically, modern applications use various database engines for their service needs; within Grab, these would be MySQL, Aurora and DynamoDB. Lately, the Caspian team has observed an increasing need to consume real-time data for many service teams. These real-time changes in database records help to support online and offline business decisions for hundreds of teams.</p>

<p>Because of that, we have invested time into synchronising data from MySQL, Aurora and Dynamodb to the message queue, i.e. Kafka. In this blog, we share how real-time data ingestion has helped since it was launched.</p>

<h2 id="introduction">Introduction</h2>
<p>Over the last few years, service teams had to write all transactional data twice: once into Kafka and once into the database. This helped to solve the inter-service communication challenges and obtain audit trail logs. However, if the transactions fail, data integrity becomes a prominent issue. Moreover, it is a daunting task for developers to maintain the schema of data written into Kafka.</p>

<p>With real-time ingestion, there is a notably better schema evolution and guaranteed data consistency; service teams no longer need to write data twice.</p>

<p>You might be wondering, why don’t we have a single transaction that spans the services’ databases and Kafka, to make data consistent? This would not work as Kafka does not support being enlisted in distributed transactions. In some situations, we might end up having new data persisting into the services’ databases, but not having the corresponding message sent to Kafka topics.</p>

<p>Instead of registering or modifying the mapped table schema in Golang writer into Kafka beforehand, service teams tend to avoid such schema maintenance tasks entirely. In such cases, real-time ingestion can be adopted where data exchange among the heterogeneous databases or replication between source and replica nodes is required.</p>

<p>While reviewing the key challenges around real-time data ingestion, we realised that there were many potential user requirements to include. To build a standardised solution, we identified several points that we felt were high priority:</p>

<ul>
  <li>Make transactional data readily available in real time to drive business decisions at scale.</li>
  <li>Capture audit trails of any given database.</li>
  <li>Get rid of the <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Storage.html">burst read</a> on databases caused by SQL-based query ingestion.</li>
</ul>

<p>To empower Grabbers with real-time data to drive their business decisions, we decided to take a scalable event-driven approach, which is being facilitated with a bunch of internal products, and designed a solution for real-time ingestion.  </p>

<h2 id="anatomy-of-architecture">Anatomy of architecture</h2>
<p>The solution for real-time ingestion has several key components:</p>
<ul>
  <li>Stream data storage</li>
  <li>Event producer</li>
  <li>Message queue</li>
  <li>Stream processor</li>
</ul>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image2.png" alt="Real time ingestion architecture" style="width:60%" /><figcaption align="middle"><i>Figure 1. Real time ingestion architecture</i></figcaption>
  </figure>
</div>

<h3 id="stream-storage">Stream storage</h3>
<p>Stream storage acts as a repository that stores the data transactions in order with <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html">exactly-once guarantee</a>. However, the level of order in stream storage differs with regards to different databases.</p>

<p>For MySQL or Aurora, transaction data is stored in <code class="language-plaintext highlighter-rouge">binlog</code> files in sequence and rotated, thus ensuring global order. Data with global order assures that all MySQL records are ordered and reflects the real life situation. For example, when transaction logs are replayed or consumed by downstream consumers, consumer A’s Grab food order at 12:01:44 pm will <strong>always appear before</strong> consumer B’s order at 12:01:45 pm.</p>

<p>However, this does not necessarily hold true for DynamoDB stream storage as DynamoDB streams are partitioned. Audit trails of a given record show that they go into the same partition in the same order, ensuring consistent partitioned order. Thus when replay happens, consumer B’s order might appear before consumer A’s.</p>

<p>Moreover, there are multiple formats to choose from for both MySQL <code class="language-plaintext highlighter-rouge">binlog</code> and DynamoDB stream records. We eventually set <code class="language-plaintext highlighter-rouge">ROW</code> for <code class="language-plaintext highlighter-rouge">binlog</code> formats and <code class="language-plaintext highlighter-rouge">NEW_AND_OLD_IMAGES</code> for DynamoDB stream records. This depicts the detailed information before and after modifying any given table record. The <code class="language-plaintext highlighter-rouge">binlog</code> and DynamoDB stream main fields are tabulated in Figures 2 and 3 respectively.</p>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image8.png" alt="Binlog record schema" style="width:60%" /><figcaption align="middle"><i>Figure 2. Binlog record schema</i></figcaption>
  </figure>
</div>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image6.png" alt="DynamoDB stream record schema" style="width:60%" /><figcaption align="middle"><i>Figure 3. DynamoDB stream record schema</i></figcaption>
  </figure>
</div>

<h3 id="event-producer">Event producer</h3>
<p>Event producers take in <code class="language-plaintext highlighter-rouge">binlog</code> messages or stream records and output to the message queue. We evaluated several technologies for the different database engines.</p>

<p>For MySQL or Aurora, three solutions were evaluated: Debezium, Maxwell, and Canal. We chose to onboard Debezium as it is deeply integrated with the Kafka Connect framework. Also, we see the potential of extending solutions among other external systems whenever moving large collections of data in and out of the Kafka cluster.</p>

<p>One such example is the <a href="https://github.com/trustpilot/kafka-connect-dynamodb">open source project</a> that attempts to build a custom DynamoDB connector extending the Kafka Connect (KC) framework. It self manages checkpointing via an additional DynamoDB table and can be deployed on KC smoothly.</p>

<p>However, the DynamoDB connector fails to exploit the fundamental nature of storage DynamoDB streams: dynamic partitioning and auto-scaling based on the traffic. Instead, it spawns only a single thread task to process all shards of a given DynamoDB table. As a result, downstream services suffer from data latency the most when write traffic surges.</p>

<p>In light of this, the lambda function becomes the most suitable candidate as the event producer. Not only does the concurrency of lambda functions scale in and out based on actual traffic, but the trigger frequency is also adjustable at your discretion.</p>

<h3 id="kafka">Kafka</h3>
<p>This is the distributed data store optimised for ingesting and processing data in real time. It is widely adopted due to its high scalability, fault-tolerance, and parallelism. The messages in Kafka are abstracted and encoded into Protobuf. </p>

<h3 id="stream-processor">Stream processor</h3>
<p>The stream processor consumes messages in Kafka and writes into S3 every minute. There are a number of options readily available in the market; Spark and Flink are the most common choices. Within Grab, we deploy a Golang library to deal with the traffic.</p>

<h2 id="use-cases">Use cases</h2>
<p>Now that we’ve covered how real-time data ingestion is done in Grab, let’s look at some of the situations that could benefit from real-time data ingestion.</p>

<h3 id="1-data-pipelines">1. Data pipelines</h3>
<p>We have thousands of pipelines running hourly in Grab. Some tables have significant growth and generate workload beyond what a SQL-based query can handle. An hourly data pipeline would incur a read spike on the production database shared among various services, draining CPU and memory resources. This deteriorates other services’ performance and could even block them from reading. With real-time ingestion, the query from data pipelines would be incremental and span over a period of time.</p>

<p>Another scenario where we switch to real-time ingestion is when a missing index is detected on the table. To speed up the query, SQL-based query ingestion requires indexing on columns such as <code class="language-plaintext highlighter-rouge">created_at</code>, <code class="language-plaintext highlighter-rouge">updated_at</code> and <code class="language-plaintext highlighter-rouge">id</code>. Without indexing, SQL based query ingestion would either result in high CPU and memory usage, or fail entirely.</p>

<p>Although adding indexes for these columns would resolve this issue, it comes with a cost, i.e. a copy of the indexed column and primary key is created on disk and the index is kept in memory. Creating and maintaining an index on a huge table is much costlier than for small tables. With performance consideration in mind, it is <em>not</em> recommended to add indexes to an existing huge table.</p>

<p>Instead, real-time ingestion overshadows SQL-based ingestion. We can spawn a new connector, archiver (Coban team’s Golang library that dumps data from Kafka at minutes-level frequency) and compaction job to bubble up the table record from <code class="language-plaintext highlighter-rouge">binlog</code> to the destination table in the Grab data lake.</p>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image5.png" alt="Using real-time ingestion for data pipelines" style="width:60%" /><figcaption align="middle"><i>Figure 4. Using real-time ingestion for data pipelines</i></figcaption>
  </figure>
</div>

<h3 id="2-drive-business-decisions">2. Drive business decisions</h3>

<p>A key use case of enabling real-time ingestion is driving business decisions at scale without even touching the source services. <a href="https://microservices.io/patterns/data/saga.html">Saga</a> pattern is commonly adopted in the microservice world. Each service has its own database, splitting an overarching database transaction into a series of multiple database transactions. Communication is established among services via message queue i.e. Kafka.</p>

<p>In an earlier <a href="https://engineering.grab.com/search-indexing-optimisation">tech blog</a> published by the Grab Search team, we talked about how real-time ingestion with Debezium optimised and boosted search capabilities. Each MySQL table is mapped to a Kafka topic and one or multiple topics build up a search index within Elasticsearch.</p>

<p>With this new approach, there is no data loss, i.e. changes via MySQL command line tool or other DB management tools can be captured. Schema evolution is also naturally supported; the new schema defined within a MySQL table is inherited and stored in Kafka. No producer code change is required to make the schema consistent with that in MySQL. Moreover, the database read has been reduced by 90 percent including the efforts of the Data Synchronisation Platform.</p>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image4.png" alt="Grab Search team use case" style="width:60%" /><figcaption align="middle"><i>Figure 5. Grab Search team use case</i></figcaption>
  </figure>
</div>

<p>The GrabFood team exemplifies mostly similar advantages in the DynamoDB area. The only differences compared to MySQL are that the frequency of the lambda functions is adjustable and parallelism is auto-scaled based on the traffic. By auto-scaling, we mean that more lambda functions will be auto-deployed to cater to a sudden spike in traffic, or destroyed as the traffic falls.</p>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image1.png" alt="Grab Food team use case" style="width:60%" /><figcaption align="middle"><i>Figure 6. Grab Food team use case</i></figcaption>
  </figure>
</div>

<h3 id="3-database-replication">3. Database replication</h3>

<p>Another use case we did not originally have in mind is incremental data replication for disaster recovery. Within Grab, we enable DynamoDB streams for tier 0 and critical DynamoDB tables. Any <code class="language-plaintext highlighter-rouge">insert</code>, <code class="language-plaintext highlighter-rouge">delete</code>, <code class="language-plaintext highlighter-rouge">modify</code> operations would be propagated to the disaster recovery table in another availability zone.</p>

<p>When migrating or replicating databases, we use the <a href="https://martinfowler.com/bliki/StranglerFigApplication.html">strangler fig pattern</a>, which offers an incremental, reliable process for migrating databases. This is a method whereby a new system slowly grows on top of an old system and is gradually adopted until the old system is “strangled” and can simply be removed. Figure 7 depicts how DynamoDB streams drive real-time synchronisation between tables in different regions.</p>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image3.png" alt="Data replication among DynamoDB tables across different regions in DBOps team" style="width:60%" /><figcaption align="middle"><i>Figure 7. Data replication among DynamoDB tables across different regions in DBOps team</i></figcaption>
  </figure>
</div>

<h3 id="4-deliver-audit-trails">4. Deliver audit trails</h3>

<p>Reasons for maintaining data audit trails are manifold in Grab: regulatory requirements might mandate businesses to keep complete historical information of a consumer or to apply machine learning techniques to detect fraudulent transactions made by consumers. Figure 8 demonstrates how we deliver audit trails in Grab.</p>

<div class="post-image-section"><figure>
  <img src="/img/real-time-data-ingestion/image9.png" alt="Data replication among DynamoDB tables across different regions in DBOps team" style="width:60%" /><figcaption align="middle"><i>Figure 8. Deliver audit trails in Grab</i></figcaption>
  </figure>
</div>

<h2 id="summary">Summary</h2>

<p>Real time ingestion is playing a pivotal role in Grab’s ecosystem. It:</p>

<ul>
  <li>boosts data pipelines with less read pressure imposed on databases shared among various services;</li>
  <li>empowers real-time business decisions with assured resource efficiency;</li>
  <li>provides data replication among tables residing in various regions; and</li>
  <li>delivers audit trails that either keep complete history or help unearth fraudulent operations.</li>
</ul>

<p>Since this project launched, we have made crucial enhancements to facilitate daily operations with several in-house products that are used for data onboarding, quality checking, maintaining freshness, etc.</p>

<p>We will continuously improve our platform to provide users with a seamless experience in data ingestion, starting with unifying our internal tools. Apart from providing a unified platform, we will also contribute more ideas to the ingestion, extending it to Azure and GCP, supporting multi-catalogue and offering multi-tenancy.</p>

<p>In our next blog, we will drill down to other interesting features of real-time ingestion, such as how ordering is achieved in different cases and custom partitioning in real-time ingestion. Stay tuned!</p>

<h2 id="join-us">Join us</h2>
<p>Grab is a leading superapp in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across over 400 cities in eight countries.</p>

<p>Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, <a href="https://grab.careers/">join our team</a> today!</p>

      </article>
      <div>
        
          <div class="post-tags">
  
  
    <a href="/tags#data-ingestion" class="label tags-label">Data ingestion</a>
  
    <a href="/tags#engineering" class="label tags-label">Engineering</a>
  
</div>

        
        <br>
      </div>
      <div class="sharing-links text-right">
  Share on &nbsp;
  <a href="https://twitter.com/intent/tweet?text=Real-time data ingestion in Grab&url=https://engineering.grab.com/real-time-data-ingestion&via=grabengineering&related=grabengineering" class="btn btn-sm btn-share btn-share-twitter" rel="nofollow" target="_new" title="Share on Twitter" onclick="onShareButtonClick(this); return false;"><i class="fa fa-lg fa-twitter"></i>&nbsp; Twitter</a>
  <a href="https://facebook.com/sharer.php?u=https://engineering.grab.com/real-time-data-ingestion" class="btn btn-sm btn-share btn-share-facebook" rel="nofollow" target="_new" title="Share on Facebook" onclick="onShareButtonClick(this); return false;"><i class="fa fa-lg fa-facebook"></i>&nbsp; Facebook</a>
  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://engineering.grab.com/real-time-data-ingestion&title=Real-time data ingestion in Grab
&summary=When it comes to data ingestion, there are several prevailing issues that come to mind: data inconsistency, integrity and maintenance. Find out how the Caspian team leveraged real-time data ingestion to help address these pain points.&source=Grab Tech" class="btn btn-sm btn-share btn-share-linkedin" rel="nofollow" target="_new" title="Share on LinkedIn" onclick="onShareButtonClick(this); return false;"><i class="fa fa-lg fa-linkedin"></i>&nbsp; LinkedIn</a>
</div>
<script>
  function onShareButtonClick(button) {
    var width = 600;
    var height = 600;
    var left = (window.screen.width / 2) - (width / 2);
    var top = (window.screen.height / 2) - (height / 2);
    window.open(button.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=' + height + ',width=' + width + ',top=' + top + ',left=' + left);
    return false;
  }
</script>

      <hr class="section-divider">

      <br/>
      <!-- 
        <div id="disqus_thread"></div>
<script>
  var disqus_config = function () {
    this.page.url = 'https://engineering.grab.com/real-time-data-ingestion';
    this.page.identifier = '/real-time-data-ingestion';
  };
  (function() {
    var d = document, s = d.createElement('script');
    s.src = '//grabengineering.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

       -->

    </div>
  </div>
</div>

    </div>
    <div class="progress-wrap">
    <svg class="progress-circle svg-content" width="100%" height="100%" viewBox="-1 -1 102 102">
        <path d="M50,1 a49,49 0 0,1 0,98 a49,49 0 0,1 0,-98" />
    </svg>
    <i class="fa fa-chevron-up btt-btn"></i>
</div>
    <footer class="site-footer">
  <div class="wrapper">
    <div class="row">
      <div class="col-sm-6 col-xs-12">
        <h2 class="footer-heading">Grab Tech</h2>
        <ul class="social-media-list">
  
    <li>
      <a href="https://github.com/grab" target="_blank" rel="nofollow noreferrer">
        <i class="fa fa-github fa-lg"></i>
      </a>
    </li>
  
  
    <li>
      <a href="https://www.linkedin.com/company/grabapp" target="_blank" rel="nofollow noreferrer">
        <i class="fa fa-linkedin fa-lg"></i>
      </a>
    </li>
  
  <li>
    <a href="https://engineering.grab.com/feed.xml" target="_blank">
      <i class="fa fa-rss fa-lg"></i>
    </a>
  </li>
</ul>

        <div>
          <script src="//platform.linkedin.com/in.js" type="text/javascript"> lang: en_US</script>
          <script type="IN/FollowCompany" data-id="5382086" data-counter="right"></script>
        </div>        
        <br>
      </div>
      <div class="col-sm-6 col-xs-12 hiring-section">
        <h2 class="footer-heading">Join Us</h2>
        <p class="text">
          Want to join us in our mission to revolutionize transportation?
        </p>
        <a class="btn" href="https://grab.careers" target="_blank">View open positions</a>

      </div>
    </div>
    
  <!-- Google Tag Manager -->
  <script>
    (function (w, d, s, l, i) {
      w[l] = w[l] || [];
      w[l].push({
        'gtm.start': new Date().getTime(),
        event: 'gtm.js'
      });
      var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s),
        dl = l != 'dataLayer' ? '&l=' + l : '';
      j.async = true;
      j.src =
        'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
      f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-T3CT72T');
  </script>
  <!-- End Google Tag Manager -->

  <!-- Old script 
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'GTM-T3CT72T', 'auto');
    ga('send', 'pageview');
  </script> -->
<!-- End of olf script -->


  </body>
</html>
