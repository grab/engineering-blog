<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab's Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>https://engineering.grab.com/</link>
    <atom:link href="https://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 06 Jul 2023 07:53:22 +0000</pubDate>
    <lastBuildDate>Thu, 06 Jul 2023 07:53:22 +0000</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Go module proxy at Grab</title>
        <description>&lt;p&gt;At Grab, we rely heavily on &lt;a href=&quot;/go-module-a-guide-for-monorepos-part-1&quot;&gt;a large Go monorepo&lt;/a&gt; for backend development, which offers benefits like code reusability and discoverability. However, as we continue to grow, managing a large monorepo brings about its own set of unique challenges.&lt;/p&gt;

&lt;p&gt;As an example, using Go commands such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go list&lt;/code&gt; can be incredibly slow when fetching Go modules residing in a large &lt;a href=&quot;https://github.com/golang/go/wiki/Modules#what-are-multi-module-repositories&quot;&gt;multi-module repository&lt;/a&gt;. This sluggishness takes a toll on developer productivity, burdens our Continuous Integration (CI) systems, and strains our Version Control System host (VCS), GitLab.&lt;/p&gt;

&lt;p&gt;In this blog post, we look at how &lt;a href=&quot;https://github.com/gomods/athens&quot;&gt;Athens&lt;/a&gt;, a Go module proxy, helps to improve the overall developer experience of engineers working with a large Go monorepo at Grab.&lt;/p&gt;

&lt;h2 id=&quot;key-highlights&quot;&gt;Key highlights&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;We reduced the time of executing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; command from &lt;strong&gt;~18 minutes&lt;/strong&gt; to &lt;strong&gt;~12 seconds&lt;/strong&gt; when fetching monorepo Go modules.&lt;/li&gt;
  &lt;li&gt;We scaled in and &lt;strong&gt;scaled down our entire Athens cluster by 70%&lt;/strong&gt; by utilising the fallback network mode in Athens along with Golang’s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOVCS&lt;/code&gt; mode, resulting in cost savings and enhanced efficiency.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;problem-statements-and-solutions&quot;&gt;Problem statements and solutions&lt;/h2&gt;

&lt;h3 id=&quot;1-painfully-slow-performance-of-go-commands&quot;&gt;1. Painfully slow performance of Go commands&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Problem summary: Running the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; command in our monorepo takes a considerable amount of time and can lead to performance degradation in our VCS.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When working with the Go programming language, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; is one of the most common commands that you’ll use every day. Besides developers, this command is also used by CI systems.&lt;/p&gt;

&lt;h4 id=&quot;what-does-go-getdo&quot;&gt;What does &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; do?&lt;/h4&gt;

&lt;p&gt;The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; command is used to download and install packages and their dependencies in Go. Note that it operates differently depending on whether it is run in &lt;a href=&quot;https://pkg.go.dev/cmd/go#hdr-Legacy_GOPATH_go_get&quot;&gt;legacy GOPATH mode&lt;/a&gt; or module-aware mode. In Grab, we’re using the &lt;a href=&quot;https://go.dev/ref/mod#mod-commands&quot;&gt;module-aware mode&lt;/a&gt; in a &lt;a href=&quot;https://github.com/golang/go/wiki/Modules#faqs--multi-module-repositories&quot;&gt;multi-module repository&lt;/a&gt; setup.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/go-module-proxy/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Every time &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; is run, it uses Git commands, like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git ls-remote&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git tag&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git fetch&lt;/code&gt;, etc, to search and download the entire worktree. The excessive use of these Git commands on our monorepo contributes to the long processing time and can be strenuous to our VCS.&lt;/p&gt;

&lt;h4 id=&quot;how-big-is-our-monorepo&quot;&gt;How big is our monorepo?&lt;/h4&gt;

&lt;p&gt;To fully grasp the challenges faced by our engineering teams, it’s crucial to understand the vast scale of the monorepo that we work with daily. For this, we use &lt;a href=&quot;https://github.com/github/git-sizer&quot;&gt;git-sizer&lt;/a&gt; to analyse our monorepo.&lt;/p&gt;

&lt;p&gt;Here’s what we found:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Overall repository size&lt;/strong&gt;: The monorepo has a total uncompressed size of &lt;strong&gt;69.3 GiB&lt;/strong&gt;, a fairly substantial figure. To put things into perspective, the &lt;a href=&quot;https://github.com/torvalds/linux&quot;&gt;Linux kernel repository&lt;/a&gt;, known for its vastness, currently stands at 55.8 GiB.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Trees&lt;/strong&gt;: The total number of trees is 3.21M and tree entries are 99.8M, which consume 3.65 GiB. This may cause performance issues during some Git operations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;References&lt;/strong&gt;: Totalling 10.7k references.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Biggest checkouts&lt;/strong&gt;: There are 64.7k directories in our monorepo. This affects operations like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git status&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git checkout&lt;/code&gt;. Moreover, our monorepo has a maximum path depth of 20. This contributes to a slow processing time on Git and negatively impacts developer experience. The number of files (354k) and the total size of files (5.08 GiB) are also concerns due to their potential impact on the repository’s performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To draw a comparison, refer to &lt;a href=&quot;https://github.com/github/git-sizer/blob/0b6d3a21c6ccbd49463534a19cc1b3f71526c077/README.md#usage&quot;&gt;the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git-sizer&lt;/code&gt; output of the Linux repository&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;how-slow-is-slow&quot;&gt;How slow is “slow”?&lt;/h4&gt;

&lt;p&gt;To illustrate the issue further, we will compare the time taken for various Go commands to fetch a single module in our monorepo at a 10 MBps download speed.&lt;/p&gt;

&lt;p&gt;This is an example of how a module is structured in our monorepo:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gitlab.company.com/monorepo/go
  |-- go.mod
  |-- commons/util/gk
        |-- go.mod
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table class=&quot;table&quot; border=&quot;1&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Go commands&lt;/th&gt;
      &lt;th&gt;GOPROXY&lt;/th&gt;
      &lt;th&gt;Previously cached?&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Result (time taken)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go get -x gitlab.company.com/monorepo/go/commons/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;proxy.golang.org,direct&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Download and install the latest version of the module. This is a common scenario that developers often encounter.&lt;/td&gt;
      &lt;td&gt;18:50.71 minutes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go get -x gitlab.company.com/monorepo/go/commons/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;proxy.golang.org,direct&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Download and install the latest version of the module &lt;strong&gt;without any module cache&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;1:11:54.56 hour&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go list -x -m -json -versions gitlab.company.com/monorepo/go/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;proxy.golang.org,direct&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;List information about the module&lt;/td&gt;
      &lt;td&gt;3.873 seconds&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go list -x -m -json -versions gitlab.company.com/monorepo/go/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;proxy.golang.org,direct&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;List information about the module &lt;strong&gt;without any module cache&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;3:18.58 minutes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In this example, using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; to fetch a module took over &lt;strong&gt;18 minutes&lt;/strong&gt; to complete. If we needed to retrieve more than one module in our monorepo, it can be incredibly time-consuming.&lt;/p&gt;

&lt;h4 id=&quot;why-is-it-slow-in-a-monorepo&quot;&gt;Why is it slow in a monorepo?&lt;/h4&gt;

&lt;p&gt;In a large Go monorepo, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; commands can be slow due to several factors:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Large number of files and directories&lt;/strong&gt;: When running &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt;, the command needs to search and download the entire worktree. In a large multi-module monorepo, the vast number of files and directories make this search process very expensive and time-consuming.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Number of refs&lt;/strong&gt;: A large number of refs (branches or tags) in our monorepo can affect performance. Ref advertisements (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git ls-remote&lt;/code&gt;), which contain every ref in our monorepo, are the first phase in any remote Git operation, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git clone&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git fetch&lt;/code&gt;. With a large number of refs, performance takes a hit when performing these operations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Commit history traversal&lt;/strong&gt;: Operations that need to traverse a repository’s commit history and consider each ref will be slow in a monorepo. The larger the monorepo, the more time-consuming these operations become.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;the-consequences-stifled-productivity-and-strained-systems&quot;&gt;The consequences: Stifled productivity and strained systems&lt;/h4&gt;

&lt;h5 id=&quot;developers-and-ci&quot;&gt;Developers and CI&lt;/h5&gt;

&lt;p&gt;When Go command operations like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; are slow, they contribute to significant delays and inefficiencies in software development workflows. This leads to reduced productivity and demotivated developers.&lt;/p&gt;

&lt;p&gt;Optimising Go command operations’ speed is crucial to ensure efficient software development workflows and high-quality software products.&lt;/p&gt;

&lt;h5 id=&quot;version-control-system&quot;&gt;Version Control System&lt;/h5&gt;

&lt;p&gt;It’s also worth noting that overusing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; commands can also lead to performance issues for VCS. When Go packages are frequently downloaded using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt;, we saw that it caused a bottleneck in our VCS cluster, which can lead to performance degradation or even cause rate-limiting queue issues.&lt;/p&gt;

&lt;p&gt;This negatively impacts the performance of our VCS infrastructure, causing delays or sometimes unavailability for some users and CI.&lt;/p&gt;

&lt;h4 id=&quot;solution-athens--fallbacknetwork-mode--govcs-custom-cache-refresh-solution&quot;&gt;Solution: Athens + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fallback&lt;/code&gt; Network Mode + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOVCS&lt;/code&gt; + Custom Cache Refresh Solution&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Problem summary: Speed up &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; command by not fetching from our VCS&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We addressed the speed issue by using Athens, &lt;a href=&quot;https://www.practical-go-lessons.com/chap-18-go-module-proxies#what-is-a-proxy-server&quot;&gt;a proxy server for Go modules&lt;/a&gt; (read more about the &lt;a href=&quot;https://go.dev/ref/mod#goproxy-protocol&quot;&gt;GOPROXY protocol&lt;/a&gt;).&lt;/p&gt;

&lt;h5 id=&quot;how-does-athens-work&quot;&gt;How does Athens work?&lt;/h5&gt;

&lt;p&gt;The following sequence diagram describes the default flow of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; command with Athens.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/go-module-proxy/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Athens uses a &lt;a href=&quot;https://docs.gomods.io/configuration/storage/&quot;&gt;storage system&lt;/a&gt; for Go module packages, which can also be configured to use various storage systems such as Amazon S3, and Google Cloud Storage, among others.&lt;/p&gt;

&lt;p&gt;By caching these module packages in storage, Athens can serve the packages directly from storage rather than requesting them from an upstream VCS while serving Go commands such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go mod download&lt;/code&gt; and &lt;a href=&quot;https://go.dev/ref/mod#build-commands&quot;&gt;certain go build modes&lt;/a&gt;. However, just using a Go module proxy didn’t fully resolve our issue since the &lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go list&lt;/code&gt;&lt;/strong&gt; commands still hit our VCS through the proxy.&lt;/p&gt;

&lt;p&gt;With this in mind, we thought “what if we could just serve the Go modules directly from Athens’ storage for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt;?” This question led us to discover Athens network mode.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;What is Athens network mode?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Athens &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;NetworkMode&lt;/code&gt; configures how Athens will return the results of the Go commands. It can be assembled from both its own storage and the upstream VCS. As of &lt;a href=&quot;https://github.com/gomods/athens/releases/tag/v0.12.1&quot;&gt;Athens v0.12.1&lt;/a&gt;, it currently supports these 3 modes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;strict&lt;/strong&gt;: merge VCS versions with storage versions, but fail if either of them fails.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;offline&lt;/strong&gt;: only get storage versions, &lt;strong&gt;never reach out to VCS&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;fallback&lt;/strong&gt;: only return storage versions, if VCS fails. Fallback mode does the best effort of giving you what’s available at the time of requesting versions.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Our Athens clusters were initially set to use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strict&lt;/code&gt; network mode, but this was not ideal for us. So we explored the other network modes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Exploring &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;offline&lt;/code&gt; mode&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We initially sought to explore the idea of putting Athens in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;offline&lt;/code&gt; network mode, which would allow Athens to serve Go requests only from its storage. This concept aligned with our aim of reducing VCS hits while also leading to significant performance improvement in Go workflows.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/go-module-proxy/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;However in practice, it’s not an ideal approach. The default Athens setup (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strict&lt;/code&gt; mode) automatically updates the module version when a user requests a new module version. Nevertheless, switching Athens to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;offline&lt;/code&gt; mode would disable the automatic updates as it wouldn’t connect to the VCS.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Custom cache refresh solution&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To solve this, we implemented a CI pipeline that refreshes Athens’ module cache whenever a new module is released in our monorepo. Employing this with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;offline&lt;/code&gt; mode made Athens effective for the monorepo but it resulted in the loss of automatic updates for other repositories&lt;/p&gt;

&lt;p&gt;Restoring this feature requires applying our custom cache refresh solution to all other Go repositories. However, implementing this workaround can be quite cumbersome and significant additional time and effort. We decided to look for another solution that would be easier to maintain in the long run.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A balanced approach: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fallback&lt;/code&gt; Mode and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOVCS&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This approach builds upon our aforementioned custom cache refresh which is specifically designed for the monorepo.&lt;/p&gt;

&lt;p&gt;We came across the &lt;a href=&quot;https://go.dev/ref/mod#vcs-govcs&quot;&gt;GOVCS environment variable&lt;/a&gt;, which we use in combination with the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fallback&lt;/code&gt; network mode to effectively put only the monorepo in “offline” mode.&lt;/p&gt;

&lt;p&gt;When &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOVCS&lt;/code&gt; is set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gitlab.company.com/monorepo/go:off&lt;/code&gt;, Athens encounters an error whenever it tries to fetch modules from VCS:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gitlab.company.com/monorepo/go/commons/util/gk@v1.1.44: unrecognized import path &quot;gitlab.company.com/monorepo/go/commons/util/gk&quot;: GOVCS disallows using git for private gitlab.company.com/monorepo/go; see 'go help vcs'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If Athens network mode is set to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;strict&lt;/code&gt;, Athens returns 404 errors to the user. By switching to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fallback&lt;/code&gt; mode, Athens tries to retrieve the module from its storage if a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOVCS&lt;/code&gt; failure occurs.&lt;/p&gt;

&lt;p&gt;Here’s the updated Athens configuration (&lt;a href=&quot;https://github.com/gomods/athens/blob/8e1581e10b0d3a70a30f45b10c24c3f992464d7a/config.dev.toml#L46&quot;&gt;example default config&lt;/a&gt;):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;GoBinaryEnvVars = [&quot;GOPROXY=direct&quot;, 
&quot;GOPRIVATE=gitlab.company.com&quot;, 
&quot;GOVCS=gitlab.company.com/monorepo/go:off&quot;]

NetworkMode = &quot;fallback&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With the custom cache refresh solution coupled with this approach, we not only accelerate the retrieval of Go modules within the monorepo but also allow for automatic updates for non-monorepo Go modules.&lt;/p&gt;

&lt;h4 id=&quot;final-results&quot;&gt;Final results&lt;/h4&gt;

&lt;p&gt;This solution resulted in a significant improvement in the performance of Go commands for our developers. With Athens, the same command is completed in just &lt;strong&gt;~12 seconds (down from ~18 minutes)&lt;/strong&gt;, which is impressively fast.&lt;/p&gt;

&lt;table class=&quot;table&quot; border=&quot;1&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Go commands&lt;/th&gt;
      &lt;th&gt;GOPROXY&lt;/th&gt;
      &lt;th&gt;Previously cached?&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
      &lt;th&gt;Result (time taken)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go get -x gitlab.company.com/monorepo/go/commons/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;goproxy.company.com&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Download and install the latest version of the module. This is a common scenario that developers often encounter.&lt;/td&gt;
      &lt;td&gt;11.556 seconds&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go get -x gitlab.company.com/monorepo/go/commons/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;goproxy.company.com&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Download and install the latest version of the module &lt;strong&gt;without any module cache&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;1:05.60 minutes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go list -x -m -json -versions gitlab.company.com/monorepo/go/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;goproxy.company.com&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;List information about the monorepo module&lt;/td&gt;
      &lt;td&gt;0.592 seconds&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code&gt;go list -x -m -json -versions gitlab.company.com/monorepo/go/util/gk&lt;/code&gt;&lt;/td&gt;
      &lt;td&gt;goproxy.company.com&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;List information about the monorepo module &lt;strong&gt;without any module cache&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;1.023 seconds&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/go-module-proxy/image5.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Average cluster CPU utlisation&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/go-module-proxy/image3.png&quot; alt=&quot;&quot; style=&quot;width:90%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Average cluster memory utlisation&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;In addition, this change to our Athens cluster also leads to substantial reduction in average cluster CPU and memory utilisation. This also enabled us to scale in and &lt;strong&gt;scale down our entire Athens cluster by 70%&lt;/strong&gt;, resulting in cost savings and enhanced efficiency. On top of that, we were also able to effectively eliminate VCS’s rate-limiting issues while making the monorepo’s command operation considerably faster.&lt;/p&gt;

&lt;h3 id=&quot;2-go-modules-in-gitlab-subgroups&quot;&gt;2. Go modules in GitLab subgroups&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Problem summary: Go modules are unable to work natively with private or internal repositories under GitLab subgroups.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When it comes to managing code repositories and packages, &lt;a href=&quot;https://docs.gitlab.com/ee/user/group/subgroups/&quot;&gt;GitLab subgroups&lt;/a&gt; and Go modules have become an integral part of the development process at Grab. Go modules help to organise and manage dependencies, and GitLab subgroups provide an additional layer of structure to group related repositories together.&lt;/p&gt;

&lt;p&gt;However, a common issue when using Go modules is that they &lt;strong&gt;do not work natively&lt;/strong&gt; with private or internal repositories under a GitLab subgroup (see this &lt;a href=&quot;https://github.com/golang/go/issues/29953&quot;&gt;GitHub issue&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;For example, using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;go get&lt;/code&gt; to retrieve a module from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gitlab.company.com/gitlab-org/subgroup/repo&lt;/code&gt; will result in a failure. This problem is not specific to Go modules, all repositories under the subgroup will face the same issue.&lt;/p&gt;

&lt;h4 id=&quot;a-cumbersome-workaround&quot;&gt;A cumbersome workaround&lt;/h4&gt;

&lt;p&gt;To overcome this issue, we had to use workarounds. One workaround is to authenticate the HTTPS calls to GitLab by adding authentication details to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.netrc&lt;/code&gt; file on your machine.&lt;/p&gt;

&lt;p&gt;The following lines can be added to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.netrc&lt;/code&gt; file:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;machine gitlab.company.com
    login user@company.com
    password &amp;lt;personal-access-token&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In our case, we are using a Personal Access Token (PAT) since we have 2FA enabled. If 2FA is not enabled, the GitLab password can be used instead. However, this approach would mean configuring the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.netrc&lt;/code&gt; file in the CI environments as well as on the machine of &lt;strong&gt;every&lt;/strong&gt; Go developer.&lt;/p&gt;

&lt;h4 id=&quot;solution-athens--netrc&quot;&gt;Solution: Athens + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.netrc&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;A feasible solution is to set up the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.netrc&lt;/code&gt; file in the Go proxy server. This method eliminates the need for N number of developers to configure their own &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.netrc&lt;/code&gt; files. Instead, the responsibility for this task is delegated to the Go proxy server.&lt;/p&gt;

&lt;h3 id=&quot;3-sharing-common-libraries&quot;&gt;3. Sharing common libraries&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Problem summary: Distributing internal common libraries within a monorepo without granting direct repository access can be challenging.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;At Grab, we work with various cross-functional teams, and some could have distinct network access like different VPNs. This adds complexity to sharing our monorepo’s internal common libraries with them. To maintain the security and integrity of our monorepo, we use a Go proxy for controlled access to necessary libraries.&lt;/p&gt;

&lt;p&gt;The key difference between granting direct access to the monorepo via VCS and using a Go proxy is that the former allows users to read everything in the repository, while the latter enables us to grant access only to the specific libraries users need within the monorepo. This approach ensures secure and efficient collaboration across diverse network configurations.&lt;/p&gt;

&lt;h4 id=&quot;without-go-module-proxy&quot;&gt;Without Go module proxy&lt;/h4&gt;

&lt;p&gt;Without Athens, we would need to create a separate repository to store the code we want to share and then use a build system to automatically mirror the code from the monorepo to the public repository.&lt;/p&gt;

&lt;p&gt;This process can be cumbersome and lead to inconsistencies in code versions between the two repositories, ultimately making it challenging to maintain the shared libraries.&lt;/p&gt;

&lt;p&gt;Furthermore, copying code can lead to errors and increase the risk of security breaches by exposing confidential or sensitive information.&lt;/p&gt;

&lt;h4 id=&quot;solution-athens--download-mode-file&quot;&gt;Solution: Athens + Download Mode File&lt;/h4&gt;

&lt;p&gt;To tackle this problem statement, we utilise Athens’ &lt;a href=&quot;https://docs.gomods.io/configuration/download/&quot;&gt;download mode file&lt;/a&gt; feature using an allowlist approach to specify which repositories can be downloaded by users.&lt;/p&gt;

&lt;p&gt;Here’s an example of the Athens download mode config file:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;downloadURL = &quot;https://proxy.golang.org&quot;

mode = &quot;sync&quot;

download &quot;gitlab.company.com/repo/a&quot; {
    mode = &quot;sync&quot;
}

download &quot;gitlab.company.com/repo/b&quot; {
    mode = &quot;sync&quot;
}

download &quot;gitlab.company.com/*&quot; {
    mode = &quot;none&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the configuration file, we specify allowlist entries for each desired repo, including their respective download modes. For example, in the snippet above, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;repo/a&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;repo/b&lt;/code&gt; are allowed (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode = “sync”&lt;/code&gt;), while everything else is blocked using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mode = “none”&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;final-results-1&quot;&gt;Final results&lt;/h4&gt;

&lt;p&gt;By using Athens’ download mode feature in this case, the benefits are clear. Athens provides a secure, centralised place to store Go modules. This approach not only provides consistency but also improves maintainability, as all code versions are managed in one single location.&lt;/p&gt;

&lt;h2 id=&quot;additional-benefits-of-go-proxy&quot;&gt;Additional benefits of Go proxy&lt;/h2&gt;

&lt;p&gt;As we’ve touched upon the impressive results achieved by implementing Athens Go proxy at Grab, it’s crucial to explore the supplementary advantages that accompany this powerful solution.&lt;/p&gt;

&lt;p&gt;These unsung benefits, though possibly overlooked, play a vital role in enriching the overall developer experience at Grab and promoting more robust software development practices:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Module immutability&lt;/strong&gt;: ​​As the software world continues to face issues around changing or &lt;a href=&quot;https://qz.com/646467/how-one-programmer-broke-the-internet-by-deleting-a-tiny-piece-of-code&quot;&gt;disappearing libraries&lt;/a&gt;, Athens serves as a useful tool in mitigating build disruptions by providing immutable storage for copied VCS code. The use of a Go proxy also ensures that builds remain deterministic, improving consistency across our software.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Uninterrupted development&lt;/strong&gt;: Athens allows users to fetch dependencies even when VCS is down, ensuring continuous and seamless development workflows.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Enhanced security&lt;/strong&gt;: Athens offers access control by enabling the blocking of specific packages within Grab. This added layer of security protects our work against potential risks from malicious third-party packages.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Vendor directory removal&lt;/strong&gt;: Athens prepares us for the eventual removal of the &lt;a href=&quot;https://docs.gomods.io/faq/#when-should-i-use-a-vendor-directory-and-when-should-i-use-athens&quot;&gt;vendor directory&lt;/a&gt;, fostering faster workflows in the future.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;p&gt;Since adopting Athens as a Go module proxy, we have observed considerable benefits, such as:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Accelerated Go command operations&lt;/li&gt;
  &lt;li&gt;Reduced infrastructure costs&lt;/li&gt;
  &lt;li&gt;Mitigated VCS load issues&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Moreover, its lesser-known advantages like module immutability, uninterrupted development, enhanced security, and vendor directory transition have also contributed to improved development practices and an enriched developer experience for Grab engineers.&lt;/p&gt;

&lt;p&gt;Today, the straightforward process of exporting three environment variables has greatly influenced our developers’ experience at Grab.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;export GOPROXY=&quot;goproxy.company.com|proxy.golang.org,direct&quot;

export GONOSUMDB=&quot;gitlab.company.com&quot;

export GONOPROXY=&quot;none&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;At Grab, we are always looking for ways to improve and optimise the way we work, so we contribute to open-sourced projects like Athens, where we help with bug fixes. If you are interested in setting up a Go module proxy, do give Athens (&lt;a href=&quot;https://github.com/gomods/athens&quot;&gt;github.com/gomods/athens&lt;/a&gt;) a try!&lt;/p&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to Swaminathan Venkatraman, En Wei Soh, Anuj More, Darius Tan, and Fernando Christyanto for contributing to this project and this article.&lt;/small&gt;&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;
&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Fri, 30 Jun 2023 01:18:00 +0000</pubDate>
        <link>https://engineering.grab.com/go-module-proxy</link>
        <guid isPermaLink="true">https://engineering.grab.com/go-module-proxy</guid>
        
        <category>Engineering</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>PII masking for privacy-grade machine learning</title>
        <description>&lt;p&gt;At Grab, data engineers work with large sets of data on a daily basis. They design and build advanced machine learning models that provide strategic insights using all of the data that flow through the Grab Platform. This enables us to provide a better experience to our users, for example by increasing the supply of drivers in areas where our predictive models indicate a surge in demand in a timely fashion.&lt;/p&gt;

&lt;p&gt;Grab has a mature privacy programme that complies with applicable privacy laws and regulations and we use tools to help identify, assess, and appropriately manage our privacy risks. To ensure that our users’ data are well-protected and avoid any human-related errors, we always take extra measures to secure this data.&lt;/p&gt;

&lt;p&gt;However, data engineers &lt;strong&gt;will still require&lt;/strong&gt; access to actual production data in order to tune effective machine learning models and ensure the models work as intended in production.&lt;/p&gt;

&lt;p&gt;In this article, we will describe how the Grab’s data streaming team (Coban), along with the data platform and user teams, have enforced Personally Identifiable Information (PII) masking on machine learning data streaming pipelines. This ensures that we uphold a high standard and embody a &lt;em&gt;privacy by design&lt;/em&gt; culture, while enabling data engineers to refine their models with sanitised production data.&lt;/p&gt;

&lt;h2 id=&quot;pii-tagging&quot;&gt;PII tagging&lt;/h2&gt;

&lt;p&gt;Data streaming at Grab leverages the Protocol Buffers (&lt;a href=&quot;https://protobuf.dev/&quot;&gt;protobuf&lt;/a&gt;) data format to structure in-transit data. When creating a new stream, developers &lt;strong&gt;must&lt;/strong&gt; describe its fields in a protobuf schema that is then used for serialising the data wherever it is sent over the wire, and deserialising it wherever it is consumed.&lt;/p&gt;

&lt;p&gt;A fictional example schema looks like this (the indexes are arbitrary, but commonly created in sequence):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;message Booking {
  string bookingID = 1;
  int64 creationTime = 2;
  int64 passengerID = 3;
  string passengerName = 4;
  ... truncated output ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Over here, the fourth field &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;passengerName&lt;/code&gt; involves a PII and the data pertaining to that field should never be accessible by any data engineer. Therefore, developers owning the stream must tag that field with a PII label like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import &quot;streams/coban/options/v1/pii.proto&quot;;

message Booking {
  string bookingID = 1;
  int64 creationTime = 2;
  int64 passengerID = 3;
  string passengerName = 4 [(streams.coban.options.v1.pii_type) = PII_TYPE_NAME];
  ... truncated output ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The imported &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pii.proto&lt;/code&gt; library defines the tags for all possible types of PII. In the example above, the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;passengerName&lt;/code&gt; field has not only been flagged as PII, but is also marked as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PII_TYPE_NAME&lt;/code&gt; – a specific type of PII that conveys the names of individuals. This high-level typing enables more flexible PII masking methods, which we will explain later.&lt;/p&gt;

&lt;p&gt;Once the PII fields have been properly identified and tagged, developers need to publish the schema of their new stream into Coban’s Git repository. A Continuous Integration (CI) pipeline described below ensures that all fields describing PII are correctly tagged.&lt;/p&gt;

&lt;p&gt;The following diagram shows this CI pipeline in action.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/pii-masking/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 1 CI pipeline failure due to untagged PII fields&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;When a developer creates a Merge Request (MR) or pushes a new commit to create or update a schema (step 1), the CI pipeline is triggered. It runs an in-house Python script that scans each variable name of the committed schema and tests it against an extensive list of PII keywords that is regularly updated, such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;name&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;address&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;email&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;phone&lt;/code&gt;, etc (step 2). If there is a match and the variable is not tagged with the expected PII label, the pipeline fails (step 3) with an explicit error message in the CI pipeline’s output, similar to this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Field name [Booking.passengerName] should have been marked with type streams.coban.options.v1.pii_type = PII_TYPE_NAME
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There are cases where a variable name in the schema is a partial match against a PII keyword but is legitimately not a PII – for example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;carModelName&lt;/code&gt; is a partial match against &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;name&lt;/code&gt; but does not contain PII data. In this case, the developer can choose to add it to a whitelist to pass the CI.&lt;/p&gt;

&lt;p&gt;However, modifying the whitelist requires approval from the Coban team for verification purposes. Apart from this particular case, the requesting team can autonomously approve their MR in a self-service fashion.&lt;/p&gt;

&lt;p&gt;Now let us look at an example of a successful CI pipeline execution.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/pii-masking/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 2 CI pipeline success and schema publishing&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Fig. 2, the committed schema (step 1) is properly tagged so our in-house Python script is unable to find any untagged PII fields (step 2). The MR is approved by a code owner (step 3), then merged to the master branch of the repository (step 4).&lt;/p&gt;

&lt;p&gt;Upon merging, another CI pipeline is triggered to package the protobuf schema in a Java Archive (JAR) of &lt;a href=&quot;https://docs.scala-lang.org/tour/classes.html&quot;&gt;Scala classes&lt;/a&gt; (step 5), which in turn is stored into a package registry (step 6). We will explain the reason for this in a later section.&lt;/p&gt;

&lt;h2 id=&quot;production-environment&quot;&gt;Production environment&lt;/h2&gt;

&lt;p&gt;With the schemas published and all of their PII fields properly tagged, we can now take a look at the data streaming pipelines.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/pii-masking/image3.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 3 PII flow in the production environment&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In this example, the user generates data by interacting with the Grab superapp and making a booking (step 1). The booking service, compiled with the stream’s schema definition, generates and produces Kafka records for other services to consume (step 2). Among those consuming services are the production machine learning pipelines that are of interest to this article (step 3).&lt;/p&gt;

&lt;p&gt;PII is not masked in this process because it is actually required by the consuming services. For example, the driver app needs to display the passenger’s actual name, so the driver can confirm their identity easily.&lt;/p&gt;

&lt;p&gt;At this part of the process, this is not much of a concern because access to the sacrosanct production environment is highly restricted and monitored by Grab.&lt;/p&gt;

&lt;h2 id=&quot;pii-masking&quot;&gt;PII masking&lt;/h2&gt;

&lt;p&gt;To ensure the security, stability, and privacy of our users, data engineers who need to tune their new machine learning models based on production data are &lt;strong&gt;not granted access&lt;/strong&gt; to the production environment. Instead, they have access to the staging environment, where production data is mirrored and PII is masked.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/pii-masking/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 4 PII masking pipeline from the production environment to the staging environment&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The actual PII masking is performed by an in-house &lt;a href=&quot;https://flink.apache.org/&quot;&gt;Flink&lt;/a&gt; application that resides in the production environment. Flink is a reference framework for data streaming that we use extensively. It is also fault tolerant, with the ability to restart from a checkpoint.&lt;/p&gt;

&lt;p&gt;The Flink application is compiled along with the JAR containing the schema as Scala classes previously mentioned. Therefore, it is able to consume the original data as a regular Kafka consumer (step 1). It then dynamically masks the PII of the consumed data stream, based on the PII tags of the schema (step 2). Ultimately, it produces the sanitised data to the Kafka cluster in the staging environment as a normal Kafka producer (step 3).&lt;/p&gt;

&lt;p&gt;Depending on the kind of PII, there are several methods of masking such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Names and strings of characters&lt;/strong&gt;: They are replaced by consistent &lt;a href=&quot;https://csrc.nist.gov/glossary/term/hash_based_message_authentication_code&quot;&gt;HMAC&lt;/a&gt; (Hash-based message authentication code). A HMAC is a digest produced by a one-way cryptographic hash function that takes a secret key as a parameter. Leveraging a secret key here is a defence against chosen plaintext attacks, i.e. computing the digest of a particular plaintext, like a targeted individual’s name.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numbers and dates&lt;/strong&gt;: Similarly, they are transformed in a consistent manner, by leveraging a random generator that takes the unmasked value as a seed, so that the same PII input consistently produces the same masked output.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that consistency is a recurring pattern. This is because it is a key requirement for certain machine learning models.&lt;/p&gt;

&lt;p&gt;This sanitised data produced to the Kafka cluster in the staging environment is then consumed by the staging machine learning pipelines (step 4). There, it is used by data engineers to tune their models effectively with near real-time production data (step 5).&lt;/p&gt;

&lt;p&gt;The Kafka cluster in the staging environment is secured with authorisation and authentication (see &lt;a href=&quot;/zero-trust-with-kafka&quot;&gt;Zero Trust with Kafka&lt;/a&gt;). This is an extra layer of security in case some PII data inadvertently fall through the cracks of PII tagging, following the defence in depth principle.&lt;/p&gt;

&lt;p&gt;Finally, whenever a new PII-tagged field is added to a schema, the PII masking Flink application needs to be compiled and deployed again. If the schema is not updated, the Flink pipeline is unable to decode this new field when deserialising the stream. Thus, the added field is just dropped and the new PII data does not make it to the staging environment.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;p&gt;For the immediate next steps, we are going to enhance this design with an in-house product based on &lt;a href=&quot;https://aws.amazon.com/macie/&quot;&gt;AWS Macie&lt;/a&gt; to automatically detect the PII that would have fallen through the cracks. Caspian, Grab’s data lake team and one of Coban’s sister teams, has built a service that is already able to detect PII data in relational databases and data lake tables. It is currently being adapted for data streaming.&lt;/p&gt;

&lt;p&gt;In the longer run, we are committed to taking our privacy by design posture to the next level. Indeed, the PII masking described in this article does not prevent a bad actor from retrieving the consistent hash of a particular individual based on their non-PII data. For example, the target might be identifiable by a signature in the masked data set, such as unique food or transportation habits.&lt;/p&gt;

&lt;p&gt;A possible counter-measure could be one or a combination of the following techniques, ordered by difficulty of implementation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Data minimisation&lt;/strong&gt;: Non-essential fields in the data stream should not be mirrored at all. E.g. fields of the data stream that are not required by the data engineers to tune their models. We can introduce a dedicated tag in the schema to flag those fields and instruct the mirroring pipeline to drop them. This is the most straightforward approach.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Differential privacy&lt;/strong&gt;: The mirroring pipeline could introduce some noise in the mirrored data, in a way that would obfuscate the signatures of particular individuals while still preserving the essential statistical properties of the dataset required for machine learning. It happens that Flink is a suitable framework to do so, as it can split a stream into multiple windows and apply computation over those windows. Designing and generalising a logic that meets the objective is challenging though.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PII encryption at source&lt;/strong&gt;: PII could be encrypted by the producing services (like the booking service), and dynamically decrypted where plaintext values are required. However, key management and performance are two tremendous challenges of this approach.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will explore these techniques further to find the solution that works best for Grab and ensures the highest level of privacy for our users.&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;
&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Jun 2023 01:18:00 +0000</pubDate>
        <link>https://engineering.grab.com/pii-masking</link>
        <guid isPermaLink="true">https://engineering.grab.com/pii-masking</guid>
        
        <category>Engineering</category>
        
        <category>Privacy</category>
        
        <category>Data masking</category>
        
        <category>Machine learning</category>
        
        
        <category>Engineering</category>
        
        <category>Security</category>
        
      </item>
    
      <item>
        <title>Performance bottlenecks of Go application on Kubernetes with non-integer (floating) CPU allocation</title>
        <description>&lt;p&gt;Grab’s real-time data platform team, Coban, has been running its stream processing framework on Kubernetes, as detailed in &lt;a href=&quot;/plumbing-at-scale&quot;&gt;Plumbing at scale&lt;/a&gt;. We’ve also written another article (&lt;a href=&quot;/optimally-scaling-kafka-consumer-applications&quot;&gt;Scaling Kafka consumers&lt;/a&gt;) about vertical pod autoscaling (VPA) and the benefits of using it.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In this article, we cover the performance bottlenecks and other issues we came across for Go applications on Kubernetes.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;We noticed CPU throttling issues on some pipelines leading to consumption lag, which meant there was a delay between data production and consumption. This was an issue because the data might no longer be relevant or accurate when it gets consumed. This led to incorrect data-driven conclusions, costly mistakes, and more.&lt;/p&gt;

&lt;p&gt;While debugging this issue, we focused primarily on the SinktoS3 pipeline. It is essentially used for sinking data from Kafka topics to AWS S3. Depending on your requirements, data sinking is primarily for archival purposes and can be used for analytical purposes.&lt;/p&gt;

&lt;h2 id=&quot;investigation&quot;&gt;Investigation&lt;/h2&gt;

&lt;p&gt;After conducting a thorough investigation, we found two main issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Resource throttling&lt;/li&gt;
  &lt;li&gt;Issue with VPA&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;resource-throttling&quot;&gt;Resource throttling&lt;/h3&gt;

&lt;p&gt;We redesigned our SinktoS3 pipeline architecture to concurrently perform the most CPU intensive operations using parallel goroutines (workers). This improved performance and considerably reduced consumer lag.&lt;/p&gt;

&lt;p&gt;But the high-performance architecture needed more intensive resource configuration. As mentioned in &lt;a href=&quot;/optimally-scaling-kafka-consumer-applications&quot;&gt;Scaling kafka consumers&lt;/a&gt;, VPA helps remove manual resource configuration. So, we decided to let the SinktoS3 pipeline run on VPA, but this exposed a new set of problems.&lt;/p&gt;

&lt;p&gt;We tested our hypothesis on one of the highest traffic pipelines with parallel goroutines (workers). When the pipeline was left running on VPA, it tried optimising the resources by slowly reducing from &lt;strong&gt;2.5 cores&lt;/strong&gt; to &lt;strong&gt;2.05 cores&lt;/strong&gt;, and then to &lt;strong&gt;1.94 cores&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;CPU requests dropped from 2.05 cores to 1.94 cores, since the maximum performance can be seen at ~1.7 cores.&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;As you can see from the image above, CPU usage and performance reduced significantly after VPA changed the CPU cores to less than 2. The pipeline ended up with a huge backlog to clear and although it had resources on pod (around 1.94 cores), it did not process any faster and instead, slowed down significantly, resulting in throttling.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image7.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;From the image above, we can see that after VPA scaled the limits of CPU down to 1.94 cores per pod, there was a sudden drop in CPU usage in each of the pods.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image3.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Stream production rate&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;You can see that at 21:00, CPU usage reached a maximum of 80%. This value dropped to around 50% between 10:00 to 12:00, which is our consecutive peak production rate.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image8.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Significant drop in consumption rate from Day_Before&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image6.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Consumer lag in terms of records pending to be consumed and in terms of minutes&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In the image above, we compared this data with trends from previous data, where the purple line indicates the day before. We noticed a significant drop in consumption rate compared to the day before, which resulted in consumer lag. This drop was surprising since we didn’t tweak the application configuration. The only change was done by VPA, which brought the CPU request and limit down to less than 2 cores.&lt;/p&gt;

&lt;p&gt;To revert this change, we redeployed the pipeline by retaining the same application setting but adjusting the minimum VPA limit to 2 cores. This helps to prevent VPA from bringing down the CPU cores below 2. With this simple change, performance and CPU utilisation improved almost instantly.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image5.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;CPU usage percentage jumped back up to ~95%&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Pipeline consumption rate compared to Day_Before&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In the image above, we compared the data with trends from the day before (indicated in purple), where the pipeline was lagging and had a large backlog. You can see that the improved consumption rate was even better than the day before and the application consumed even more records. This is because it was catching up on the backlog from the previous consumer lag.&lt;/p&gt;

&lt;h4 id=&quot;deep-dive-into-the-root-cause&quot;&gt;Deep dive into the root cause&lt;/h4&gt;

&lt;p&gt;This significant improvement just from increasing CPU allocation from 1.94 to 2 cores was unexpected as we had &lt;a href=&quot;http://go.uber.org/automaxprocs&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AUTO-GOMAXPROCS&lt;/code&gt;&lt;/a&gt; enabled in our SPF pipelines and this only uses integer values for CPU.&lt;/p&gt;

&lt;p&gt;Upon &lt;a href=&quot;https://blog.devgenius.io/know-gomaxprocs-before-deploying-your-go-app-to-kubernetes-7a458fb63af1&quot;&gt;further investigation&lt;/a&gt;, we found that the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOMAXPROCS&lt;/code&gt; is useful to control the CPU that golang uses on a kubernetes node when kubernetes Cgroup masks the actual CPU cores of the nodes. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOMAXPROCS&lt;/code&gt; only allocates the requested resources of the pod, hence configuring this value correctly helps the runtime to preallocate the correct CPU resources.&lt;/p&gt;

&lt;p&gt;Without configuring &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOMAXPROCS&lt;/code&gt;, go runtime assumes the node’s entire CPU capacity is available for its execution, which is sub-optimal when we run the Golang application on Kubernetes. Thus, it is important to configure &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOMAXPROCS&lt;/code&gt; correctly so your application pre-allocates the right number of threads based on CPU resources. More details can be found in &lt;a href=&quot;https://blog.devgenius.io/know-gomaxprocs-before-deploying-your-go-app-to-kubernetes-7a458fb63af1&quot;&gt;this article&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let’s look at how Kubernetes resources relate to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GOMAXPROCS&lt;/code&gt; value in the following table:&lt;/p&gt;

&lt;table class=&quot;table&quot; border=&quot;1&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Kubernetes resources&lt;/th&gt;
      &lt;th&gt;GOMAXPROCS value&lt;/th&gt;
      &lt;th&gt;Remarks&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;2.5 core&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Go runtime will just take and utilise 2 cores efficiently.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2 core&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Go runtime will take and utilise the maximum CPU of the pod efficiently if the workload requires it.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1.5 core&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;AUTO-GOMAXPROCS will set the value as &lt;strong&gt;1&lt;/strong&gt; since it rounds down the &lt;strong&gt;non-integer&lt;/strong&gt; CPU value to an integer number. Hence the performance will be the same as if you had 1 core CPU.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0.5 core&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;AUTO-GOMAXPROCS will set the value as &lt;strong&gt;1&lt;/strong&gt; CPU as the minimum allowed value for GOMAXPROCS is &lt;strong&gt;1&lt;/strong&gt;. Here we will see some throttling as Kubernetes will only give 0.5 core but runtime configures itself as it would have 1  hence it will starve for a few CPU cycles.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;issue-with-vpa&quot;&gt;Issue with VPA&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler&quot;&gt;vertical pod autoscaler&lt;/a&gt; enables you to easily scale pods vertically so you don’t have to make manual adjustments. It automatically allocates resources based on usage and allows proper scheduling so that there will be appropriate resources available for each pod. However, in our case, the throttling and CPU starvation issue was because VPA brought resources down to less than 2 cores.&lt;/p&gt;

&lt;p&gt;To better visualise the issue, let’s use an example. Assume that this application needs roughly &lt;strong&gt;1.7 cores&lt;/strong&gt; to perform all its operations without any resource throttling. Let’s see how the VPA journey in this scenario looks like and where it will fail to correctly scale.&lt;/p&gt;

&lt;table class=&quot;table&quot; border=&quot;1&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Timeline&lt;/th&gt;
      &lt;th&gt;VPA recommendation&lt;/th&gt;
      &lt;th&gt;CPU Utilisation&lt;/th&gt;
      &lt;th&gt;AUTO-GOMAXPROCS&lt;/th&gt;
      &lt;th&gt;Remarks&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;T0&lt;/td&gt;
      &lt;td&gt;0.5 core&lt;/td&gt;
      &lt;td&gt;&amp;gt;90%&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Throttled by Kubernetes Cgroup as it does give only 0.5 core.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;T1&lt;/td&gt;
      &lt;td&gt;1 core&lt;/td&gt;
      &lt;td&gt;&amp;gt;90%&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;CPU utilisation will still be &amp;gt;90% as GOMAXPROCS setting for the application remains the same. In reality, it will need even more.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;T2&lt;/td&gt;
      &lt;td&gt;1.2 core&lt;/td&gt;
      &lt;td&gt;&amp;lt;85%&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Since the application actually needs more resources, VPA sets a non-integer value but GOMAXPROCS never utilised that extra resource and continued to throttle. Now, VPA computes that the CPU is underutilised and it won't scale further.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;T3&lt;/td&gt;
      &lt;td&gt;2 core (manual override)&lt;/td&gt;
      &lt;td&gt;80-90%&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Since the application has enough resources, it will perform most optimally without throttling and will have maximum throughput.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;During our investigation, we saw that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AUTO-GOMAXPROCS&lt;/code&gt; sets an integer value (minimum 1). To avoid CPU throttling, we need VPA to propose integer values while scaling.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;https://github.com/kubernetes/autoscaler/releases/tag/vertical-pod-autoscaler-0.13.0&quot;&gt;v0.13 of VPA&lt;/a&gt;, this &lt;a href=&quot;https://github.com/kubernetes/autoscaler/blob/master/vertical-pod-autoscaler/README.md%23using-cpu-management-with-static-policy&quot;&gt;feature&lt;/a&gt; is available but only for Kubernetes versions &lt;strong&gt;≥1.25&lt;/strong&gt; – see #5313 in the image below.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/performance-bottlenecks/image9.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We acknowledge that if we define a default minimum integer CPU value of 1 core for Coban’s stream processing pipelines, it might be excessive for those that only require less than 1 core. So we propose to &lt;strong&gt;only enable&lt;/strong&gt; this default setting for pipelines with heavy resource requirements and require more than 1 core.&lt;/p&gt;

&lt;p&gt;That said, you should make this decision by evaluating your application’s needs. For example, some Coban pipelines still run on VPA with less than one core but they do not experience any lag. As we mentioned earlier  AUTO-GOMAXPROCS would be configured to 1 in this case, still they can catch up with message production rates. However, technically these pipelines are actually throttled and do not perform optimally but these pipelines don’t have consumer lag.&lt;/p&gt;

&lt;p&gt;As we move from single to concurrent goroutine processing, we need more intensive CPU allocation. In the following table, we consider some scenarios where we have a few pipelines with heavy workloads that are not able to catch up with the production rate.&lt;/p&gt;

&lt;table class=&quot;table&quot; border=&quot;1&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Actual CPU requirement&lt;/th&gt;
      &lt;th&gt;VPA recommendation (after upgrade to v0.13)&lt;/th&gt;
      &lt;th&gt;GOMAXPROCS value&lt;/th&gt;
      &lt;th&gt;Remarks&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0.8&lt;/td&gt;
      &lt;td&gt;1 core&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Optimal setting for this pipeline. It should not lag and should utilise the CPU resources optimally via concurrent goroutines.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1.2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;No CPU throttling and no lag. But not very cost efficient.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1.8&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Optimal performance with no lag and cost efficiency.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;learningsconclusion&quot;&gt;Learnings/Conclusion&lt;/h2&gt;

&lt;p&gt;From this experience, we learnt several things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Incorrect GOMAXPROCS configuration can lead to significant throttling and CPU starvation issues.&lt;/li&gt;
  &lt;li&gt;Autoscaling solutions are important, but can only take you so far. Depending on your application needs, manual intervention might still be needed to ensure optimal performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;
&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 23 May 2023 01:18:00 +0000</pubDate>
        <link>https://engineering.grab.com/performance-bottlenecks-go-apps</link>
        <guid isPermaLink="true">https://engineering.grab.com/performance-bottlenecks-go-apps</guid>
        
        <category>Engineering</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>How we improved our iOS CI infrastructure with observability tools</title>
        <description>&lt;p&gt;&lt;small&gt;&lt;em&gt;Note: Timestamps used in this article are in UTC+8 Singapore time, unless stated otherwise.&lt;/em&gt;&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;When we upgraded to Xcode 13.1 in April 2022, we noticed a few issues such as instability of the CI tests and other problems related to the switch to Xcode 13.1. &lt;/p&gt;

&lt;p&gt;After taking a step back, we investigated this issue by integrating some observability tools into our iOS CI development process. This gave us a comprehensive perspective of the entire process, from the beginning to the end of the UITest job. In this article, we share the improvements we made, the insights we gathered, and the impact of these improvements on the overall process and resource utilisation.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;In the following sections, we elaborate the various steps we took to investigate the issues, like unstable CI tests and high CPU utilisation, and the improvements we made to make our iOS CI infrastructure more reliable.&lt;/p&gt;

&lt;h3 id=&quot;analyse-xcode-131-cpu-utilisation&quot;&gt;Analyse Xcode 13.1 CPU utilisation&lt;/h3&gt;

&lt;p&gt;As an iOS developer, we are certain that you have also experienced Spotlight process-related CPU usage problems with Xcode 13.1, which have since been resolved in Xcode 13.2. After investigating, we found that the CPU usage issues were one of the root causes of UITest’s instability and it was something we needed to fix urgently. We decided not to wait for Apple’s update as it would cost us more time to perform another round of migration.&lt;/p&gt;

&lt;p&gt;Before we started UITest, we moved the spotlight.app into a new folder. When the test was complete, we restored the application to its original location. This significantly decreased CPU utilisation by more than 50%.&lt;/p&gt;

&lt;p&gt;This section helps you better visualise how the different versions of Xcode affected CPU utilisation.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/iOS-CI-infrastructure-with-observability-tools/image6.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Xcode 12.1&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/iOS-CI-infrastructure-with-observability-tools/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Xcode 13.1 before fix&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/iOS-CI-infrastructure-with-observability-tools/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Xcode 13.1 after fix&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;remove-ios-safaris-dependency-during-deep-link-testing&quot;&gt;Remove iOS Safari’s dependency during deep link testing&lt;/h3&gt;

&lt;p&gt;As a superapp, there are countless scenarios that need to be thoroughly tested at Grab before the feature is released in production. One of these tests is deep link testing.&lt;/p&gt;

&lt;p&gt;More than 10% of the total number of tests are deep link tests. Typically, it is advised to mock the dependencies throughout the test to ensure that it runs quickly and reliably. However, this creates another reliance on iOS Safari.&lt;/p&gt;

&lt;p&gt;As a result, we created a mock browser in UITest. We used the URL to the mock browser as the launch argument, and the same URL is then called back. This method results in a 20% reduction in CI time and more stable tests.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/iOS-CI-infrastructure-with-observability-tools/image4.gif&quot; alt=&quot;&quot; style=&quot;width:20% ;height:20% &quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;boot-the-ios-simulator-with-permission&quot;&gt;Boot the iOS simulator with permission&lt;/h3&gt;

&lt;p&gt;It is always a good idea to reset the simulator before running UITest so that there are no residual presets or simulated data from a different test. Additionally, using any of the simulator’s services (location, ATT, contacts, etc.) will prompt the simulator to request permission, which slows down execution. We used UIInterruptionHandler (a handler block for managing alerts and other dialogues) to manage asynchronous UI interruptions during the test.&lt;/p&gt;

&lt;p&gt;We wanted to reduce the time taken for test execution, which we knew includes many permissions. Therefore, in order to speed up execution, we boot the simulator with permissions. This removes the need for permissions during UITest, which speeds up performance by 5%.&lt;/p&gt;
&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/iOS-CI-infrastructure-with-observability-tools/image7.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;monitor-http-traffic-during-the-uitest&quot;&gt;Monitor HTTP traffic during the UITest&lt;/h3&gt;

&lt;p&gt;When writing tests, it is important to mock all resources as this enables us to focus on the code that’s being tested and not how external dependencies interact or respond. However, with a large team working concurrently, it can be challenging to ensure that nothing is actually downloaded from the internet.&lt;/p&gt;

&lt;p&gt;Developers often make changes to code, and UITests are essential for ensuring that these modifications do not adversely affect existing functionality. It is advised to mock all dependencies while writing tests to simulate all possible behavior. We discovered that a significant number of resources were being downloaded each time we ran the tests, which was highly inefficient.&lt;/p&gt;

&lt;p&gt;In large teams working simultaneously, preventing downloads from the internet can be quite challenging. To tackle this issue, we devised a custom tool that tracks all URLs accessed throughout the UITest. This enabled us to identify resources being downloaded from the internet during the testing process.&lt;/p&gt;

&lt;p&gt;By using our custom tool to analyse network traffic, we were able to ensure that no resources were being downloaded during testing. Instead, we relied on mocked dependencies, resulting in reduced testing times and improved stability.&lt;/p&gt;

&lt;h3 id=&quot;gitlab-load-runner-analysis&quot;&gt;GitLab load runner analysis&lt;/h3&gt;

&lt;p&gt;At Grab, we have many teams of developers who maintain the app, make code changes, and raise merge requests (MRs) on a daily basis. To make sure that new changes don’t conflict with existing code, these MRs are integrated with CI.&lt;/p&gt;

&lt;p&gt;Additionally, to manage the number of MRs, we maintain a list of clusters that run test runners concurrently for better resource utilisation and performance. We frequently run these tests to determine how many parallel processors are required for stable results.&lt;/p&gt;

&lt;p&gt;####Return HTTP responses to the local mock server&lt;/p&gt;

&lt;p&gt;We have a tool that we use to mock API requests, which we improved to also support HTML responses. This increases the scope of testing and ensures the HTML response sequences work properly.&lt;/p&gt;

&lt;h3 id=&quot;use-explicit-waiting-commands&quot;&gt;Use explicit waiting commands&lt;/h3&gt;

&lt;p&gt;When running multiple tests, timing issues are inevitable and they cause tests to occasionally pass and fail. To mitigate this, most of the developers prefer to add a sleep command so there is time for the element to render properly before we verify it – but this slows down execution. In order to improve CI execution, we introduced a link that allows us to track sleep function usage and suggest developers use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;waitForExistence&lt;/code&gt; wrappers in UI tests.&lt;/p&gt;

&lt;h3 id=&quot;track-each-failure-state&quot;&gt;Track each failure state&lt;/h3&gt;

&lt;p&gt;With large codebases, it is quite common to see flakiness in UITests, where tests occasionally succeed and fail without any code changes. This means that test results can be inconsistent and in some cases, faulty. Faulty testing can be frustrating, and quite expensive. This is because engineers need to re-trigger entire builds, which ends up consuming more time.&lt;/p&gt;

&lt;p&gt;Initially, we used an internal tool that required all tests to pass on the first run, before merging was allowed. However, we realised that this significantly increased engineers’ manual retry time, hence, we modified the rules to allow merging as long as a subsequent retry passes the tests. This minor change improved our engineers’ CI overall experience and did not result in more flaky tests.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;img/iOS-CI-infrastructure-with-observability-tools/image5.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h2 id=&quot;learningsconclusion&quot;&gt;Learnings/Conclusion&lt;/h2&gt;

&lt;p&gt;Our journey to improve iOS CI infrastructure is still ongoing, but from this experience, we learnt several things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Focus on the feature being tested by ensuring all external responses are mocked.&lt;/li&gt;
  &lt;li&gt;A certain degree of test flakiness is expected, but you should monitor past trends. If flakiness increases, there’s probably a deeper lying issue within your code.&lt;/li&gt;
  &lt;li&gt;Regularly monitor resource utilisation and performance – detecting a sudden spike early could save you a lot of time and money.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;
&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 18 May 2023 04:39:00 +0000</pubDate>
        <link>https://engineering.grab.com/iOS-CI-infrastructure-with-observability-tools</link>
        <guid isPermaLink="true">https://engineering.grab.com/iOS-CI-infrastructure-with-observability-tools</guid>
        
        <category>iOS</category>
        
        <category>Mobile</category>
        
        <category>Engineering</category>
        
        <category>UITesting</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>2.3x faster using the Go plugin to replace Lua virtual machine</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We’re excited to share with you the latest update on our open-source project &lt;a href=&quot;https://github.com/kelindar/talaria&quot;&gt;Talaria&lt;/a&gt;. In our efforts to improve performance and overcome infrastructure limitations, we’ve made significant strides by implementing the &lt;a href=&quot;https://pkg.go.dev/plugin&quot;&gt;Go plugin&lt;/a&gt; to replace Lua VM.&lt;/p&gt;

&lt;p&gt;Our team has found that the &lt;a href=&quot;https://pkg.go.dev/plugin&quot;&gt;Go plugin&lt;/a&gt; is roughly 2.3x faster and uses 2.3x less memory than the Lua VM. This significant performance boost has helped us improve overall functionality, scalability, and speed.&lt;/p&gt;

&lt;p&gt;For those who aren’t familiar, Talaria is a distributed, highly available, and low-latency time-series database that’s designed for Big Data systems. &lt;a href=&quot;https://engineering.grab.com/big-data-real-time-presto-talariadb&quot;&gt;Originally developed and implemented at Grab&lt;/a&gt;, Talaria is a critical component in processing millions and millions of transactions and connections every day, which demands scalable, data-driven decision-making.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;
&lt;p&gt;One of the methods we previously used for processing ingested data was &lt;a href=&quot;https://github.com/talariadb/talaria/blob/51560d23faed1c0d8174531142ef3314cfdc86b1/internal/scripting/script_test.go#L14&quot;&gt;Lua script&lt;/a&gt;. This method allowed users to customise the ingestion process, providing a high degree of flexibility.&lt;/p&gt;

&lt;p&gt;The config below is an example of using Lua script to JSON encode the row as a data column:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;computed:
  - name: data
    type: json
    func: |
      local json = require(&quot;json&quot;)
      function main(row)
        return json.encode(row)
      end     
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;
&lt;p&gt;We found that loading a Lua script required launching a Lua virtual machine (VM) to execute the script, which had a significant impact on performance, especially when ingesting large amounts of events.&lt;/p&gt;

&lt;p&gt;This performance issue led us to reevaluate our approach to processing ingested data and make changes to improve Talaria’s performance.&lt;/p&gt;

&lt;p&gt;As a result, this is the code we used on Lua VM to run the trim, remove keys “key1”, “key2”, “key3”, “key4”, “key5”, in the ingested data:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import &quot;github.com/kelindar/lua&quot;

func luaTrim() string {
    s, err := lua.FromString(&quot;test.lua&quot;, `
    local json = require(&quot;json&quot;)
    local keys = {
    &quot;key1&quot;, &quot;key2&quot;, &quot;key3&quot;, &quot;key4&quot;, &quot;key5&quot;,
    }
    function main(input)
        local data = json.decode(input)
        for i, key in ipairs(keys) do
            data[key] = nil
        end
        return json.encode(data)
    end
`)
    if err != nil {
        panic(err)
    }
    result, err := s.Run(context.Background(), jsonstr)
    if err != nil {
        panic(err)
    }
    return result.String()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the benchmark, using Lua VM is 1000 times slower and uses 1000 times more memory than Golang’s native function on a Trim function:&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkTrim-12  &lt;/th&gt;
      &lt;th&gt;543541 &lt;/th&gt;
      &lt;th&gt;2258 ns/op&lt;/th&gt;
      &lt;th&gt;848 B/op&lt;/th&gt;
      &lt;th&gt;12 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkLuaTrim-12 &lt;/th&gt;
      &lt;th&gt;553&lt;/th&gt;
      &lt;th&gt;2105506 ns/op&lt;/th&gt;
      &lt;th&gt;5006319 B/op&lt;/th&gt;
      &lt;th&gt;10335 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
&lt;/table&gt;

&lt;p&gt;But, anything can be improved by adding a cache, what if we cache the Lua VM and reuse them? Here is the new improved benchmark:&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkTrim-8&lt;/th&gt;
      &lt;th&gt;232105 &lt;/th&gt;
      &lt;th&gt;4995 ns/op &lt;/th&gt;
      &lt;th&gt;2192 B/op &lt;/th&gt;
      &lt;th&gt;53 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkLuaTrim-8&lt;/th&gt;
      &lt;th&gt;97536&lt;/th&gt;
      &lt;th&gt;12108 ns/op &lt;/th&gt;
      &lt;th&gt;4573 B/op &lt;/th&gt;
      &lt;th&gt;121 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
&lt;/table&gt;

&lt;p&gt;So we can conclude that Lua VMs are roughly 2.3x faster and use 2.3x less memory than Golang’s native function.&lt;/p&gt;

&lt;h2 id=&quot;use-the-go-plugin-as-lua-vm-to-execute-custom-code&quot;&gt;Use the Go plugin as Lua VM to execute custom code&lt;/h2&gt;
&lt;p&gt;We came up with the idea of using a &lt;a href=&quot;https://developer.ibm.com/tutorials/l-dynamic-libraries/&quot;&gt;Linux shared library&lt;/a&gt; to execute the custom function instead of using Lua VM to run the custom script. Maybe you will be more familiar with the files with suffixes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.so&lt;/code&gt;; they are shared libraries designed to package similar functionality in a single unit and shared with other developers so that they can call the function without writing it again.&lt;/p&gt;

&lt;p&gt;In Golang, a similar idea is called &lt;a href=&quot;https://pkg.go.dev/plugin&quot;&gt;Go plugin&lt;/a&gt;, which allows you to build Golang code as a shared library (Golang names it a plugin). Open this file and call the Go function inside this plugin.&lt;/p&gt;

&lt;h3 id=&quot;how-to-use-the-go-plugin&quot;&gt;How to use the Go plugin&lt;/h3&gt;
&lt;p&gt;Let’s say you have a function F that wants to be called via the plugin.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package main
import &quot;fmt&quot;
func F() { fmt.Printf(&quot;Hello, world&quot;) }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After writing the function F, you can compile it as a Go plugin file f_plugin.so via Go build -buildmode=plugin -o f_plugin.so. And you can open the file and use the function F like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;p, err := plugin.Open(&quot;f_plugin.so&quot;)
if err != nil {
    panic(err)
}
f, err := p.Lookup(&quot;F&quot;)
if err != nil {
    panic(err)
}
f.(func())() // prints &quot;Hello, world&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;go-plugin-benchmark&quot;&gt;Go plugin benchmark&lt;/h3&gt;
&lt;p&gt;Here is the result that compares Golang native function, Golang plugin call.&lt;/p&gt;

&lt;p&gt;Golang native function: 2.3x faster and 2.3x lesser memory than using the Lua VM.
Golang plugin call has almost the same performance as Golang native function.&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkNativeFunctionCall-12&lt;/th&gt;
      &lt;th&gt;2917465 &lt;/th&gt;
      &lt;th&gt;401.7 ns/op &lt;/th&gt;
      &lt;th&gt;200 B/op&lt;/th&gt;
      &lt;th&gt;6 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkPluginCall-12&lt;/th&gt;
      &lt;th&gt;2778988 &lt;/th&gt;
      &lt;th&gt;447.1 ns/op  &lt;/th&gt;
      &lt;th&gt;200 B/op &lt;/th&gt;
      &lt;th&gt;6 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
&lt;/table&gt;

&lt;h3 id=&quot;integrated-into-talaria&quot;&gt;Integrated into Talaria&lt;/h3&gt;
&lt;p&gt;This is the MR we integrated the Go plugin into Talaria: &lt;a href=&quot;https://github.com/talariadb/talaria/pull/87&quot;&gt;https://github.com/talariadb/talaria/pull/87&lt;/a&gt;, adding it as a loader like LuaLoader.&lt;/p&gt;

&lt;p&gt;They both implemented the Handler interfaces.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;type Handler interface {
    Load(uriOrCode string) (Handler, error)
    String() string
    Value(map[string]interface{}) (interface{}, error)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The implementation of this interface is listed here:&lt;/p&gt;

&lt;h4 id=&quot;for-lua-loader&quot;&gt;For Lua loader&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Load&lt;/strong&gt;: Load the Lua code or Lua script file path (local file path or s3 path) as the loader.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;String&lt;/strong&gt;: Return “lua” so that we can call it to get what the loader is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;: Run the Lua script, and take the arg as input.&lt;/p&gt;

&lt;h4 id=&quot;for-go-plugin-loader&quot;&gt;For Go plugin loader&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Load&lt;/strong&gt;: Read the plugin file path (local file path or s3 path) as the plugin, lookup the function name defined by the user, save the function for later use.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;String&lt;/strong&gt;: Return “plugin” so that we can call it to get what the loader is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;: Run the saved function, take the arg as input.&lt;/p&gt;

&lt;h2 id=&quot;things-you-need-to-notice&quot;&gt;Things you need to notice&lt;/h2&gt;
&lt;p&gt;The Go version you used to build the  Golang plugin must be the same as the service used in that plugin. We use Docker to build the service, so that we can ensure the Go version is the same.&lt;/p&gt;

&lt;h2 id=&quot;reference-benchmark-plugin-and-lua&quot;&gt;Reference (Benchmark plugin and LUA)&lt;/h2&gt;
&lt;p&gt;https://github.com/atlas-comstock/talaria_benchmark/tree/master/benchmark_plugin_and_lua&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;
&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 15 May 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/faster-using-the-go-plugin-to-replace-Lua-VM</link>
        <guid isPermaLink="true">https://engineering.grab.com/faster-using-the-go-plugin-to-replace-Lua-VM</guid>
        
        <category>Engineering</category>
        
        <category>Virtual machines</category>
        
        <category>Faster</category>
        
        <category>Go plugin</category>
        
        <category>Lua VM</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Safer deployment of streaming applications</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://flink.apache.org/&quot;&gt;Flink&lt;/a&gt; framework has gained popularity as a real-time stateful stream processing solution for distributed stream and batch data processing. Flink also provides data distribution, communication, and fault tolerance for distributed computations over data streams. To fully leverage Flink’s features, Coban, Grab’s real-time data platform team, has adopted Flink as part of our service offerings.&lt;/p&gt;

&lt;p&gt;In this article, we explore how we ensure that deploying Flink applications remain safe as we incorporate the lessons learned through our &lt;a href=&quot;/our-journey-to-continuous-delivery-at-grab&quot;&gt;journey to continuous delivery&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 1. Flink platform architecture within Coban&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Users interact with our systems to develop and deploy Flink applications in three different ways.&lt;/p&gt;

&lt;p&gt;Firstly, users create a Merge Request (MR) to develop their Flink applications on our Flink Scala repository, according to business requirements. After the MR is merged, GitOps Continuous Integration/Continuous Deployment (CI/CD) automatically runs and dockerises the application, allowing the containerised applications to be deployed easily.&lt;/p&gt;

&lt;p&gt;Secondly, users create another MR to our &lt;a href=&quot;/securing-gitops-pipeline&quot;&gt;infrastructure as a code&lt;/a&gt; repository. The GitOps CI/CD that is integrated with Terraform runs and configures the created Spinnaker application. This process configures the Flink application that will be deployed.&lt;/p&gt;

&lt;p&gt;Finally, users trigger the actual deployment of the Flink applications on Spinnaker, which orchestrates the deployment of the Docker image onto our Kubernetes cluster. Flink applications are deployed as standalone clusters in Grab to ensure resource isolation.&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;

&lt;p&gt;The main issue we noticed with streaming pipelines like these, is that they are often interconnected, where application A depends on application B’s output. This makes it hard to find a solution that perfectly includes integration tests and ensures that propagated changes do not affect downstream applications.&lt;/p&gt;

&lt;p&gt;However, this problem statement is too large to solve with a single solution. As such, we are narrowing the problem statement to focus on ensuring safety of our applications, where engineers can deploy Flink applications that will be rolled back if they fail health checks. In our case, the definition of a Flink application’s health is limited to the uptime of the Flink application itself.&lt;/p&gt;

&lt;p&gt;It is worth noting that Flink applications are designed to be &lt;strong&gt;stateful streaming applications&lt;/strong&gt;, meaning a “state” is shared between events (stream entities) and thus, past events can influence the way current events are processed. This also implies that traditional deployment strategies do not apply to the deployment of Flink applications.&lt;/p&gt;

&lt;h3 id=&quot;current-strategy&quot;&gt;Current strategy&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image3.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 2. Current deployment stages&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Figure 2, our current deployment stages are split into three parts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Delete current deployment&lt;/strong&gt;: Remove current configurations (if applicable) to allow applications to pick up the new configurations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bake (Manifest)&lt;/strong&gt;: Bake the Helm charts with the provided configurations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deploy (Manifest)&lt;/strong&gt;: Deploy the charts onto Kubernetes.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Over time, we learnt that this strategy can be risky. Part 2 can result in a loss of Flink application states due to how internal CI/CD processes are set up. There is also no easy way to rollback if an issue arises. Engineers will need to revert all config changes and rollback the deployment &lt;strong&gt;manually&lt;/strong&gt; by re-deploying the older Docker image – which results in slower operation recovery.&lt;/p&gt;

&lt;p&gt;Lastly, there are no in-built monitoring mechanisms that perform regular health probes. Engineers need to manually monitor their applications to see if their deployment was successful or if they need to perform a rollback.&lt;/p&gt;

&lt;p&gt;With all these issues, deploying Flink applications for engineers are often stressful and fraught with uncertainty. Common mitigation strategies are &lt;em&gt;canary&lt;/em&gt; and &lt;em&gt;blue-green deployments&lt;/em&gt;, which we cover in the next section.&lt;/p&gt;

&lt;h3 id=&quot;canary-deployments&quot;&gt;Canary deployments&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 3. Canary deployment&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In canary deployments, you gradually roll out new versions of the application in parallel with the production version, while serving a percentage of total traffic before promoting it gradually.&lt;/p&gt;

&lt;p&gt;This does not work for Flink deployments due to the nature of stream processing. Applications are frequently required to do streaming operations like stream joining, which involves matching related events in different Kafka topics. So, if a Flink application is only receiving a portion of the total traffic, the data generated will be considered inaccurate due to incomplete data inputs.&lt;/p&gt;

&lt;h3 id=&quot;blue-greendeployments&quot;&gt;Blue-green deployments&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image6.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 4. Blue-green deployment&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Blue-green deployments work by running two versions of the application with a Load Balancer that acts as a traffic switch, which determines which version traffic is directed to.&lt;/p&gt;

&lt;p&gt;This method might work for Flink applications if we only allow one version of the application to consume Kafka messages at any point in time. However, we noticed some issues when switching traffic to another version. For example, the state of both versions will be inconsistent because of the different data traffic each version receives, which complicates the process of switching Kafka consumption traffic.&lt;/p&gt;

&lt;p&gt;So if there’s a failure and we need to rollback from Green to Blue deployment, or vice versa, we will need to take an extra step and ensure that before the failure, the data traffic received is &lt;strong&gt;exactly the same&lt;/strong&gt; for both deployments.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;
&lt;p&gt;As previously mentioned, it is crucial for streaming applications to ensure that at any point in time, only one application is receiving data traffic to ensure data completeness and accuracy. Although employing blue-green deployments can technically fulfil this requirement, the process must be modified to handle state consistency such that both versions have the same starting internal state and receive the &lt;strong&gt;same data traffic&lt;/strong&gt; as each other, if a rollback is needed.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image5.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 5. Visualised deployment flow&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This deployment flow will operate in the following way:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Collect metadata regarding current application&lt;/li&gt;
  &lt;li&gt;Take savepoint and stop the current application&lt;/li&gt;
  &lt;li&gt;Clear up high availability configurations&lt;/li&gt;
  &lt;li&gt;Bake and deploy the new application&lt;/li&gt;
  &lt;li&gt;Monitor application and rollback if the health check fails&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s elaborate on the key changes implemented in this new process.&lt;/p&gt;

&lt;h3 id=&quot;savepointing&quot;&gt;Savepointing&lt;/h3&gt;

&lt;p&gt;Flink’s savepointing feature helps address the issue of state consistency and ensures safer deployments.&lt;/p&gt;

&lt;p&gt;A savepoint in Flink is a snapshot of a Flink application’s state at the point in time. This savepoint allows us to pause the Flink application and restore the application to this snapshot state, if there’s an issue.&lt;/p&gt;

&lt;p&gt;Before deploying a Flink application, we perform a savepoint via the Flink API before killing the current application. This would enable us to save the current state of the Flink application and rollback if our deployment fails – just like how you would do a quick save before attempting a difficult level when playing games. This mechanism ensures that both deployment versions have the same internal state during deployment as they both start from the same savepoint.&lt;/p&gt;

&lt;p&gt;Additionally, this feature allows us to easily handle Kafka offsets since these consumed offsets are stored as part of the savepoint. As Flink manages their own state, they don’t need to rely on Kafka’s consumer offset management. With this savepoint feature, we can ensure that the application receives the same data traffic post rollback and that no messages are lost due to processing on the failed version.&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;

&lt;p&gt;To consistently monitor Flink applications, we can conduct health probes to the respective API endpoints to check if the application is stuck in a restart state or if it is running healthily.&lt;/p&gt;

&lt;p&gt;We also configured our monitoring jobs to wait for a few minutes for the deployment to stabilise before probing it over a defined duration, to ensure that the application is in a stable running state.&lt;/p&gt;

&lt;h3 id=&quot;rollback&quot;&gt;Rollback&lt;/h3&gt;

&lt;p&gt;If the health checks fail, we then perform an automatic rollback. Typically, Flink applications are deployed as a standalone cluster and a rollback involves changes in one of the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Application and Flink configurations&lt;/li&gt;
  &lt;li&gt;Taskmanager or Jobmanager resource provision&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;application-and-flink-configuration-changes&quot;&gt;Application and Flink configuration changes&lt;/h4&gt;

&lt;p&gt;For configuration changes, we leverage the fact that Spinnaker performs versioned deployment of &lt;a href=&quot;https://kubernetes.io/docs/concepts/configuration/configmap/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configmap&lt;/code&gt;&lt;/a&gt; resources. In this case, a rollback simply involves mounting the old &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configmap&lt;/code&gt; back onto the Kubernetes deployment.&lt;/p&gt;

&lt;p&gt;To retrieve the old version of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configmap&lt;/code&gt; mount, we can simply utilise Kubernetes’ rollback mechanisms – Kubernetes updates a deployment by creating a new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replicaset&lt;/code&gt; with an incremental version before attaching it to the current deployment and scaling the previous &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replicaset&lt;/code&gt; to 0. To retrieve previous deployment specs, we just need to list all &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replicasets&lt;/code&gt; related to the deployment and find the previous deployed version, before updating the current deployment to mimic the previous template specifications.&lt;/p&gt;

&lt;p&gt;However, this deployment does not contain the number of replicas of previously configured task managers. Kubernetes does not register the number of replicas as part of deployment configuration as this is a dynamic configuration and might be changed during processing due to auto scaling operations.&lt;/p&gt;

&lt;p&gt;Our Flink applications are deployed as standalone clusters and do not use native or yarn resource providers. Coupled with the fact that Flink has strict resource provision, we realised that we do not have enough information to perform rollbacks, without the exact number of replicas created.&lt;/p&gt;

&lt;h4 id=&quot;taskmanager-or-jobmanager-resource-provision-changes&quot;&gt;Taskmanager or Jobmanager resource provision changes&lt;/h4&gt;

&lt;p&gt;To gather information about resource provision changes, we can simply include the previously configured number of replicas as part of our metadata annotation. This allows us to retrieve it in future during rollback.&lt;/p&gt;

&lt;p&gt;Making this change involves creating an additional step of metadata retrieval to retrieve and store previous deployment states as annotations of the new deployment.&lt;/p&gt;

&lt;h3 id=&quot;impact&quot;&gt;Impact&lt;/h3&gt;

&lt;p&gt;With this solution, the deployment flow on Spinnaker looks like this:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image7.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 6. New deployment flow on Spinnaker&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Engineers no longer need to monitor the deployment pipeline as closely as they get notified of their application’s deployment status via Slack. They only need to interact or take action when they get notified that the different stages of the deployment pipeline are completed.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 7. Slack notifications on deployment status&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;It is also easier to deploy Flink applications since failures and rollbacks are handled automatically. Furthermore, application state management is also automated, which reduces the amount of uncertainties.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;As we work to further improve our deployment pipeline, we will look into extending the capabilities at our monitoring stage to allow engineers to define and configure their own health probes, allowing our deployment configurations to be more extendable.&lt;/p&gt;

&lt;p&gt;Another interesting improvement will be to make this deployment flow seamlessly, ensuring as little downtime as possible by minimising cold start duration.&lt;/p&gt;

&lt;p&gt;Coban also looks forward to pushing more features on our Flink platform to enable our engineers to explore more use cases that utilises real-time data to allow our operations to become auto adaptive and make data-driven decisions.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/&quot;&gt;Flink Savepointing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-master/docs/ops/rest_api/&quot;&gt;Flink API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/%23updating-a-deployment&quot;&gt;Kubernetes rollback&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 02 May 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/safer-flink-deployments</link>
        <guid isPermaLink="true">https://engineering.grab.com/safer-flink-deployments</guid>
        
        <category>Engineering</category>
        
        <category>Deployments</category>
        
        <category>Streaming applications</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Message Center - Redesigning the messaging experience on the Grab superapp</title>
        <description>&lt;p&gt;Since 2016, Grab has been using &lt;a href=&quot;https://www.grab.com/ph/blog/grabchat/&quot;&gt;GrabChat&lt;/a&gt;, a built-in messaging feature to connect our users with delivery-partners or driver-partners. However, as the Grab superapp grew to include more features, the limitations of the old system became apparent. GrabChat could only handle two-party chats because that’s what it was designed to do. To make our messaging feature more extensible for future features, we decided to redesign the messaging experience, which is now called Message Center.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/message-center/image2.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Migrating from the old GrabChat to the new Message Center&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To some, building our own chat function might not be the ideal approach, especially with open source alternatives like &lt;a href=&quot;https://github.com/signalapp&quot;&gt;Signal&lt;/a&gt;. However, Grab’s business requirements introduce some level of complexity, which required us to develop our own solution.&lt;/p&gt;

&lt;p&gt;Some of these requirements include, but are not limited to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Handle multiple user types (passengers, driver-partners, consumers, delivery-partners, customer support agents, merchant-partners, etc.) with custom user interface (UI) rendering logic and behaviour.&lt;/li&gt;
  &lt;li&gt;Enable other Grab backend services to send system generated messages (e.g. your driver is reaching) and customise push notifications.&lt;/li&gt;
  &lt;li&gt;Persist message state even if users uninstall and reinstall their apps. Users should be able to receive undelivered messages even if they were offline for hours.&lt;/li&gt;
  &lt;li&gt;Provide translation options for non-native speakers.&lt;/li&gt;
  &lt;li&gt;Filter profanities in the chat.&lt;/li&gt;
  &lt;li&gt;Allow users to handle group chats. This feature might come in handy in future if there needs to be communication between passengers, driver-partners, and delivery-partners.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution-architecture&quot;&gt;Solution architecture&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/message-center/image3.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Message Center architecture&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The new Message Center was designed to have two components:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Message-center backend: Message processor service that handles logical and database operations.&lt;/li&gt;
  &lt;li&gt;Message-center postman: Message delivery service that can scale independently from the backend service.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This architecture allows the services to be sufficiently decoupled and scale independently. For example, if you have a group chat with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; participants and each message sent results in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; messages being delivered, this architecture would enable message-center postman to scale accordingly to handle the higher load.&lt;/p&gt;

&lt;p&gt;As Grab delivers millions of events a day via the Message Center service, we need to ensure that our system can handle high throughput. As such, we are using Apache Kafka as the low-latency high-throughput event stream connecting both services and Amazon SQS as a redundant delay queue that attempts a retry 10 seconds later.&lt;/p&gt;

&lt;p&gt;Another important aspect for this service is the ability to support low-latency and bi-directional communications from the client to the server. That’s why we chose Transmission Control Protocol (TCP) as the main protocol for client-server communication. Mobile and web clients connect to Hermes, Grab’s TCP gateway service, which then digests the TCP packets and proxies the payloads to Message Center via gRPC. If both recipients and senders are online, the message is successfully delivered in a matter of milliseconds.&lt;/p&gt;

&lt;p&gt;Unlike HTTP, individual TCP packets do not require a response so there is an inherent uncertainty in whether the messages were successfully delivered. Message delivery can fail due to several reasons, such as the client terminating the connection but the server’s connection remaining established. This is why we built a system of acknowledgements (ACKs) between the client and server, which ensures that every event is received by the receiving party.&lt;/p&gt;

&lt;p&gt;The following diagram shows the high-level sequence of events when sending a message.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/message-center/image1.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Events involved in sending a message on Message Center&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Following the sequence of events involved in sending a message and updating its status for the sender from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sending&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sent&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delivered&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read&lt;/code&gt;, the process can get very complicated quickly. For example, the sender will retry the 1302 TCP new message &lt;em&gt;until&lt;/em&gt; it receives a server ACK. Similarly, the server will also keep attempting to send the 1402 TCP message receipt or 1303 TCP message unless it receives a client ACK. With this in mind, we knew we had to give special attention to the ACK implementation, to prevent infinite retries on the client and server, which can quickly cascade to a system-wide failure.&lt;/p&gt;

&lt;p&gt;Lastly, we also had to consider dropped TCP connections on mobile devices, which happens quite frequently. What happens then? Message Center relies on Hedwig, another in-house notification service, to send push notifications to the mobile device when it receives a failed response from Hermes. Message Center also maintains a user-events DynamoDB database, which updates the state of every pending event of the client to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delivered&lt;/code&gt; whenever a client ACK is received.&lt;/p&gt;

&lt;p&gt;Every time the mobile client reconnects to Hermes, it also sends a special TCP message to notify Message Center that the client is back online, and then the server retries sending all the pending events to the client.&lt;/p&gt;

&lt;h2 id=&quot;learningsconclusion&quot;&gt;Learnings/Conclusion&lt;/h2&gt;

&lt;p&gt;With large-scale features like Message Center, it’s important to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Decouple services so that each microservice can function and scale as needed.&lt;/li&gt;
  &lt;li&gt;Understand our feature requirements well so that we can make the best choices and design for extensibility.&lt;/li&gt;
  &lt;li&gt;Implement safeguards to prevent system timeouts, infinite loops, or other failures from cascading to the entire system, i.e. rate limiting, message batching, and idempotent &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eventIDs&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 17 Apr 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/message-center</link>
        <guid isPermaLink="true">https://engineering.grab.com/message-center</guid>
        
        <category>Engineering</category>
        
        <category>GrabChat</category>
        
        <category>Redesign</category>
        
        <category>Messaging</category>
        
        <category>Chat support</category>
        
        
        <category>Engineering</category>
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>Evolution of quality at Grab</title>
        <description>&lt;p&gt;To achieve our vision of becoming the leading superapp in Southeast Asia, we constantly need to balance development velocity with maintaining the high quality of the Grab app. Like most tech companies, we started out with the traditional software development lifecycle (SDLC) but as our app evolved, we soon noticed several challenges like high feature bugs and production issues.  &lt;/p&gt;

&lt;p&gt;In this article, we dive deeper into our quality improvement journey that officially began in 2019, the challenges we faced along the way, and where we stand as of 2022.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image4.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 1 - Software development life cycle (SDLC) sample&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;When Grab first started in 2012, we were using the Agile SDLC (Figure 1) across all teams and features. This meant that every new feature went through the entire process and was &lt;strong&gt;only released&lt;/strong&gt; to app distribution platforms (PlayStore or AppStore) &lt;strong&gt;after&lt;/strong&gt; the quality assurance (QA) team manually tested and signed off on it.&lt;/p&gt;

&lt;p&gt;Over time, we discovered that feature testing took longer, with more bugs being reported and impact areas that needed to be tested. This was the same for regression testing as QA engineers had to manually test each feature in the app before a release. Despite the best efforts of our QA teams, there were still many major and critical production issues reported on our app – the highest numbers were in 2019 (Figure 2).&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image1.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 2 - Critical open production issue (OPI) trend&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This surge in production issues and feature bugs was directly impacting our users’ experience on our app. To directly address the high production issues and slow testing process, we changed our testing strategy and adopted shift-left testing.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.testim.io/blog/shift-left-testing-guide/&quot;&gt;Shift-left testing&lt;/a&gt; is an approach that brings testing forward to the early phases of software development. This means testing can start as early as the planning and design phases.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image2.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 3 - Shift-left testing&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;By adopting shift-left testing, engineering teams at Grab are able to proactively prevent possible defect leakage in the early stages of testing, directly addressing our users’ concerns without delaying delivery times.&lt;/p&gt;

&lt;p&gt;With shift-left testing, we made three significant changes to our SDLC:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Software engineers conduct acceptance testing&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Incorporate Definition of Ready (DoR) and Definition of Done (DoD)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Balanced testing strategy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s dive deeper into how we implemented each change, the challenges, and learnings we gained along the way.&lt;/p&gt;

&lt;h3 id=&quot;software-engineers-conduct-acceptance-testing&quot;&gt;Software engineers conduct acceptance testing&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/acceptance-testing-software-testing/&quot;&gt;Acceptance testing&lt;/a&gt; determines whether a feature satisfies the defined acceptance criteria, which helps the team evaluate if the feature fulfills our consumers’ needs. Typically, acceptance testing is done after development. But our QA engineers still discovered many bugs and the cost of fixing bugs at this stage is more expensive and time-consuming. We also realised that the most common root causes of bugs were associated with insufficient requirements, vague details, or missing test cases.&lt;/p&gt;

&lt;p&gt;With shift-left testing, QA engineers start writing test cases before development starts and these acceptance tests will be executed by the software engineers during development. Writing acceptance tests early helps identify potential gaps in the requirements before development begins. It also prevents possible bugs and streamlines the testing process as engineers can find and fix bugs even before the testing phase. This is because they can execute the test cases directly during the development stage.&lt;/p&gt;

&lt;p&gt;On top of that, QA and Product managers also made &lt;strong&gt;Given/When/Then (GWT)&lt;/strong&gt; the standard for acceptance criteria and test cases, making them easier for all stakeholders to understand.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;table border=&quot;1&quot;&gt;
  &lt;tr&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;Step by Step style&lt;/th&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;GWT format&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 20px&quot;&gt;&lt;ol&gt;&lt;li&gt;Open the Grab app&lt;/li&gt;&lt;li&gt;Navigate to home feed&lt;/li&gt;&lt;li&gt;Tap on merchant entry point card&lt;/li&gt;&lt;li&gt;Check that merchant landing page is shown&lt;/li&gt;&lt;/ol&gt;&lt;/td&gt;
    &lt;td style=&quot;padding: 20px&quot;&gt;Given user opens the app &lt;br /&gt;And user navigates to the home feed&lt;br /&gt;When the user taps on the merchant entry point card&lt;br /&gt;Then the user should see the merchant’s landing page&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;br /&gt;
By enabling software engineers to conduct acceptance testing, we minimised back-and-forth discussions within the team regarding bug fixes and also, influenced a significant shift in perspective – quality is everyone’s responsibility.&lt;/p&gt;

&lt;p&gt;Another key aspect of shift-left testing is for teams to agree on a standard of quality in earlier stages of the SDLC. To do that, we started incorporating Definition of Ready (DoR) and Definition of Done (DoD) in our tasks.&lt;/p&gt;

&lt;h3 id=&quot;incorporate-definition-of-ready-dor-and-definition-of-done-dod&quot;&gt;Incorporate Definition of Ready (DoR) and Definition of Done (DoD)&lt;/h3&gt;

&lt;p&gt;As mentioned, quality checks can be done before development even begins and can start as early as backlog grooming and sprint planning. The team needs to agree on a standard for work products such as requirements, design, engineering solutions, and test cases. Having this alignment helps reduce the possibility of unclear requirements or misunderstandings that may lead to re-work or a low-quality feature.&lt;/p&gt;

&lt;p&gt;To enforce consistent quality of work products, everyone in the team should have access to these products and should follow DoRs and DoDs as standards in completing their tasks.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;DoR&lt;/strong&gt;: Explicit criteria that an epic, user story, or task must meet before it can be accepted into an upcoming sprint. &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DoD&lt;/strong&gt;: List of criteria to fulfill before we can mark the epic, user story, or task complete, or the entry or exit criteria for each story state transitions. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Including DoRs and DoDs have proven to improve delivery pace and quality. One of the first teams to adopt this observed significant improvements in their delivery speed and app quality – consistently delivering over 90% of task commitments, minimising technical debt, and reducing manual testing times.&lt;/p&gt;

&lt;p&gt;Unfortunately, having these two changes alone were not sufficient – testing was still manually intensive and time consuming. To ease the load on our QA engineers, we needed to develop a balanced testing strategy.  &lt;/p&gt;

&lt;h3 id=&quot;balanced-testing-strategy&quot;&gt;Balanced testing strategy&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image3.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 4 - Test automation strategy&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Our initial automation strategy only included unit testing, but we have since enhanced our testing strategy to be more balanced.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unit testing&lt;/li&gt;
  &lt;li&gt;UI component testing&lt;/li&gt;
  &lt;li&gt;Backend integration testing&lt;/li&gt;
  &lt;li&gt;End-to-End (E2E) testing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Simply having good coverage in one layer does not guarantee good quality of an app or new feature. It is important for teams to test vigorously with different types of testing to ensure that we cover all possible scenarios before a release.&lt;/p&gt;

&lt;p&gt;As you already know, unit tests are written and executed by software engineers during the development phases. Let’s look at what the remaining three layers mean.&lt;/p&gt;

&lt;h4 id=&quot;ui-component-testing&quot;&gt;UI component testing&lt;/h4&gt;

&lt;p&gt;This type of testing focuses on individual components within the application and is useful for testing specific use cases of a service or feature. To reduce manual effort from QA engineers, teams started exploring automation and introduced a mobile testing framework for &lt;a href=&quot;https://applitools.com/learn/concepts/component-testing/&quot;&gt;component testing&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This UI component testing framework used mocked API responses to test screens and interactions on the elements. These UI component tests were automatically executed whenever the pipeline was run, which helped to reduce manual regression efforts. With shift-left testing, we also revised the DoD for new features to include at least 70% coverage of UI component tests.&lt;/p&gt;

&lt;h4 id=&quot;backend-integration-testing&quot;&gt;Backend integration testing&lt;/h4&gt;

&lt;p&gt;Backend integration testing is especially important if your application regularly interacts with backend services, much like the Grab app. This means we need to ensure the quality and stability of these backend services. Since Grab started its journey toward becoming a superapp, more teams started performing backend integration tests like API integration tests.&lt;/p&gt;

&lt;p&gt;Our backend integration tests also covered positive and negative test cases to determine the happy and unhappy paths. At the moment, majority of Grab teams have complete test coverage for happy path use cases and are continuously improving coverage for other use cases.&lt;/p&gt;

&lt;h4 id=&quot;end-to-end-e2e-testing&quot;&gt;End-to-End (E2E) testing&lt;/h4&gt;

&lt;p&gt;E2E tests are important because they simulate the entire user experience from start to end, ensuring that the system works as expected. We started exploring E2E testing frameworks, from as early as 2015, to automate tests for critical services like logging in and booking a ride.&lt;/p&gt;

&lt;p&gt;But as Grab introduced more services, off-the-shelf solutions were no longer a viable option, as we noticed issues like automation limitations and increased test flakiness. We needed a framework that is compatible with existing processes, stable enough to reduce flakiness, scalable, and easy to learn.&lt;/p&gt;

&lt;p&gt;With this criteria in mind, our QA engineering teams built an internal E2E framework that could make API calls, test different account-based scenarios, and provide many other features. Multiple pilot teams have started implementing tests with the E2E framework, which has helped to reduce regression efforts. We are continuously improving the framework by adding new capabilities to cover more test scenarios.&lt;/p&gt;

&lt;p&gt;Now that we’ve covered all the changes we implemented with shift-left testing, let’s take a look at how this changed our SDLC.&lt;/p&gt;

&lt;h2 id=&quot;impact&quot;&gt;Impact&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image6.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 5 - Updated SDLC process&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Since the implementation of shift-left testing, we have improved our app quality without compromising our project delivery pace. Compared to 2019, we observed the following improvements within the Grab superapp in 2022:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Production issues with “Major and Critical” severity bugs found in production were &lt;strong&gt;reduced by 60%&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Bugs found in development phase with “Major and Critical” severity were &lt;strong&gt;reduced by 40%&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;Through this journey, we recognise that there’s no such thing as a bug-free app – no matter how much we test, production issues still happen occasionally. To minimise the occurrence of bugs, we’re regularly conducting root cause analyses and writing postmortem reports for production incidents. These allow us to retrospect with other teams and come up with corrective actions and prevention plans. Through these continuous learnings and improvements, we can continue to shape the future of the Grab superapp.&lt;/p&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to Sori Han for designing the images in this article.&lt;/small&gt;&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Fri, 31 Mar 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/evolution-of-quality</link>
        <guid isPermaLink="true">https://engineering.grab.com/evolution-of-quality</guid>
        
        <category>Engineering</category>
        
        <category>Technology stack</category>
        
        <category>Exploration</category>
        
        
        <category>Engineering</category>
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>How OVO determined the right technology stack for their web-based projects</title>
        <description>&lt;p&gt;In the current technology landscape, startups are developing rapidly. This usually leads to an increase in the number of engineers in teams, with the goal of increasing the speed of product development and delivery frequency. However, this growth often leads to a diverse selection of technology stacks being used by different teams within the same organisation.&lt;/p&gt;

&lt;p&gt;Having different technology stacks within a team could lead to a bigger problem in the future, especially if documentation is not well-maintained. The best course of action is to pick just one technology stack for your projects, but it begs the question, &lt;strong&gt;“How do I choose the best technology stack for my projects?”&lt;/strong&gt;. &lt;/p&gt;

&lt;p&gt;One such example is OVO, which is an Indonesian payments, rewards, and financial services platform within Grab. We share our process and analysis to determine the best technology stack that complies with precise standards. By the end of the article, you may also learn to choose the best technology stack for your needs.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;In recent years, we have seen massive growth in modern web technologies, such as React, Angular, Vue, Svelte, Django, TypeScript, and many more. Each technology has its benefits. However, having so many choices can be confusing when you must determine which technologies are best for your projects. To narrow down the choices, a few aspects, such as scalability, stability, and usage in the market, must be considered.&lt;/p&gt;

&lt;p&gt;That’s the problem that we used to face. Most of our legacy services were not standardised and were written in different languages like PHP, React, and Vue. Also, the documentation for these legacy services is not well-structured or regularly updated.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image1.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Current technology stack usage in OVO&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We realised that we had &lt;strong&gt;two&lt;/strong&gt; main problems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Various technology stacks&lt;/strong&gt; (PHP, Vue, React, Nuxt, and Go) maintained simultaneously, with incomplete documentation, may consume a lot of time to understand the code, especially for engineers unfamiliar with the frameworks or even a new hire.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Context switching&lt;/strong&gt; when reviewing code makes it hard to review other teammates’ merge requests on complex projects and quickly offer better code suggestions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To prevent these problems from recurring, teams must use &lt;strong&gt;one primary technology stack&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;After detailed comparisons, we narrowed our choices to &lt;strong&gt;two&lt;/strong&gt; options – React and Vue – because we have developed projects in both technologies and already have the user interface (UI) library in each technology stack.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image4.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Taken from &lt;a href=&quot;https://www.ulam.io/blog/react-vs-vue-framework-comparison&quot;&gt;ulam.io&lt;/a&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Next, we conducted a more detailed research and exploration for each technology. The main goals were to find the unique features, scalability, ease of migration, and compatibility for the UI library for React and Vue. To test the compatibility of each UI library, we also used a sample UI on one of our upcoming projects and sliced it.&lt;/p&gt;

&lt;p&gt;Here’s a quick summary of our exploration:&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;
&lt;tr&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;Metrics&lt;/th&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;Vue&lt;/th&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;React&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;UI Library Compatibility&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Doesn’t require much component development&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Doesn’t require much component development&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Scalability&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Easier to upgrade, slower in releasing major updates, clear migration guide&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Quicker release of major versions, supports gradual updates&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Others&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Composition API, strong community (&lt;a href=&quot;https://vue-community.org/&quot;&gt;Vue Community&lt;/a&gt;)&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Latest version (v18) of React gradual updates, doesn’t support IE&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
From this table, we found that the differences between these frameworks are miniscule, making it tough for us to determine which to use. Ultimately, we decided to step back and see the &lt;strong&gt;Big Why&lt;/strong&gt;. &lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;The Big Why here was “Why do we need to standardise our technology stack?”. We wanted to ease the onboarding process for new hires and reduce the complexity, like context switching, during code reviews, which ultimately saves time.&lt;/p&gt;

&lt;p&gt;As Kleppmann (2017) states, &lt;em&gt;“The majority of the cost of software is in its ongoing maintenance”&lt;/em&gt;. In this case, the biggest cost was time. Increasing the ease of maintenance would reduce the cost, so we decided to use maintainability as our north star metric.&lt;/p&gt;

&lt;p&gt;Kleppmann (2017) also highlighted &lt;strong&gt;three design principles&lt;/strong&gt; in any software system:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Operability&lt;/em&gt;: Make it easy to keep the system running.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Simplicity&lt;/em&gt;: Easy for new engineers to understand the system by minimising complexity.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Evolvability&lt;/em&gt;: Make it easy for engineers to make changes to the system in the future.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Keeping these design principles in mind, we defined &lt;strong&gt;three metrics&lt;/strong&gt; that our selected tech stack must achieve:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Scalability&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Keeping software and platforms up to date&lt;/li&gt;
      &lt;li&gt;Anticipating possible future problems&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Stability of the library and documentation&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Establishing good practices and tools for development&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Usage in the market&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;The popularity of the library or framework and variety of coding best practices&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;table border=&quot;1&quot;&gt;
  &lt;tr&gt;
    &lt;th style=&quot;padding: 20px&quot;&gt;Metrics&lt;/th&gt;
    &lt;th style=&quot;padding: 20px&quot;&gt;Vue&lt;/th&gt;
    &lt;th style=&quot;padding: 20px&quot;&gt;React&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Scalability&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;&lt;strong&gt;Framework&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;Operability&lt;/strong&gt;&lt;br /&gt;Easier to update because there aren’t many approaches to writing Vue.&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;Evolvability&lt;/strong&gt;&lt;br /&gt;Since Vue is a framework, it needs fewer steps to upgrade.&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;&lt;strong&gt;Library&lt;/strong&gt;&lt;br /&gt;Supports gradual updates but there will be many different approaches when upgrading React on our services.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Stability of the library and documentation&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Has standardised documentation&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Has many versions of documentation&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Usage on Market&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Smaller market share.&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;Simplicity&lt;/strong&gt;&lt;br /&gt;We can reduce complexity for new hires, as the Vue standard in OVO remains consistent with standards in other companies.&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Larger &lt;a href=&quot;https://www.statista.com/statistics/1124699/worldwide-developer-survey-most-used-frameworks-web/&quot;&gt;market share&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;    Many React variants are currently in the market, so different companies may have different folder structures/conventions.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;/table&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image3.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Screenshot taken from &lt;a href=&quot;https://www.statista.com/&quot;&gt;https://www.statista.com/&lt;/a&gt; on 2022-10-13&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;After conducting a detailed comparison between Vue and React, we decided to use Vue as our primary tech stack as it best aligns with Kleppmann’s three design principles and our north star metric of maintainability. Even though we noticed a few disadvantages to using Vue, such as smaller market share, we found that Vue is still the better option as it complies with all our metrics.&lt;/p&gt;

&lt;p&gt;Moving forward, we will only use one tech stack across our projects but we decided not to migrate technology for existing projects. This allows us to continue &lt;strong&gt;exploring&lt;/strong&gt; and &lt;strong&gt;learning&lt;/strong&gt; about other technologies’ developments. One of the things we need to do is ensure that our current projects are kept up-to-date.&lt;/p&gt;

&lt;h3 id=&quot;implementation&quot;&gt;Implementation&lt;/h3&gt;

&lt;p&gt;After deciding on the primary technology stack, we had to do the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define a boilerplate for future Vue projects, which will include items like a &lt;strong&gt;general library or dependencies&lt;/strong&gt;, &lt;strong&gt;implementation for unit testing&lt;/strong&gt;, and &lt;strong&gt;folder structure&lt;/strong&gt;, to align with our north star metric.&lt;/li&gt;
  &lt;li&gt;Update our existing &lt;strong&gt;UI library&lt;/strong&gt; with new components and the latest Vue version.&lt;/li&gt;
  &lt;li&gt;Perform periodic upgrades to existing React services and create a standardised code structure with proper documentation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With these practices in place, we can ensure that future projects will be standardised, making them easier for engineers to maintain.&lt;/p&gt;

&lt;h3 id=&quot;impact&quot;&gt;Impact&lt;/h3&gt;

&lt;p&gt;There are a few key benefits of standardising our technology stack.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scalability and maintainability&lt;/strong&gt;: It’s much easier to scale and maintain projects using the same technology stack. For example, when implementing security patches on all projects due to certain vulnerabilities in the system or libraries, we will need one patch for each technology. With only one stack, we only need to implement one patch across all projects, saving a lot of time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Faster onboarding process&lt;/strong&gt;: The onboarding process is simplified for new hires because we have standardisation between all services, which will minimise the amount of context switching and lower the learning curve.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Faster deliveries&lt;/strong&gt;: When it’s easier to implement a change, there’s a compounding impact where the delivery process is shortened and release to production is quicker. Ultimately, faster deliveries of a new product or feature will help increase revenue.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;learningsconclusion&quot;&gt;Learnings/Conclusion&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image2.jpg&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;For every big decision, it is important to take a step back and understand the Big Why or the main motivation behind it, in order to remain objective. That’s why after we identified maintainability as our north star metric, it was easier to narrow down the choices and make detailed comparisons.&lt;/p&gt;

&lt;p&gt;The north star metric, or deciding factor, might differ vastly, but it depends on the problems you are trying to solve.&lt;/p&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Note: The OVO web team conducted this research in 2022 and was accurate at the time of publishing. The information here may only be applicable to the OVO web team.&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Kleppmann, M. (2017). Designing Data-Intensive Applications. Beijing: O’Reilly. ISBN: 978-1-4493-7332-0&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.statista.com/statistics/1124699/worldwide-developer-survey-most-used-frameworks-web/&quot;&gt;Most used web frameworks 2022 - Statista&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Mar 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/determining-tech-stack</link>
        <guid isPermaLink="true">https://engineering.grab.com/determining-tech-stack</guid>
        
        <category>Engineering</category>
        
        <category>Technology stack</category>
        
        <category>Exploration</category>
        
        
        <category>Engineering</category>
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>Migrating from Role to Attribute-based Access Control</title>
        <description>&lt;p&gt;Grab has always regarded security as one of our top priorities; this is especially important for data platform teams. We need to control access to data and resources in order to protect our consumers and ensure compliance with various, continuously evolving security standards.&lt;/p&gt;

&lt;p&gt;Additionally, we want to keep the process convenient, simple, and easily scalable for teams. However, as Grab continues to grow, we have more services and resources to manage and it becomes increasingly difficult to keep the process frictionless. That’s why we decided to move from Role-Based Access Control (RBAC) to Attribute-Based Access Control (ABAC) for our Kafka Control Plane (KCP).&lt;/p&gt;

&lt;p&gt;In this article, you will learn how Grab’s streaming data platform team (Coban) deleted manual role and permission management of hundreds of roles and resources, and reduced operational overhead of requesting or approving permissions to zero by moving from RBAC to ABAC.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Kafka is widely used across Grab teams as a streaming platform. For decentralised Kafka resource (e.g. topic) management, teams have the right to create, update, or delete based on their needs. As the data platform team, we implemented a KCP to ensure that these operations are only performed by authorised parties, especially on multi-tenant Kafka clusters.&lt;/p&gt;

&lt;p&gt;For internal access management, Grab uses its own Identity and Access Management (IAM) service, based on RBAC, to support authentication and authorisation processes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; verifies the identity of a user or service, for example, if the provided token is valid or expired.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Authorisation&lt;/strong&gt; determines their access rights, for example, whether users can only update and/or delete their own Kafka topics.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In RBAC, roles, permissions, actions, resources, and the relationships between them need to be defined in the IAM service. They are used to determine whether a user can access a certain resource.&lt;/p&gt;

&lt;p&gt;In the following example, we can see how IAM concepts come together. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coban engineer&lt;/code&gt; role belongs to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Engineering-coban&lt;/code&gt; group and has permission to update the topic’s retention. Any engineer added to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Engineering-coban&lt;/code&gt; group will also be able to update the topic’s retention.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image5.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Following the same concept, each team using the KCP has its own roles, permissions, and resources created in the system. However, there are some disadvantages to this approach:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It leads to a significant growth in the number of access control artifacts both platform and user teams need to manage, and increased time and effort to debug access control issues. We start off by finding which group the engineer belongs to and locating the group that should be used for KCP, and then trace to role and permissions.&lt;/li&gt;
  &lt;li&gt;All group membership access requests of new joiners need to be reviewed and approved by their direct managers. This leads to a lot of backlog as new joiners might have multiple groups to join and managers might not be able to review them timely. In some cases, roles need to be re-applied or renewed every 90 days, which further adds to the delay.&lt;/li&gt;
  &lt;li&gt;Group memberships are not updated to reflect active members in the team, leaving some engineers with access they don’t need and others with access they should have but don’t.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;With ABAC, access management becomes a lot easier. Any new joiner to a specific team gets the same access rights as everyone on that team – no need for manual approval from a manager. However, for ABAC to work, we need these components in place:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;User attributes: Who is the subject (actor) of a request?&lt;/li&gt;
  &lt;li&gt;Resource attributes: Which object (resource) does the actor want to deal with?&lt;/li&gt;
  &lt;li&gt;Evaluation engine: How do we decide if the actor is allowed to perform the action on the resource?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;User attributes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All users have certain attributes depending on the department or team they belong to. This data is then stored and synced automatically with the human resource management system (HRMS) tool, which acts as a source of truth for Grab-wide data, every time a user switches teams, roles, or leaves the company.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resource attributes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Resource provisioning is an authenticated operation. This means that KCP knows who sent the requests and what each request/action is about. Similarly, resource attributes can be derived from their creators. For new resource provisioning, it is possible to capture the resource tags and store them after authentication. For existing resources, a major challenge was the need to backfill the tagging and ensure a seamless transition from the user’s perspective. In the past, all resource provisioning operations were done by a centralised platform team and most of the existing resource attributes are still under platform team’s ownership.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Evaluation engine&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We chose to use &lt;a href=&quot;https://www.openpolicyagent.org/&quot;&gt;Open Policy Agent&lt;/a&gt; (OPA) as our policy evaluation engine mainly for its wide community support, applicable feature set, and extensibility to other tools and platforms in our system. This is also currently used by our team for &lt;a href=&quot;/zero-trust-with-kafka&quot;&gt;Kafka authorisation&lt;/a&gt;. The policies are written in &lt;a href=&quot;https://www.openpolicyagent.org/docs/latest/policy-language/&quot;&gt;Rego&lt;/a&gt;, the default language supported by OPA.&lt;/p&gt;

&lt;h2 id=&quot;architectureand-implementation&quot;&gt;Architecture and implementation&lt;/h2&gt;

&lt;p&gt;With ABAC, the access control process looks like this:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image6.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;user-attributes&quot;&gt;User attributes&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image4.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Authentication is handled by the IAM service. In the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/generate_token&lt;/code&gt; call, a user requests an authentication token from KCP before calling an authenticated endpoint. KCP then calls IAM to generate a token and returns it to the user.&lt;/p&gt;

&lt;p&gt;In the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/create_topic&lt;/code&gt; call, the user includes the generated token in the request header. KCP takes the token and verifies the token validity with IAM. User attributes are then extracted from the token payload for later use in request authorisation.&lt;/p&gt;

&lt;p&gt;Some of the common attributes we use for our policy are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;user identifier&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;department code&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;team code&lt;/code&gt;, which provide details like a user’s department and work scope.&lt;/p&gt;

&lt;p&gt;When it comes to data governance and central platform and identity teams, one of the major challenges was standardising the set of attributes to be used for clear and consistent ABAC policies across platforms so that their lifecycle and changes could be governed. This was an important shift in the mental model for attribute management over the RBAC model.&lt;/p&gt;

&lt;h4 id=&quot;resource-attributes&quot;&gt;Resource attributes&lt;/h4&gt;

&lt;p&gt;For newly created resources, attributes will be derived from user attributes that are captured during the authentication process.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image3.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Previously with RBAC, existing resources did not have the required attributes. Since migrating to ABAC, the implementation has tagged newly created resources and ensured that their attributes are up to standard. IAM was also still doing the actual authorisation using RBAC.&lt;/p&gt;

&lt;p&gt;It is also important to note that we collaborated with data governance teams to backfill Kafka resource ownership. Having accurate ownership of resources like data lake or Kafka topics enabled us to move toward a self-service model and remove bottlenecks from centralised platform teams.&lt;/p&gt;

&lt;p&gt;After identifying most of the resource ownership, we started switching over to ABAC. The transition was smooth and had no impact on user experience. The remaining unidentified resources were tagged to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lost-and-found&lt;/code&gt; and could be reclaimed by service teams when they needed permission to manage them.&lt;/p&gt;

&lt;h4 id=&quot;open-policy-agent&quot;&gt;Open Policy Agent&lt;/h4&gt;

&lt;p&gt;The most common question when implementing the policy is “how do you define ownership by attributes?”. With respect to the principle of least privilege, each policy must be sufficiently strict to limit access to only the relevant parties. In the end, we aligned as an organisation on defining ownership by department and team.&lt;/p&gt;

&lt;p&gt;We created a simple example below to demonstrate how to define a policy:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package authz

import future.keywords

default allow = false

allow if {
        input.endpoint == &quot;updateTopic&quot;
        is_owner(input.resource_attributes)
}

is_owner(md) if {
        md.department == input.user_attributes.department
        md.team == input.user_attributes.team
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this example, we start with denying access to everyone. If the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;updateTopic&lt;/code&gt; endpoint is called and the department and team attributes between user and resource are matched, access is allowed.&lt;/p&gt;

&lt;p&gt;With a similar scenario, we would need 1 role, 1 action, 1 resource, and 1 mapping (a.k.a permission) between action and resource. We will need to keep adding resources and permissions when we have new resources created. Compared to the policy above, no other changes are required.&lt;/p&gt;

&lt;p&gt;With ABAC, there are no further setup or access requests needed when a user changes teams. The user will be tagged to different attributes, automatically granted access to the new team’s resources, and excluded from the previous team’s resources.&lt;/p&gt;

&lt;p&gt;Another consideration we had was making sure that the policy is well-written and transparent in terms of change history. We decided to include this as part of our application code so every change is accounted for in the unit test and review process.&lt;/p&gt;

&lt;h4 id=&quot;authorisation&quot;&gt;Authorisation&lt;/h4&gt;

&lt;p&gt;The last part of the ABAC process is authorisation logic. We added the logic to the middleware so that we could make a call to OPA for authorisation.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image2.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To ensure token validity after authentication, KCP extracts user attributes from the token payload and fetches resource attributes from the resource store. It combines the request metadata such as method and endpoint, along with the user and resource attributes into an OPA request. OPA then evaluates the request based on the redefined policy above and returns a response.&lt;/p&gt;

&lt;h2 id=&quot;auditability&quot;&gt;Auditability&lt;/h2&gt;

&lt;p&gt;For ABAC authorisation, there are two key areas of consideration:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Who made changes to the policy, who deployed, and when the change was made&lt;/li&gt;
  &lt;li&gt;Who accessed what resource and when&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We manage policies in a dedicated GitLab repository and changes are submitted via merge requests. Based on the commit history, we can easily tell who made changes, reviewed, approved, and deployed the policy. &lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image1.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;For resource access, OPA produces a decision log containing user attributes, resource attributes, and the authorisation decision for every call it serves. The log is kept for five days in Kibana for debugging purposes, then moved to S3 where it is kept for 28 days.&lt;/p&gt;

&lt;h2 id=&quot;impact&quot;&gt;Impact&lt;/h2&gt;

&lt;p&gt;The move to ABAC authorisation has improved our controls as compared to the previous RBAC model, with the biggest impact being fewer resources to manage. Some other benefits include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Optimised resource allocation: Discarded over 200 roles, 200 permissions, and almost 3000 unused resources from IAM services, simplifying our debugging process. Now, we can simply check the user and resource attributes as needed.&lt;/li&gt;
  &lt;li&gt;Simplified resource management: In the three months we have been using ABAC, about 600 resources have been added without any increase in complexity for authorisation, which is significantly lesser than the RBAC model.&lt;/li&gt;
  &lt;li&gt;Reduction in delays and waiting time: Engineers no longer have to wait for approval for KCP access.&lt;/li&gt;
  &lt;li&gt;Better governance over resource ownership and costs: ABAC allowed us to have a standardised and accurate tagging system of almost 3000 resources.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;learnings&quot;&gt;Learnings&lt;/h2&gt;

&lt;p&gt;Although ABAC does provide significant improvements over RBAC, it comes with its own caveats:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It needs a reliable and comprehensive attribute tagging system to function properly. This only became possible after roughly three months of identifying and tagging the ownership of existing resources by both automated and manual methods.&lt;/li&gt;
  &lt;li&gt;Tags should be kept up to date with the company’s growth. Teams could lose access to their resources if they are wrongly tagged. It needs a mechanism to keep up with changes, or people will unexpectedly lose access when user and resource attributes are changed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;To keep up with organisational growth, KCP needs to start listening to the IAM stream, which is where all IAM changes are published. This will allow KCP to regularly update user attributes and refresh resource attributes when restructuring occurs, allowing authorisation to be done with the right data.&lt;/li&gt;
  &lt;li&gt;Constant collaboration with HR to ensure that we maintain sufficient user attributes (no extra unused information) that remain clean so ABAC works as expected.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.openpolicyagent.org/&quot;&gt;OPA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.openpolicyagent.org/docs/latest/policy-language/&quot;&gt;Rego&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/zero-trust-with-kafka&quot;&gt;Zero trust with Kafka&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Mar 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/migrating-to-abac</link>
        <guid isPermaLink="true">https://engineering.grab.com/migrating-to-abac</guid>
        
        <category>Engineering</category>
        
        <category>Access control</category>
        
        <category>Security</category>
        
        
        <category>Engineering</category>
        
        <category>Security</category>
        
      </item>
    
  </channel>
</rss>
