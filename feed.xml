<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grab Tech</title>
    <description>Grab's Engineering team solves critical transportation challenges and makes transport freedom a reality for 620 million people in Southeast Asia.
</description>
    <link>https://engineering.grab.com/</link>
    <atom:link href="https://engineering.grab.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Mon, 15 May 2023 09:40:03 +0000</pubDate>
    <lastBuildDate>Mon, 15 May 2023 09:40:03 +0000</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>2.3x faster using the Go plugin to replace Lua virtual machine</title>
        <description>&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We’re excited to share with you the latest update on our open-source project &lt;a href=&quot;https://github.com/kelindar/talaria&quot;&gt;Talaria&lt;/a&gt;. In our efforts to improve performance and overcome infrastructure limitations, we’ve made significant strides by implementing the &lt;a href=&quot;https://pkg.go.dev/plugin&quot;&gt;Go plugin&lt;/a&gt; to replace Lua VM.&lt;/p&gt;

&lt;p&gt;Our team has found that the &lt;a href=&quot;https://pkg.go.dev/plugin&quot;&gt;Go plugin&lt;/a&gt; is roughly 2.3x faster and uses 2.3x less memory than the Lua VM. This significant performance boost has helped us improve overall functionality, scalability, and speed.&lt;/p&gt;

&lt;p&gt;For those who aren’t familiar, Talaria is a distributed, highly available, and low-latency time-series database that’s designed for Big Data systems. &lt;a href=&quot;https://engineering.grab.com/big-data-real-time-presto-talariadb&quot;&gt;Originally developed and implemented at Grab&lt;/a&gt;, Talaria is a critical component in processing millions and millions of transactions and connections every day, which demands scalable, data-driven decision-making.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;
&lt;p&gt;One of the methods we previously used for processing ingested data was &lt;a href=&quot;https://github.com/talariadb/talaria/blob/51560d23faed1c0d8174531142ef3314cfdc86b1/internal/scripting/script_test.go#L14&quot;&gt;Lua script&lt;/a&gt;. This method allowed users to customise the ingestion process, providing a high degree of flexibility.&lt;/p&gt;

&lt;p&gt;The config below is an example of using Lua script to JSON encode the row as a data column:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;computed:
  - name: data
    type: json
    func: |
      local json = require(&quot;json&quot;)
      function main(row)
        return json.encode(row)
      end     
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;
&lt;p&gt;We found that loading a Lua script required launching a Lua virtual machine (VM) to execute the script, which had a significant impact on performance, especially when ingesting large amounts of events.&lt;/p&gt;

&lt;p&gt;This performance issue led us to reevaluate our approach to processing ingested data and make changes to improve Talaria’s performance.&lt;/p&gt;

&lt;p&gt;As a result, this is the code we used on Lua VM to run the trim, remove keys “key1”, “key2”, “key3”, “key4”, “key5”, in the ingested data:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import &quot;github.com/kelindar/lua&quot;

func luaTrim() string {
    s, err := lua.FromString(&quot;test.lua&quot;, `
    local json = require(&quot;json&quot;)
    local keys = {
    &quot;key1&quot;, &quot;key2&quot;, &quot;key3&quot;, &quot;key4&quot;, &quot;key5&quot;,
    }
    function main(input)
        local data = json.decode(input)
        for i, key in ipairs(keys) do
            data[key] = nil
        end
        return json.encode(data)
    end
`)
    if err != nil {
        panic(err)
    }
    result, err := s.Run(context.Background(), jsonstr)
    if err != nil {
        panic(err)
    }
    return result.String()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here is the benchmark, using Lua VM is 1000 times slower and uses 1000 times more memory than Golang’s native function on a Trim function:&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkTrim-12  &lt;/th&gt;
      &lt;th&gt;543541 &lt;/th&gt;
      &lt;th&gt;2258 ns/op&lt;/th&gt;
      &lt;th&gt;848 B/op&lt;/th&gt;
      &lt;th&gt;12 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkLuaTrim-12 &lt;/th&gt;
      &lt;th&gt;553&lt;/th&gt;
      &lt;th&gt;2105506 ns/op&lt;/th&gt;
      &lt;th&gt;5006319 B/op&lt;/th&gt;
      &lt;th&gt;10335 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
&lt;/table&gt;

&lt;p&gt;But, anything can be improved by adding a cache, what if we cache the Lua VM and reuse them? Here is the new improved benchmark:&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkTrim-8&lt;/th&gt;
      &lt;th&gt;232105 &lt;/th&gt;
      &lt;th&gt;4995 ns/op &lt;/th&gt;
      &lt;th&gt;2192 B/op &lt;/th&gt;
      &lt;th&gt;53 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkLuaTrim-8&lt;/th&gt;
      &lt;th&gt;97536&lt;/th&gt;
      &lt;th&gt;12108 ns/op &lt;/th&gt;
      &lt;th&gt;4573 B/op &lt;/th&gt;
      &lt;th&gt;121 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
&lt;/table&gt;

&lt;p&gt;So we can conclude that Lua VMs are roughly 2.3x faster and use 2.3x less memory than Golang’s native function.&lt;/p&gt;

&lt;h2 id=&quot;use-the-go-plugin-as-lua-vm-to-execute-custom-code&quot;&gt;Use the Go plugin as Lua VM to execute custom code&lt;/h2&gt;
&lt;p&gt;We came up with the idea of using a &lt;a href=&quot;https://developer.ibm.com/tutorials/l-dynamic-libraries/&quot;&gt;Linux shared library&lt;/a&gt; to execute the custom function instead of using Lua VM to run the custom script. Maybe you will be more familiar with the files with suffixes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.so&lt;/code&gt;; they are shared libraries designed to package similar functionality in a single unit and shared with other developers so that they can call the function without writing it again.&lt;/p&gt;

&lt;p&gt;In Golang, a similar idea is called &lt;a href=&quot;https://pkg.go.dev/plugin&quot;&gt;Go plugin&lt;/a&gt;, which allows you to build Golang code as a shared library (Golang names it a plugin). Open this file and call the Go function inside this plugin.&lt;/p&gt;

&lt;h3 id=&quot;how-to-use-the-go-plugin&quot;&gt;How to use the Go plugin&lt;/h3&gt;
&lt;p&gt;Let’s say you have a function F that wants to be called via the plugin.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package main
import &quot;fmt&quot;
func F() { fmt.Printf(&quot;Hello, world&quot;) }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After writing the function F, you can compile it as a Go plugin file f_plugin.so via Go build -buildmode=plugin -o f_plugin.so. And you can open the file and use the function F like this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;p, err := plugin.Open(&quot;f_plugin.so&quot;)
if err != nil {
    panic(err)
}
f, err := p.Lookup(&quot;F&quot;)
if err != nil {
    panic(err)
}
f.(func())() // prints &quot;Hello, world&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;go-plugin-benchmark&quot;&gt;Go plugin benchmark&lt;/h3&gt;
&lt;p&gt;Here is the result that compares Golang native function, Golang plugin call.&lt;/p&gt;

&lt;p&gt;Golang native function: 2.3x faster and 2.3x lesser memory than using the Lua VM.
Golang plugin call has almost the same performance as Golang native function.&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkNativeFunctionCall-12&lt;/th&gt;
      &lt;th&gt;2917465 &lt;/th&gt;
      &lt;th&gt;401.7 ns/op &lt;/th&gt;
      &lt;th&gt;200 B/op&lt;/th&gt;
      &lt;th&gt;6 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;BenchmarkPluginCall-12&lt;/th&gt;
      &lt;th&gt;2778988 &lt;/th&gt;
      &lt;th&gt;447.1 ns/op  &lt;/th&gt;
      &lt;th&gt;200 B/op &lt;/th&gt;
      &lt;th&gt;6 allocs/op&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
&lt;/table&gt;

&lt;h3 id=&quot;integrated-into-talaria&quot;&gt;Integrated into Talaria&lt;/h3&gt;
&lt;p&gt;This is the MR we integrated the Go plugin into Talaria: &lt;a href=&quot;https://github.com/talariadb/talaria/pull/87&quot;&gt;https://github.com/talariadb/talaria/pull/87&lt;/a&gt;, adding it as a loader like LuaLoader.&lt;/p&gt;

&lt;p&gt;They both implemented the Handler interfaces.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;type Handler interface {
    Load(uriOrCode string) (Handler, error)
    String() string
    Value(map[string]interface{}) (interface{}, error)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The implementation of this interface is listed here:&lt;/p&gt;

&lt;h4 id=&quot;for-lua-loader&quot;&gt;For Lua loader&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Load&lt;/strong&gt;: Load the Lua code or Lua script file path (local file path or s3 path) as the loader.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;String&lt;/strong&gt;: Return “lua” so that we can call it to get what the loader is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;: Run the Lua script, and take the arg as input.&lt;/p&gt;

&lt;h4 id=&quot;for-go-plugin-loader&quot;&gt;For Go plugin loader&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Load&lt;/strong&gt;: Read the plugin file path (local file path or s3 path) as the plugin, lookup the function name defined by the user, save the function for later use.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;String&lt;/strong&gt;: Return “plugin” so that we can call it to get what the loader is.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Value&lt;/strong&gt;: Run the saved function, take the arg as input.&lt;/p&gt;

&lt;h2 id=&quot;things-you-need-to-notice&quot;&gt;Things you need to notice&lt;/h2&gt;
&lt;p&gt;The Go version you used to build the  Golang plugin must be the same as the service used in that plugin. We use Docker to build the service, so that we can ensure the Go version is the same.&lt;/p&gt;

&lt;h2 id=&quot;reference-benchmark-plugin-and-lua&quot;&gt;Reference (Benchmark plugin and LUA)&lt;/h2&gt;
&lt;p&gt;https://github.com/atlas-comstock/talaria_benchmark/tree/master/benchmark_plugin_and_lua&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;
&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 15 May 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/faster-using-the-go-plugin-to-replace-Lua-VM</link>
        <guid isPermaLink="true">https://engineering.grab.com/faster-using-the-go-plugin-to-replace-Lua-VM</guid>
        
        <category>Engineering</category>
        
        <category>Virtual machines</category>
        
        <category>Faster</category>
        
        <category>Go plugin</category>
        
        <category>Lua VM</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Safer deployment of streaming applications</title>
        <description>&lt;p&gt;The &lt;a href=&quot;https://flink.apache.org/&quot;&gt;Flink&lt;/a&gt; framework has gained popularity as a real-time stateful stream processing solution for distributed stream and batch data processing. Flink also provides data distribution, communication, and fault tolerance for distributed computations over data streams. To fully leverage Flink’s features, Coban, Grab’s real-time data platform team, has adopted Flink as part of our service offerings.&lt;/p&gt;

&lt;p&gt;In this article, we explore how we ensure that deploying Flink applications remain safe as we incorporate the lessons learned through our &lt;a href=&quot;/our-journey-to-continuous-delivery-at-grab&quot;&gt;journey to continuous delivery&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 1. Flink platform architecture within Coban&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Users interact with our systems to develop and deploy Flink applications in three different ways.&lt;/p&gt;

&lt;p&gt;Firstly, users create a Merge Request (MR) to develop their Flink applications on our Flink Scala repository, according to business requirements. After the MR is merged, GitOps Continuous Integration/Continuous Deployment (CI/CD) automatically runs and dockerises the application, allowing the containerised applications to be deployed easily.&lt;/p&gt;

&lt;p&gt;Secondly, users create another MR to our &lt;a href=&quot;/securing-gitops-pipeline&quot;&gt;infrastructure as a code&lt;/a&gt; repository. The GitOps CI/CD that is integrated with Terraform runs and configures the created Spinnaker application. This process configures the Flink application that will be deployed.&lt;/p&gt;

&lt;p&gt;Finally, users trigger the actual deployment of the Flink applications on Spinnaker, which orchestrates the deployment of the Docker image onto our Kubernetes cluster. Flink applications are deployed as standalone clusters in Grab to ensure resource isolation.&lt;/p&gt;

&lt;h2 id=&quot;problem&quot;&gt;Problem&lt;/h2&gt;

&lt;p&gt;The main issue we noticed with streaming pipelines like these, is that they are often interconnected, where application A depends on application B’s output. This makes it hard to find a solution that perfectly includes integration tests and ensures that propagated changes do not affect downstream applications.&lt;/p&gt;

&lt;p&gt;However, this problem statement is too large to solve with a single solution. As such, we are narrowing the problem statement to focus on ensuring safety of our applications, where engineers can deploy Flink applications that will be rolled back if they fail health checks. In our case, the definition of a Flink application’s health is limited to the uptime of the Flink application itself.&lt;/p&gt;

&lt;p&gt;It is worth noting that Flink applications are designed to be &lt;strong&gt;stateful streaming applications&lt;/strong&gt;, meaning a “state” is shared between events (stream entities) and thus, past events can influence the way current events are processed. This also implies that traditional deployment strategies do not apply to the deployment of Flink applications.&lt;/p&gt;

&lt;h3 id=&quot;current-strategy&quot;&gt;Current strategy&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image3.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 2. Current deployment stages&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Figure 2, our current deployment stages are split into three parts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Delete current deployment&lt;/strong&gt;: Remove current configurations (if applicable) to allow applications to pick up the new configurations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bake (Manifest)&lt;/strong&gt;: Bake the Helm charts with the provided configurations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deploy (Manifest)&lt;/strong&gt;: Deploy the charts onto Kubernetes.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Over time, we learnt that this strategy can be risky. Part 2 can result in a loss of Flink application states due to how internal CI/CD processes are set up. There is also no easy way to rollback if an issue arises. Engineers will need to revert all config changes and rollback the deployment &lt;strong&gt;manually&lt;/strong&gt; by re-deploying the older Docker image – which results in slower operation recovery.&lt;/p&gt;

&lt;p&gt;Lastly, there are no in-built monitoring mechanisms that perform regular health probes. Engineers need to manually monitor their applications to see if their deployment was successful or if they need to perform a rollback.&lt;/p&gt;

&lt;p&gt;With all these issues, deploying Flink applications for engineers are often stressful and fraught with uncertainty. Common mitigation strategies are &lt;em&gt;canary&lt;/em&gt; and &lt;em&gt;blue-green deployments&lt;/em&gt;, which we cover in the next section.&lt;/p&gt;

&lt;h3 id=&quot;canary-deployments&quot;&gt;Canary deployments&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 3. Canary deployment&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In canary deployments, you gradually roll out new versions of the application in parallel with the production version, while serving a percentage of total traffic before promoting it gradually.&lt;/p&gt;

&lt;p&gt;This does not work for Flink deployments due to the nature of stream processing. Applications are frequently required to do streaming operations like stream joining, which involves matching related events in different Kafka topics. So, if a Flink application is only receiving a portion of the total traffic, the data generated will be considered inaccurate due to incomplete data inputs.&lt;/p&gt;

&lt;h3 id=&quot;blue-greendeployments&quot;&gt;Blue-green deployments&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image6.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 4. Blue-green deployment&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Blue-green deployments work by running two versions of the application with a Load Balancer that acts as a traffic switch, which determines which version traffic is directed to.&lt;/p&gt;

&lt;p&gt;This method might work for Flink applications if we only allow one version of the application to consume Kafka messages at any point in time. However, we noticed some issues when switching traffic to another version. For example, the state of both versions will be inconsistent because of the different data traffic each version receives, which complicates the process of switching Kafka consumption traffic.&lt;/p&gt;

&lt;p&gt;So if there’s a failure and we need to rollback from Green to Blue deployment, or vice versa, we will need to take an extra step and ensure that before the failure, the data traffic received is &lt;strong&gt;exactly the same&lt;/strong&gt; for both deployments.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;
&lt;p&gt;As previously mentioned, it is crucial for streaming applications to ensure that at any point in time, only one application is receiving data traffic to ensure data completeness and accuracy. Although employing blue-green deployments can technically fulfil this requirement, the process must be modified to handle state consistency such that both versions have the same starting internal state and receive the &lt;strong&gt;same data traffic&lt;/strong&gt; as each other, if a rollback is needed.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image5.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 5. Visualised deployment flow&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This deployment flow will operate in the following way:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Collect metadata regarding current application&lt;/li&gt;
  &lt;li&gt;Take savepoint and stop the current application&lt;/li&gt;
  &lt;li&gt;Clear up high availability configurations&lt;/li&gt;
  &lt;li&gt;Bake and deploy the new application&lt;/li&gt;
  &lt;li&gt;Monitor application and rollback if the health check fails&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let’s elaborate on the key changes implemented in this new process.&lt;/p&gt;

&lt;h3 id=&quot;savepointing&quot;&gt;Savepointing&lt;/h3&gt;

&lt;p&gt;Flink’s savepointing feature helps address the issue of state consistency and ensures safer deployments.&lt;/p&gt;

&lt;p&gt;A savepoint in Flink is a snapshot of a Flink application’s state at the point in time. This savepoint allows us to pause the Flink application and restore the application to this snapshot state, if there’s an issue.&lt;/p&gt;

&lt;p&gt;Before deploying a Flink application, we perform a savepoint via the Flink API before killing the current application. This would enable us to save the current state of the Flink application and rollback if our deployment fails – just like how you would do a quick save before attempting a difficult level when playing games. This mechanism ensures that both deployment versions have the same internal state during deployment as they both start from the same savepoint.&lt;/p&gt;

&lt;p&gt;Additionally, this feature allows us to easily handle Kafka offsets since these consumed offsets are stored as part of the savepoint. As Flink manages their own state, they don’t need to rely on Kafka’s consumer offset management. With this savepoint feature, we can ensure that the application receives the same data traffic post rollback and that no messages are lost due to processing on the failed version.&lt;/p&gt;

&lt;h3 id=&quot;monitoring&quot;&gt;Monitoring&lt;/h3&gt;

&lt;p&gt;To consistently monitor Flink applications, we can conduct health probes to the respective API endpoints to check if the application is stuck in a restart state or if it is running healthily.&lt;/p&gt;

&lt;p&gt;We also configured our monitoring jobs to wait for a few minutes for the deployment to stabilise before probing it over a defined duration, to ensure that the application is in a stable running state.&lt;/p&gt;

&lt;h3 id=&quot;rollback&quot;&gt;Rollback&lt;/h3&gt;

&lt;p&gt;If the health checks fail, we then perform an automatic rollback. Typically, Flink applications are deployed as a standalone cluster and a rollback involves changes in one of the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Application and Flink configurations&lt;/li&gt;
  &lt;li&gt;Taskmanager or Jobmanager resource provision&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;application-and-flink-configuration-changes&quot;&gt;Application and Flink configuration changes&lt;/h4&gt;

&lt;p&gt;For configuration changes, we leverage the fact that Spinnaker performs versioned deployment of &lt;a href=&quot;https://kubernetes.io/docs/concepts/configuration/configmap/&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configmap&lt;/code&gt;&lt;/a&gt; resources. In this case, a rollback simply involves mounting the old &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configmap&lt;/code&gt; back onto the Kubernetes deployment.&lt;/p&gt;

&lt;p&gt;To retrieve the old version of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configmap&lt;/code&gt; mount, we can simply utilise Kubernetes’ rollback mechanisms – Kubernetes updates a deployment by creating a new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replicaset&lt;/code&gt; with an incremental version before attaching it to the current deployment and scaling the previous &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replicaset&lt;/code&gt; to 0. To retrieve previous deployment specs, we just need to list all &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;replicasets&lt;/code&gt; related to the deployment and find the previous deployed version, before updating the current deployment to mimic the previous template specifications.&lt;/p&gt;

&lt;p&gt;However, this deployment does not contain the number of replicas of previously configured task managers. Kubernetes does not register the number of replicas as part of deployment configuration as this is a dynamic configuration and might be changed during processing due to auto scaling operations.&lt;/p&gt;

&lt;p&gt;Our Flink applications are deployed as standalone clusters and do not use native or yarn resource providers. Coupled with the fact that Flink has strict resource provision, we realised that we do not have enough information to perform rollbacks, without the exact number of replicas created.&lt;/p&gt;

&lt;h4 id=&quot;taskmanager-or-jobmanager-resource-provision-changes&quot;&gt;Taskmanager or Jobmanager resource provision changes&lt;/h4&gt;

&lt;p&gt;To gather information about resource provision changes, we can simply include the previously configured number of replicas as part of our metadata annotation. This allows us to retrieve it in future during rollback.&lt;/p&gt;

&lt;p&gt;Making this change involves creating an additional step of metadata retrieval to retrieve and store previous deployment states as annotations of the new deployment.&lt;/p&gt;

&lt;h3 id=&quot;impact&quot;&gt;Impact&lt;/h3&gt;

&lt;p&gt;With this solution, the deployment flow on Spinnaker looks like this:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image7.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 6. New deployment flow on Spinnaker&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Engineers no longer need to monitor the deployment pipeline as closely as they get notified of their application’s deployment status via Slack. They only need to interact or take action when they get notified that the different stages of the deployment pipeline are completed.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/safer-flink-deployments/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 7. Slack notifications on deployment status&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;It is also easier to deploy Flink applications since failures and rollbacks are handled automatically. Furthermore, application state management is also automated, which reduces the amount of uncertainties.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;As we work to further improve our deployment pipeline, we will look into extending the capabilities at our monitoring stage to allow engineers to define and configure their own health probes, allowing our deployment configurations to be more extendable.&lt;/p&gt;

&lt;p&gt;Another interesting improvement will be to make this deployment flow seamlessly, ensuring as little downtime as possible by minimising cold start duration.&lt;/p&gt;

&lt;p&gt;Coban also looks forward to pushing more features on our Flink platform to enable our engineers to explore more use cases that utilises real-time data to allow our operations to become auto adaptive and make data-driven decisions.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-release-1.16/docs/ops/state/savepoints/&quot;&gt;Flink Savepointing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://nightlies.apache.org/flink/flink-docs-master/docs/ops/rest_api/&quot;&gt;Flink API&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kubernetes.io/docs/concepts/workloads/controllers/deployment/%23updating-a-deployment&quot;&gt;Kubernetes rollback&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 02 May 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/safer-flink-deployments</link>
        <guid isPermaLink="true">https://engineering.grab.com/safer-flink-deployments</guid>
        
        <category>Engineering</category>
        
        <category>Deployments</category>
        
        <category>Streaming applications</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>Message Center - Redesigning the messaging experience on the Grab superapp</title>
        <description>&lt;p&gt;Since 2016, Grab has been using &lt;a href=&quot;https://www.grab.com/ph/blog/grabchat/&quot;&gt;GrabChat&lt;/a&gt;, a built-in messaging feature to connect our users with delivery-partners or driver-partners. However, as the Grab superapp grew to include more features, the limitations of the old system became apparent. GrabChat could only handle two-party chats because that’s what it was designed to do. To make our messaging feature more extensible for future features, we decided to redesign the messaging experience, which is now called Message Center.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/message-center/image2.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Migrating from the old GrabChat to the new Message Center&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To some, building our own chat function might not be the ideal approach, especially with open source alternatives like &lt;a href=&quot;https://github.com/signalapp&quot;&gt;Signal&lt;/a&gt;. However, Grab’s business requirements introduce some level of complexity, which required us to develop our own solution.&lt;/p&gt;

&lt;p&gt;Some of these requirements include, but are not limited to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Handle multiple user types (passengers, driver-partners, consumers, delivery-partners, customer support agents, merchant-partners, etc.) with custom user interface (UI) rendering logic and behaviour.&lt;/li&gt;
  &lt;li&gt;Enable other Grab backend services to send system generated messages (e.g. your driver is reaching) and customise push notifications.&lt;/li&gt;
  &lt;li&gt;Persist message state even if users uninstall and reinstall their apps. Users should be able to receive undelivered messages even if they were offline for hours.&lt;/li&gt;
  &lt;li&gt;Provide translation options for non-native speakers.&lt;/li&gt;
  &lt;li&gt;Filter profanities in the chat.&lt;/li&gt;
  &lt;li&gt;Allow users to handle group chats. This feature might come in handy in future if there needs to be communication between passengers, driver-partners, and delivery-partners.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution-architecture&quot;&gt;Solution architecture&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/message-center/image3.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Message Center architecture&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The new Message Center was designed to have two components:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Message-center backend: Message processor service that handles logical and database operations.&lt;/li&gt;
  &lt;li&gt;Message-center postman: Message delivery service that can scale independently from the backend service.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This architecture allows the services to be sufficiently decoupled and scale independently. For example, if you have a group chat with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; participants and each message sent results in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; messages being delivered, this architecture would enable message-center postman to scale accordingly to handle the higher load.&lt;/p&gt;

&lt;p&gt;As Grab delivers millions of events a day via the Message Center service, we need to ensure that our system can handle high throughput. As such, we are using Apache Kafka as the low-latency high-throughput event stream connecting both services and Amazon SQS as a redundant delay queue that attempts a retry 10 seconds later.&lt;/p&gt;

&lt;p&gt;Another important aspect for this service is the ability to support low-latency and bi-directional communications from the client to the server. That’s why we chose Transmission Control Protocol (TCP) as the main protocol for client-server communication. Mobile and web clients connect to Hermes, Grab’s TCP gateway service, which then digests the TCP packets and proxies the payloads to Message Center via gRPC. If both recipients and senders are online, the message is successfully delivered in a matter of milliseconds.&lt;/p&gt;

&lt;p&gt;Unlike HTTP, individual TCP packets do not require a response so there is an inherent uncertainty in whether the messages were successfully delivered. Message delivery can fail due to several reasons, such as the client terminating the connection but the server’s connection remaining established. This is why we built a system of acknowledgements (ACKs) between the client and server, which ensures that every event is received by the receiving party.&lt;/p&gt;

&lt;p&gt;The following diagram shows the high-level sequence of events when sending a message.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/message-center/image1.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Events involved in sending a message on Message Center&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Following the sequence of events involved in sending a message and updating its status for the sender from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sending&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sent&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delivered&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;read&lt;/code&gt;, the process can get very complicated quickly. For example, the sender will retry the 1302 TCP new message &lt;em&gt;until&lt;/em&gt; it receives a server ACK. Similarly, the server will also keep attempting to send the 1402 TCP message receipt or 1303 TCP message unless it receives a client ACK. With this in mind, we knew we had to give special attention to the ACK implementation, to prevent infinite retries on the client and server, which can quickly cascade to a system-wide failure.&lt;/p&gt;

&lt;p&gt;Lastly, we also had to consider dropped TCP connections on mobile devices, which happens quite frequently. What happens then? Message Center relies on Hedwig, another in-house notification service, to send push notifications to the mobile device when it receives a failed response from Hermes. Message Center also maintains a user-events DynamoDB database, which updates the state of every pending event of the client to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;delivered&lt;/code&gt; whenever a client ACK is received.&lt;/p&gt;

&lt;p&gt;Every time the mobile client reconnects to Hermes, it also sends a special TCP message to notify Message Center that the client is back online, and then the server retries sending all the pending events to the client.&lt;/p&gt;

&lt;h2 id=&quot;learningsconclusion&quot;&gt;Learnings/Conclusion&lt;/h2&gt;

&lt;p&gt;With large-scale features like Message Center, it’s important to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Decouple services so that each microservice can function and scale as needed.&lt;/li&gt;
  &lt;li&gt;Understand our feature requirements well so that we can make the best choices and design for extensibility.&lt;/li&gt;
  &lt;li&gt;Implement safeguards to prevent system timeouts, infinite loops, or other failures from cascading to the entire system, i.e. rate limiting, message batching, and idempotent &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eventIDs&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Mon, 17 Apr 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/message-center</link>
        <guid isPermaLink="true">https://engineering.grab.com/message-center</guid>
        
        <category>Engineering</category>
        
        <category>GrabChat</category>
        
        <category>Redesign</category>
        
        <category>Messaging</category>
        
        <category>Chat support</category>
        
        
        <category>Engineering</category>
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>Evolution of quality at Grab</title>
        <description>&lt;p&gt;To achieve our vision of becoming the leading superapp in Southeast Asia, we constantly need to balance development velocity with maintaining the high quality of the Grab app. Like most tech companies, we started out with the traditional software development lifecycle (SDLC) but as our app evolved, we soon noticed several challenges like high feature bugs and production issues.  &lt;/p&gt;

&lt;p&gt;In this article, we dive deeper into our quality improvement journey that officially began in 2019, the challenges we faced along the way, and where we stand as of 2022.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image4.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 1 - Software development life cycle (SDLC) sample&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;When Grab first started in 2012, we were using the Agile SDLC (Figure 1) across all teams and features. This meant that every new feature went through the entire process and was &lt;strong&gt;only released&lt;/strong&gt; to app distribution platforms (PlayStore or AppStore) &lt;strong&gt;after&lt;/strong&gt; the quality assurance (QA) team manually tested and signed off on it.&lt;/p&gt;

&lt;p&gt;Over time, we discovered that feature testing took longer, with more bugs being reported and impact areas that needed to be tested. This was the same for regression testing as QA engineers had to manually test each feature in the app before a release. Despite the best efforts of our QA teams, there were still many major and critical production issues reported on our app – the highest numbers were in 2019 (Figure 2).&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image1.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 2 - Critical open production issue (OPI) trend&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;This surge in production issues and feature bugs was directly impacting our users’ experience on our app. To directly address the high production issues and slow testing process, we changed our testing strategy and adopted shift-left testing.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.testim.io/blog/shift-left-testing-guide/&quot;&gt;Shift-left testing&lt;/a&gt; is an approach that brings testing forward to the early phases of software development. This means testing can start as early as the planning and design phases.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image2.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 3 - Shift-left testing&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;By adopting shift-left testing, engineering teams at Grab are able to proactively prevent possible defect leakage in the early stages of testing, directly addressing our users’ concerns without delaying delivery times.&lt;/p&gt;

&lt;p&gt;With shift-left testing, we made three significant changes to our SDLC:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Software engineers conduct acceptance testing&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Incorporate Definition of Ready (DoR) and Definition of Done (DoD)&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Balanced testing strategy&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let’s dive deeper into how we implemented each change, the challenges, and learnings we gained along the way.&lt;/p&gt;

&lt;h3 id=&quot;software-engineers-conduct-acceptance-testing&quot;&gt;Software engineers conduct acceptance testing&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.geeksforgeeks.org/acceptance-testing-software-testing/&quot;&gt;Acceptance testing&lt;/a&gt; determines whether a feature satisfies the defined acceptance criteria, which helps the team evaluate if the feature fulfills our consumers’ needs. Typically, acceptance testing is done after development. But our QA engineers still discovered many bugs and the cost of fixing bugs at this stage is more expensive and time-consuming. We also realised that the most common root causes of bugs were associated with insufficient requirements, vague details, or missing test cases.&lt;/p&gt;

&lt;p&gt;With shift-left testing, QA engineers start writing test cases before development starts and these acceptance tests will be executed by the software engineers during development. Writing acceptance tests early helps identify potential gaps in the requirements before development begins. It also prevents possible bugs and streamlines the testing process as engineers can find and fix bugs even before the testing phase. This is because they can execute the test cases directly during the development stage.&lt;/p&gt;

&lt;p&gt;On top of that, QA and Product managers also made &lt;strong&gt;Given/When/Then (GWT)&lt;/strong&gt; the standard for acceptance criteria and test cases, making them easier for all stakeholders to understand.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;table border=&quot;1&quot;&gt;
  &lt;tr&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;Step by Step style&lt;/th&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;GWT format&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 20px&quot;&gt;&lt;ol&gt;&lt;li&gt;Open the Grab app&lt;/li&gt;&lt;li&gt;Navigate to home feed&lt;/li&gt;&lt;li&gt;Tap on merchant entry point card&lt;/li&gt;&lt;li&gt;Check that merchant landing page is shown&lt;/li&gt;&lt;/ol&gt;&lt;/td&gt;
    &lt;td style=&quot;padding: 20px&quot;&gt;Given user opens the app &lt;br /&gt;And user navigates to the home feed&lt;br /&gt;When the user taps on the merchant entry point card&lt;br /&gt;Then the user should see the merchant’s landing page&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;br /&gt;
By enabling software engineers to conduct acceptance testing, we minimised back-and-forth discussions within the team regarding bug fixes and also, influenced a significant shift in perspective – quality is everyone’s responsibility.&lt;/p&gt;

&lt;p&gt;Another key aspect of shift-left testing is for teams to agree on a standard of quality in earlier stages of the SDLC. To do that, we started incorporating Definition of Ready (DoR) and Definition of Done (DoD) in our tasks.&lt;/p&gt;

&lt;h3 id=&quot;incorporate-definition-of-ready-dor-and-definition-of-done-dod&quot;&gt;Incorporate Definition of Ready (DoR) and Definition of Done (DoD)&lt;/h3&gt;

&lt;p&gt;As mentioned, quality checks can be done before development even begins and can start as early as backlog grooming and sprint planning. The team needs to agree on a standard for work products such as requirements, design, engineering solutions, and test cases. Having this alignment helps reduce the possibility of unclear requirements or misunderstandings that may lead to re-work or a low-quality feature.&lt;/p&gt;

&lt;p&gt;To enforce consistent quality of work products, everyone in the team should have access to these products and should follow DoRs and DoDs as standards in completing their tasks.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;DoR&lt;/strong&gt;: Explicit criteria that an epic, user story, or task must meet before it can be accepted into an upcoming sprint. &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DoD&lt;/strong&gt;: List of criteria to fulfill before we can mark the epic, user story, or task complete, or the entry or exit criteria for each story state transitions. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Including DoRs and DoDs have proven to improve delivery pace and quality. One of the first teams to adopt this observed significant improvements in their delivery speed and app quality – consistently delivering over 90% of task commitments, minimising technical debt, and reducing manual testing times.&lt;/p&gt;

&lt;p&gt;Unfortunately, having these two changes alone were not sufficient – testing was still manually intensive and time consuming. To ease the load on our QA engineers, we needed to develop a balanced testing strategy.  &lt;/p&gt;

&lt;h3 id=&quot;balanced-testing-strategy&quot;&gt;Balanced testing strategy&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image3.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 4 - Test automation strategy&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Our initial automation strategy only included unit testing, but we have since enhanced our testing strategy to be more balanced.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unit testing&lt;/li&gt;
  &lt;li&gt;UI component testing&lt;/li&gt;
  &lt;li&gt;Backend integration testing&lt;/li&gt;
  &lt;li&gt;End-to-End (E2E) testing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Simply having good coverage in one layer does not guarantee good quality of an app or new feature. It is important for teams to test vigorously with different types of testing to ensure that we cover all possible scenarios before a release.&lt;/p&gt;

&lt;p&gt;As you already know, unit tests are written and executed by software engineers during the development phases. Let’s look at what the remaining three layers mean.&lt;/p&gt;

&lt;h4 id=&quot;ui-component-testing&quot;&gt;UI component testing&lt;/h4&gt;

&lt;p&gt;This type of testing focuses on individual components within the application and is useful for testing specific use cases of a service or feature. To reduce manual effort from QA engineers, teams started exploring automation and introduced a mobile testing framework for &lt;a href=&quot;https://applitools.com/learn/concepts/component-testing/&quot;&gt;component testing&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This UI component testing framework used mocked API responses to test screens and interactions on the elements. These UI component tests were automatically executed whenever the pipeline was run, which helped to reduce manual regression efforts. With shift-left testing, we also revised the DoD for new features to include at least 70% coverage of UI component tests.&lt;/p&gt;

&lt;h4 id=&quot;backend-integration-testing&quot;&gt;Backend integration testing&lt;/h4&gt;

&lt;p&gt;Backend integration testing is especially important if your application regularly interacts with backend services, much like the Grab app. This means we need to ensure the quality and stability of these backend services. Since Grab started its journey toward becoming a superapp, more teams started performing backend integration tests like API integration tests.&lt;/p&gt;

&lt;p&gt;Our backend integration tests also covered positive and negative test cases to determine the happy and unhappy paths. At the moment, majority of Grab teams have complete test coverage for happy path use cases and are continuously improving coverage for other use cases.&lt;/p&gt;

&lt;h4 id=&quot;end-to-end-e2e-testing&quot;&gt;End-to-End (E2E) testing&lt;/h4&gt;

&lt;p&gt;E2E tests are important because they simulate the entire user experience from start to end, ensuring that the system works as expected. We started exploring E2E testing frameworks, from as early as 2015, to automate tests for critical services like logging in and booking a ride.&lt;/p&gt;

&lt;p&gt;But as Grab introduced more services, off-the-shelf solutions were no longer a viable option, as we noticed issues like automation limitations and increased test flakiness. We needed a framework that is compatible with existing processes, stable enough to reduce flakiness, scalable, and easy to learn.&lt;/p&gt;

&lt;p&gt;With this criteria in mind, our QA engineering teams built an internal E2E framework that could make API calls, test different account-based scenarios, and provide many other features. Multiple pilot teams have started implementing tests with the E2E framework, which has helped to reduce regression efforts. We are continuously improving the framework by adding new capabilities to cover more test scenarios.&lt;/p&gt;

&lt;p&gt;Now that we’ve covered all the changes we implemented with shift-left testing, let’s take a look at how this changed our SDLC.&lt;/p&gt;

&lt;h2 id=&quot;impact&quot;&gt;Impact&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/evolution-of-quality/image6.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 5 - Updated SDLC process&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Since the implementation of shift-left testing, we have improved our app quality without compromising our project delivery pace. Compared to 2019, we observed the following improvements within the Grab superapp in 2022:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Production issues with “Major and Critical” severity bugs found in production were &lt;strong&gt;reduced by 60%&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Bugs found in development phase with “Major and Critical” severity were &lt;strong&gt;reduced by 40%&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;
&lt;p&gt;Through this journey, we recognise that there’s no such thing as a bug-free app – no matter how much we test, production issues still happen occasionally. To minimise the occurrence of bugs, we’re regularly conducting root cause analyses and writing postmortem reports for production incidents. These allow us to retrospect with other teams and come up with corrective actions and prevention plans. Through these continuous learnings and improvements, we can continue to shape the future of the Grab superapp.&lt;/p&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to Sori Han for designing the images in this article.&lt;/small&gt;&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Fri, 31 Mar 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/evolution-of-quality</link>
        <guid isPermaLink="true">https://engineering.grab.com/evolution-of-quality</guid>
        
        <category>Engineering</category>
        
        <category>Technology stack</category>
        
        <category>Exploration</category>
        
        
        <category>Engineering</category>
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>How OVO determined the right technology stack for their web-based projects</title>
        <description>&lt;p&gt;In the current technology landscape, startups are developing rapidly. This usually leads to an increase in the number of engineers in teams, with the goal of increasing the speed of product development and delivery frequency. However, this growth often leads to a diverse selection of technology stacks being used by different teams within the same organisation.&lt;/p&gt;

&lt;p&gt;Having different technology stacks within a team could lead to a bigger problem in the future, especially if documentation is not well-maintained. The best course of action is to pick just one technology stack for your projects, but it begs the question, &lt;strong&gt;“How do I choose the best technology stack for my projects?”&lt;/strong&gt;. &lt;/p&gt;

&lt;p&gt;One such example is OVO, which is an Indonesian payments, rewards, and financial services platform within Grab. We share our process and analysis to determine the best technology stack that complies with precise standards. By the end of the article, you may also learn to choose the best technology stack for your needs.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;In recent years, we have seen massive growth in modern web technologies, such as React, Angular, Vue, Svelte, Django, TypeScript, and many more. Each technology has its benefits. However, having so many choices can be confusing when you must determine which technologies are best for your projects. To narrow down the choices, a few aspects, such as scalability, stability, and usage in the market, must be considered.&lt;/p&gt;

&lt;p&gt;That’s the problem that we used to face. Most of our legacy services were not standardised and were written in different languages like PHP, React, and Vue. Also, the documentation for these legacy services is not well-structured or regularly updated.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image1.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Current technology stack usage in OVO&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We realised that we had &lt;strong&gt;two&lt;/strong&gt; main problems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Various technology stacks&lt;/strong&gt; (PHP, Vue, React, Nuxt, and Go) maintained simultaneously, with incomplete documentation, may consume a lot of time to understand the code, especially for engineers unfamiliar with the frameworks or even a new hire.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Context switching&lt;/strong&gt; when reviewing code makes it hard to review other teammates’ merge requests on complex projects and quickly offer better code suggestions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To prevent these problems from recurring, teams must use &lt;strong&gt;one primary technology stack&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;After detailed comparisons, we narrowed our choices to &lt;strong&gt;two&lt;/strong&gt; options – React and Vue – because we have developed projects in both technologies and already have the user interface (UI) library in each technology stack.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image4.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Taken from &lt;a href=&quot;https://www.ulam.io/blog/react-vs-vue-framework-comparison&quot;&gt;ulam.io&lt;/a&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Next, we conducted a more detailed research and exploration for each technology. The main goals were to find the unique features, scalability, ease of migration, and compatibility for the UI library for React and Vue. To test the compatibility of each UI library, we also used a sample UI on one of our upcoming projects and sliced it.&lt;/p&gt;

&lt;p&gt;Here’s a quick summary of our exploration:&lt;/p&gt;

&lt;table border=&quot;1&quot;&gt;
&lt;tr&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;Metrics&lt;/th&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;Vue&lt;/th&gt;
  &lt;th style=&quot;padding: 20px&quot;&gt;React&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;UI Library Compatibility&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Doesn’t require much component development&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Doesn’t require much component development&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Scalability&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Easier to upgrade, slower in releasing major updates, clear migration guide&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Quicker release of major versions, supports gradual updates&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Others&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Composition API, strong community (&lt;a href=&quot;https://vue-community.org/&quot;&gt;Vue Community&lt;/a&gt;)&lt;/td&gt;
  &lt;td style=&quot;padding: 20px&quot;&gt;Latest version (v18) of React gradual updates, doesn’t support IE&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
From this table, we found that the differences between these frameworks are miniscule, making it tough for us to determine which to use. Ultimately, we decided to step back and see the &lt;strong&gt;Big Why&lt;/strong&gt;. &lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;The Big Why here was “Why do we need to standardise our technology stack?”. We wanted to ease the onboarding process for new hires and reduce the complexity, like context switching, during code reviews, which ultimately saves time.&lt;/p&gt;

&lt;p&gt;As Kleppmann (2017) states, &lt;em&gt;“The majority of the cost of software is in its ongoing maintenance”&lt;/em&gt;. In this case, the biggest cost was time. Increasing the ease of maintenance would reduce the cost, so we decided to use maintainability as our north star metric.&lt;/p&gt;

&lt;p&gt;Kleppmann (2017) also highlighted &lt;strong&gt;three design principles&lt;/strong&gt; in any software system:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Operability&lt;/em&gt;: Make it easy to keep the system running.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Simplicity&lt;/em&gt;: Easy for new engineers to understand the system by minimising complexity.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Evolvability&lt;/em&gt;: Make it easy for engineers to make changes to the system in the future.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Keeping these design principles in mind, we defined &lt;strong&gt;three metrics&lt;/strong&gt; that our selected tech stack must achieve:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Scalability&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Keeping software and platforms up to date&lt;/li&gt;
      &lt;li&gt;Anticipating possible future problems&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Stability of the library and documentation&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;Establishing good practices and tools for development&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Usage in the market&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;The popularity of the library or framework and variety of coding best practices&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;table border=&quot;1&quot;&gt;
  &lt;tr&gt;
    &lt;th style=&quot;padding: 20px&quot;&gt;Metrics&lt;/th&gt;
    &lt;th style=&quot;padding: 20px&quot;&gt;Vue&lt;/th&gt;
    &lt;th style=&quot;padding: 20px&quot;&gt;React&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Scalability&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;&lt;strong&gt;Framework&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;Operability&lt;/strong&gt;&lt;br /&gt;Easier to update because there aren’t many approaches to writing Vue.&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;Evolvability&lt;/strong&gt;&lt;br /&gt;Since Vue is a framework, it needs fewer steps to upgrade.&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;&lt;strong&gt;Library&lt;/strong&gt;&lt;br /&gt;Supports gradual updates but there will be many different approaches when upgrading React on our services.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Stability of the library and documentation&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Has standardised documentation&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Has many versions of documentation&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Usage on Market&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Smaller market share.&lt;br /&gt;&lt;br /&gt;&lt;strong&gt;Simplicity&lt;/strong&gt;&lt;br /&gt;We can reduce complexity for new hires, as the Vue standard in OVO remains consistent with standards in other companies.&lt;/td&gt;
    &lt;td style=&quot;padding: 10px&quot;&gt;Larger &lt;a href=&quot;https://www.statista.com/statistics/1124699/worldwide-developer-survey-most-used-frameworks-web/&quot;&gt;market share&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;    Many React variants are currently in the market, so different companies may have different folder structures/conventions.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;/table&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image3.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Screenshot taken from &lt;a href=&quot;https://www.statista.com/&quot;&gt;https://www.statista.com/&lt;/a&gt; on 2022-10-13&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;After conducting a detailed comparison between Vue and React, we decided to use Vue as our primary tech stack as it best aligns with Kleppmann’s three design principles and our north star metric of maintainability. Even though we noticed a few disadvantages to using Vue, such as smaller market share, we found that Vue is still the better option as it complies with all our metrics.&lt;/p&gt;

&lt;p&gt;Moving forward, we will only use one tech stack across our projects but we decided not to migrate technology for existing projects. This allows us to continue &lt;strong&gt;exploring&lt;/strong&gt; and &lt;strong&gt;learning&lt;/strong&gt; about other technologies’ developments. One of the things we need to do is ensure that our current projects are kept up-to-date.&lt;/p&gt;

&lt;h3 id=&quot;implementation&quot;&gt;Implementation&lt;/h3&gt;

&lt;p&gt;After deciding on the primary technology stack, we had to do the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Define a boilerplate for future Vue projects, which will include items like a &lt;strong&gt;general library or dependencies&lt;/strong&gt;, &lt;strong&gt;implementation for unit testing&lt;/strong&gt;, and &lt;strong&gt;folder structure&lt;/strong&gt;, to align with our north star metric.&lt;/li&gt;
  &lt;li&gt;Update our existing &lt;strong&gt;UI library&lt;/strong&gt; with new components and the latest Vue version.&lt;/li&gt;
  &lt;li&gt;Perform periodic upgrades to existing React services and create a standardised code structure with proper documentation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With these practices in place, we can ensure that future projects will be standardised, making them easier for engineers to maintain.&lt;/p&gt;

&lt;h3 id=&quot;impact&quot;&gt;Impact&lt;/h3&gt;

&lt;p&gt;There are a few key benefits of standardising our technology stack.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Scalability and maintainability&lt;/strong&gt;: It’s much easier to scale and maintain projects using the same technology stack. For example, when implementing security patches on all projects due to certain vulnerabilities in the system or libraries, we will need one patch for each technology. With only one stack, we only need to implement one patch across all projects, saving a lot of time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Faster onboarding process&lt;/strong&gt;: The onboarding process is simplified for new hires because we have standardisation between all services, which will minimise the amount of context switching and lower the learning curve.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Faster deliveries&lt;/strong&gt;: When it’s easier to implement a change, there’s a compounding impact where the delivery process is shortened and release to production is quicker. Ultimately, faster deliveries of a new product or feature will help increase revenue.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;learningsconclusion&quot;&gt;Learnings/Conclusion&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/determining-tech-stack/image2.jpg&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;For every big decision, it is important to take a step back and understand the Big Why or the main motivation behind it, in order to remain objective. That’s why after we identified maintainability as our north star metric, it was easier to narrow down the choices and make detailed comparisons.&lt;/p&gt;

&lt;p&gt;The north star metric, or deciding factor, might differ vastly, but it depends on the problems you are trying to solve.&lt;/p&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Note: The OVO web team conducted this research in 2022 and was accurate at the time of publishing. The information here may only be applicable to the OVO web team.&lt;/small&gt;&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Kleppmann, M. (2017). Designing Data-Intensive Applications. Beijing: O’Reilly. ISBN: 978-1-4493-7332-0&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.statista.com/statistics/1124699/worldwide-developer-survey-most-used-frameworks-web/&quot;&gt;Most used web frameworks 2022 - Statista&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Mar 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/determining-tech-stack</link>
        <guid isPermaLink="true">https://engineering.grab.com/determining-tech-stack</guid>
        
        <category>Engineering</category>
        
        <category>Technology stack</category>
        
        <category>Exploration</category>
        
        
        <category>Engineering</category>
        
        <category>Design</category>
        
      </item>
    
      <item>
        <title>Migrating from Role to Attribute-based Access Control</title>
        <description>&lt;p&gt;Grab has always regarded security as one of our top priorities; this is especially important for data platform teams. We need to control access to data and resources in order to protect our consumers and ensure compliance with various, continuously evolving security standards.&lt;/p&gt;

&lt;p&gt;Additionally, we want to keep the process convenient, simple, and easily scalable for teams. However, as Grab continues to grow, we have more services and resources to manage and it becomes increasingly difficult to keep the process frictionless. That’s why we decided to move from Role-Based Access Control (RBAC) to Attribute-Based Access Control (ABAC) for our Kafka Control Plane (KCP).&lt;/p&gt;

&lt;p&gt;In this article, you will learn how Grab’s streaming data platform team (Coban) deleted manual role and permission management of hundreds of roles and resources, and reduced operational overhead of requesting or approving permissions to zero by moving from RBAC to ABAC.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Kafka is widely used across Grab teams as a streaming platform. For decentralised Kafka resource (e.g. topic) management, teams have the right to create, update, or delete based on their needs. As the data platform team, we implemented a KCP to ensure that these operations are only performed by authorised parties, especially on multi-tenant Kafka clusters.&lt;/p&gt;

&lt;p&gt;For internal access management, Grab uses its own Identity and Access Management (IAM) service, based on RBAC, to support authentication and authorisation processes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt; verifies the identity of a user or service, for example, if the provided token is valid or expired.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Authorisation&lt;/strong&gt; determines their access rights, for example, whether users can only update and/or delete their own Kafka topics.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In RBAC, roles, permissions, actions, resources, and the relationships between them need to be defined in the IAM service. They are used to determine whether a user can access a certain resource.&lt;/p&gt;

&lt;p&gt;In the following example, we can see how IAM concepts come together. The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Coban engineer&lt;/code&gt; role belongs to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Engineering-coban&lt;/code&gt; group and has permission to update the topic’s retention. Any engineer added to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Engineering-coban&lt;/code&gt; group will also be able to update the topic’s retention.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image5.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Following the same concept, each team using the KCP has its own roles, permissions, and resources created in the system. However, there are some disadvantages to this approach:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It leads to a significant growth in the number of access control artifacts both platform and user teams need to manage, and increased time and effort to debug access control issues. We start off by finding which group the engineer belongs to and locating the group that should be used for KCP, and then trace to role and permissions.&lt;/li&gt;
  &lt;li&gt;All group membership access requests of new joiners need to be reviewed and approved by their direct managers. This leads to a lot of backlog as new joiners might have multiple groups to join and managers might not be able to review them timely. In some cases, roles need to be re-applied or renewed every 90 days, which further adds to the delay.&lt;/li&gt;
  &lt;li&gt;Group memberships are not updated to reflect active members in the team, leaving some engineers with access they don’t need and others with access they should have but don’t.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;With ABAC, access management becomes a lot easier. Any new joiner to a specific team gets the same access rights as everyone on that team – no need for manual approval from a manager. However, for ABAC to work, we need these components in place:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;User attributes: Who is the subject (actor) of a request?&lt;/li&gt;
  &lt;li&gt;Resource attributes: Which object (resource) does the actor want to deal with?&lt;/li&gt;
  &lt;li&gt;Evaluation engine: How do we decide if the actor is allowed to perform the action on the resource?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;User attributes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;All users have certain attributes depending on the department or team they belong to. This data is then stored and synced automatically with the human resource management system (HRMS) tool, which acts as a source of truth for Grab-wide data, every time a user switches teams, roles, or leaves the company.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Resource attributes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Resource provisioning is an authenticated operation. This means that KCP knows who sent the requests and what each request/action is about. Similarly, resource attributes can be derived from their creators. For new resource provisioning, it is possible to capture the resource tags and store them after authentication. For existing resources, a major challenge was the need to backfill the tagging and ensure a seamless transition from the user’s perspective. In the past, all resource provisioning operations were done by a centralised platform team and most of the existing resource attributes are still under platform team’s ownership.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Evaluation engine&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We chose to use &lt;a href=&quot;https://www.openpolicyagent.org/&quot;&gt;Open Policy Agent&lt;/a&gt; (OPA) as our policy evaluation engine mainly for its wide community support, applicable feature set, and extensibility to other tools and platforms in our system. This is also currently used by our team for &lt;a href=&quot;/zero-trust-with-kafka&quot;&gt;Kafka authorisation&lt;/a&gt;. The policies are written in &lt;a href=&quot;https://www.openpolicyagent.org/docs/latest/policy-language/&quot;&gt;Rego&lt;/a&gt;, the default language supported by OPA.&lt;/p&gt;

&lt;h2 id=&quot;architectureand-implementation&quot;&gt;Architecture and implementation&lt;/h2&gt;

&lt;p&gt;With ABAC, the access control process looks like this:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image6.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;user-attributes&quot;&gt;User attributes&lt;/h4&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image4.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Authentication is handled by the IAM service. In the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/generate_token&lt;/code&gt; call, a user requests an authentication token from KCP before calling an authenticated endpoint. KCP then calls IAM to generate a token and returns it to the user.&lt;/p&gt;

&lt;p&gt;In the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/create_topic&lt;/code&gt; call, the user includes the generated token in the request header. KCP takes the token and verifies the token validity with IAM. User attributes are then extracted from the token payload for later use in request authorisation.&lt;/p&gt;

&lt;p&gt;Some of the common attributes we use for our policy are &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;user identifier&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;department code&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;team code&lt;/code&gt;, which provide details like a user’s department and work scope.&lt;/p&gt;

&lt;p&gt;When it comes to data governance and central platform and identity teams, one of the major challenges was standardising the set of attributes to be used for clear and consistent ABAC policies across platforms so that their lifecycle and changes could be governed. This was an important shift in the mental model for attribute management over the RBAC model.&lt;/p&gt;

&lt;h4 id=&quot;resource-attributes&quot;&gt;Resource attributes&lt;/h4&gt;

&lt;p&gt;For newly created resources, attributes will be derived from user attributes that are captured during the authentication process.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image3.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Previously with RBAC, existing resources did not have the required attributes. Since migrating to ABAC, the implementation has tagged newly created resources and ensured that their attributes are up to standard. IAM was also still doing the actual authorisation using RBAC.&lt;/p&gt;

&lt;p&gt;It is also important to note that we collaborated with data governance teams to backfill Kafka resource ownership. Having accurate ownership of resources like data lake or Kafka topics enabled us to move toward a self-service model and remove bottlenecks from centralised platform teams.&lt;/p&gt;

&lt;p&gt;After identifying most of the resource ownership, we started switching over to ABAC. The transition was smooth and had no impact on user experience. The remaining unidentified resources were tagged to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;lost-and-found&lt;/code&gt; and could be reclaimed by service teams when they needed permission to manage them.&lt;/p&gt;

&lt;h4 id=&quot;open-policy-agent&quot;&gt;Open Policy Agent&lt;/h4&gt;

&lt;p&gt;The most common question when implementing the policy is “how do you define ownership by attributes?”. With respect to the principle of least privilege, each policy must be sufficiently strict to limit access to only the relevant parties. In the end, we aligned as an organisation on defining ownership by department and team.&lt;/p&gt;

&lt;p&gt;We created a simple example below to demonstrate how to define a policy:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;package authz

import future.keywords

default allow = false

allow if {
        input.endpoint == &quot;updateTopic&quot;
        is_owner(input.resource_attributes)
}

is_owner(md) if {
        md.department == input.user_attributes.department
        md.team == input.user_attributes.team
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this example, we start with denying access to everyone. If the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;updateTopic&lt;/code&gt; endpoint is called and the department and team attributes between user and resource are matched, access is allowed.&lt;/p&gt;

&lt;p&gt;With a similar scenario, we would need 1 role, 1 action, 1 resource, and 1 mapping (a.k.a permission) between action and resource. We will need to keep adding resources and permissions when we have new resources created. Compared to the policy above, no other changes are required.&lt;/p&gt;

&lt;p&gt;With ABAC, there are no further setup or access requests needed when a user changes teams. The user will be tagged to different attributes, automatically granted access to the new team’s resources, and excluded from the previous team’s resources.&lt;/p&gt;

&lt;p&gt;Another consideration we had was making sure that the policy is well-written and transparent in terms of change history. We decided to include this as part of our application code so every change is accounted for in the unit test and review process.&lt;/p&gt;

&lt;h4 id=&quot;authorisation&quot;&gt;Authorisation&lt;/h4&gt;

&lt;p&gt;The last part of the ABAC process is authorisation logic. We added the logic to the middleware so that we could make a call to OPA for authorisation.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image2.png&quot; alt=&quot;&quot; style=&quot;width:60%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To ensure token validity after authentication, KCP extracts user attributes from the token payload and fetches resource attributes from the resource store. It combines the request metadata such as method and endpoint, along with the user and resource attributes into an OPA request. OPA then evaluates the request based on the redefined policy above and returns a response.&lt;/p&gt;

&lt;h2 id=&quot;auditability&quot;&gt;Auditability&lt;/h2&gt;

&lt;p&gt;For ABAC authorisation, there are two key areas of consideration:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Who made changes to the policy, who deployed, and when the change was made&lt;/li&gt;
  &lt;li&gt;Who accessed what resource and when&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We manage policies in a dedicated GitLab repository and changes are submitted via merge requests. Based on the commit history, we can easily tell who made changes, reviewed, approved, and deployed the policy. &lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/migrating-to-abac/image1.png&quot; alt=&quot;&quot; style=&quot;width:80%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;For resource access, OPA produces a decision log containing user attributes, resource attributes, and the authorisation decision for every call it serves. The log is kept for five days in Kibana for debugging purposes, then moved to S3 where it is kept for 28 days.&lt;/p&gt;

&lt;h2 id=&quot;impact&quot;&gt;Impact&lt;/h2&gt;

&lt;p&gt;The move to ABAC authorisation has improved our controls as compared to the previous RBAC model, with the biggest impact being fewer resources to manage. Some other benefits include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Optimised resource allocation: Discarded over 200 roles, 200 permissions, and almost 3000 unused resources from IAM services, simplifying our debugging process. Now, we can simply check the user and resource attributes as needed.&lt;/li&gt;
  &lt;li&gt;Simplified resource management: In the three months we have been using ABAC, about 600 resources have been added without any increase in complexity for authorisation, which is significantly lesser than the RBAC model.&lt;/li&gt;
  &lt;li&gt;Reduction in delays and waiting time: Engineers no longer have to wait for approval for KCP access.&lt;/li&gt;
  &lt;li&gt;Better governance over resource ownership and costs: ABAC allowed us to have a standardised and accurate tagging system of almost 3000 resources.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;learnings&quot;&gt;Learnings&lt;/h2&gt;

&lt;p&gt;Although ABAC does provide significant improvements over RBAC, it comes with its own caveats:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It needs a reliable and comprehensive attribute tagging system to function properly. This only became possible after roughly three months of identifying and tagging the ownership of existing resources by both automated and manual methods.&lt;/li&gt;
  &lt;li&gt;Tags should be kept up to date with the company’s growth. Teams could lose access to their resources if they are wrongly tagged. It needs a mechanism to keep up with changes, or people will unexpectedly lose access when user and resource attributes are changed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;To keep up with organisational growth, KCP needs to start listening to the IAM stream, which is where all IAM changes are published. This will allow KCP to regularly update user attributes and refresh resource attributes when restructuring occurs, allowing authorisation to be done with the right data.&lt;/li&gt;
  &lt;li&gt;Constant collaboration with HR to ensure that we maintain sufficient user attributes (no extra unused information) that remain clean so ABAC works as expected.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.openpolicyagent.org/&quot;&gt;OPA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.openpolicyagent.org/docs/latest/policy-language/&quot;&gt;Rego&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/zero-trust-with-kafka&quot;&gt;Zero trust with Kafka&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Mar 2023 01:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/migrating-to-abac</link>
        <guid isPermaLink="true">https://engineering.grab.com/migrating-to-abac</guid>
        
        <category>Engineering</category>
        
        <category>Access control</category>
        
        <category>Security</category>
        
        
        <category>Engineering</category>
        
        <category>Security</category>
        
      </item>
    
      <item>
        <title>Securing GitOps pipelines</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Grab’s real-time data platform team, Coban, has been managing infrastructure resources via Infrastructure-as-code (IaC). Through the IaC approach, Terraform is used to maintain infrastructure consistency, automation, and ease of deployment of our streaming infrastructure, notably:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://flink.apache.org/&quot;&gt;Flink&lt;/a&gt; pipelines&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kafka.apache.org/&quot;&gt;Kafka&lt;/a&gt; topics&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.confluent.io/platform/current/connect/index.html#kafka-connect&quot;&gt;Kafka Connect&lt;/a&gt; connectors&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With Grab’s exponential growth, there needs to be a better way to scale infrastructure automatically. Moving towards GitOps processes benefits us in many ways:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Versioned and immutable&lt;/strong&gt;: With our source code being stored in Git repositories, the desired state of infrastructure is stored in an environment that enforces immutability, versioning, and retention of version history, which helps with auditing and traceability.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Faster deployment&lt;/strong&gt;: By automating the process of deploying resources after code is merged, we eliminate manual steps and improve overall engineering productivity while maintaining consistency.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Easier rollbacks&lt;/strong&gt;: It’s as simple as making a revert for a Git commit as compared to creating a merge request (MR) and commenting Atlantis commands, which add extra steps and contribute to a higher mean-time-to-resolve (MTTR) for incidents.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Originally, Coban implemented automation on Terraform resources using &lt;a href=&quot;https://www.runatlantis.io/&quot;&gt;Atlantis&lt;/a&gt;, an application that operates based on user comments on MRs.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/atlantis-user-flow.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 1 User flow with Atlantis&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We have come a long way with Atlantis. It has helped us to automate our workflows and enable self-service capabilities for our engineers. However, there were a few limitations in our setup, which we wanted to improve:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Coarse grained&lt;/strong&gt;: There is no way to restrict the kind of Terraform resources users can create, which introduces security issues. For example, if a user is one of the &lt;a href=&quot;https://docs.gitlab.com/ee/user/project/code_owners.html&quot;&gt;Code owners&lt;/a&gt;, they can create another IAM role with Admin privileges with approval from their own team anywhere in the repository.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Limited automation&lt;/strong&gt;: Users are still required to make comments in their MR such as &lt;a href=&quot;https://www.runatlantis.io/docs/using-atlantis.html#atlantis-apply&quot;&gt;atlantis apply&lt;/a&gt;. This requires the learning of Atlantis commands and is prone to human errors.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Limited capability&lt;/strong&gt;: Having to rely entirely on Terraform and Hashicorp Configuration Language (HCL) functions to validate user input comes with limitations. For example, the ability to validate an input variable based on the value of another has been a &lt;a href=&quot;https://github.com/hashicorp/terraform/issues/25609&quot;&gt;requested feature&lt;/a&gt; for a long time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Not adhering to Don’t Repeat Yourself (DRY) principle&lt;/strong&gt;: Users need to create an entire Terraform project with boilerplate codes such as Terraform environment, local variables, and Terraform provider configurations to create a simple resource such as a Kafka topic.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;We have developed an in-house GitOps solution named Khone. Its name was inspired by the &lt;a href=&quot;https://en.wikipedia.org/wiki/Khone_Phapheng_Falls&quot;&gt;Khone Phapheng Waterfall&lt;/a&gt;. We have evaluated some of the best and most widely used GitOps products available but chose not to go with any as the majority of them aim to support Kubernetes native or &lt;a href=&quot;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/&quot;&gt;custom resources&lt;/a&gt;, and we needed infrastructure provisioning that is beyond Kubernetes. With our approach, we have full control of the entire user flow and its implementation, and thus we benefit from:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Security&lt;/strong&gt;: The ability to secure the pipeline with many customised scripts and workflows.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Simple user experience (UX)&lt;/strong&gt;: Simplified user flow and prevents human errors with automation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;DRY&lt;/strong&gt;: Minimise boilerplate codes. Users only need to create a single Terraform resource and not an entire Terraform project.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/khone-user-flow.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 2 User flow with Khone&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;With all types of streaming infrastructure resources that we support, be it Kafka topics or Flink pipelines, we have identified they all have common properties such as namespace, environment, or cluster name such as Kafka cluster and Kubernetes cluster. As such, using those values as file paths help us to easily validate users input and de-couple them from the resource specific configuration properties in their HCL source code. Moreover, it helps to remove redundant information to maintain consistency. If the piece of information is in the file path, it won’t be elsewhere in resource definition.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/khone-directory-structure.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 3 Khone directory structure&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;With this approach, we can utilise our pipeline scripts, which are written in Python and perform validations on the types of resources and resource names using Regular Expressions (Regex) without relying on HCL functions. Furthermore, we helped prevent human errors and improved developers’ efficiency by deriving these properties and reducing boilerplate codes by automatically parsing out other necessary configurations such as Kafka brokers endpoint from the cluster name and environment.&lt;/p&gt;

&lt;h3 id=&quot;pipeline-stages&quot;&gt;Pipeline stages&lt;/h3&gt;

&lt;p&gt;Khone’s pipeline implementation is designed with three stages. Each stage has different duties and responsibilities in verifying user input and securely creating the resources.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/khone-pipeline-example.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 4 An example of a Khone pipeline&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;initialisation-stage&quot;&gt;Initialisation stage&lt;/h4&gt;

&lt;p&gt;At this stage, we categorise the changes into Deleted, Created or Changed resources and filter out unsupported resource types. We also prevent users from creating unintended resources by validating them based on resource path and inspecting the HCL source code in their Terraform module. This stage also prepares artefacts for subsequent stages.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/terraform-changes.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 5 Terraform changes detected by Khone&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;terraform-stage&quot;&gt;Terraform stage&lt;/h4&gt;

&lt;p&gt;This is a downstream pipeline that runs either the Terraform plan or Terraform apply command depending on the state of the MR, which can either be pending review or merged. &lt;a href=&quot;https://engineering.grab.com/how-we-reduced-our-ci-yaml&quot;&gt;Individual jobs run in parallel&lt;/a&gt; for each resource change, which helps with performance and reduces the overall pipeline run time.&lt;/p&gt;

&lt;p&gt;For each individual job, we implemented multiple security checkpoints such as:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Code inspection&lt;/strong&gt;: We use the &lt;a href=&quot;https://pypi.org/project/python-hcl2/&quot;&gt;python-hcl2&lt;/a&gt; library to read HCL content of Terraform resources to perform validation, restrict the types of Terraform resources users can create, and ensure that resources have the intended configurations. We also validate whitelisted Terraform module source endpoint based on the declared resource type. This enables us to inherit the flexibility of Python as a programming language and perform validations more dynamically rather than relying on HCL functions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Resource validation&lt;/strong&gt;: We validate configurations based on resource path to ensure users are following the correct and intended directory structure.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Linting and formatting&lt;/strong&gt;: Perform HCL code linting and formatting using Terraform CLI to ensure code consistency.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Furthermore, our Terraform module independently validates parameters by verifying the working directory instead of relying on user input, acting as an additional layer of defence for validation.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;path = one(regexall(join(&quot;/&quot;,
[
    &quot;^*&quot;,
    &quot;(?P&amp;lt;repository&amp;gt;khone|khone-dev)&quot;,
    &quot;resources&quot;,
    &quot;(?P&amp;lt;namespace&amp;gt;[^/]*)&quot;,
    &quot;(?P&amp;lt;resource_type&amp;gt;[^/]*)&quot;,
    &quot;(?P&amp;lt;env&amp;gt;[^/]*)&quot;,
    &quot;(?P&amp;lt;cluster_name&amp;gt;[^/]*)&quot;,
    &quot;(?P&amp;lt;resource_name&amp;gt;[^/]*)$&quot;
]), path.cwd))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;metric-stage&quot;&gt;Metric stage&lt;/h4&gt;

&lt;p&gt;In this stage, we consolidate previous jobs’ status and publish our pipeline metrics such as success or error rate.&lt;/p&gt;

&lt;p&gt;For our metrics, we identified actual users by omitting users from Coban. This helps us measure success metrics more consistently as we could isolate metrics from test continuous integration/continuous deployment (CI/CD) pipelines.&lt;/p&gt;

&lt;p&gt;For the second half of 2022, we achieved a 100% uptime for Khone pipelines.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/success-metrics.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 6 Khone's success metrics for the second half of 2022&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;preventing-pipeline-config-tampering&quot;&gt;Preventing pipeline config tampering&lt;/h3&gt;

&lt;p&gt;By default, with each repository on GitLab that has CI/CD pipelines enabled, owners or administrators would need to have a pipeline config file at the root directory of the repository with the name &lt;strong&gt;.gitlab-ci.yml&lt;/strong&gt;. Other scripts may also be stored somewhere within the repository.&lt;/p&gt;

&lt;p&gt;With this setup, whenever a user creates an MR, if the pipeline config file is modified as part of the MR, the modified version of the config file will be immediately reflected in the pipeline’s run. Users can exploit this by running arbitrary code on the privileged GitLab runner.&lt;/p&gt;

&lt;p&gt;In order to prevent this, we utilise GitLab’s &lt;a href=&quot;https://docs.gitlab.com/ee/ci/pipelines/settings.html#specify-a-custom-cicd-configuration-file&quot;&gt;remote pipeline config&lt;/a&gt; functionality. We have created another private repository, &lt;strong&gt;khone-admin&lt;/strong&gt;, and stored our pipeline config there.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/khone-remote-pipeline-config.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 7 Khone's remote pipeline config&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Fig. 7, our configuration is set to a file called &lt;strong&gt;khone-gitlab-ci.yml&lt;/strong&gt; residing in the &lt;strong&gt;khone-admin&lt;/strong&gt; repository under &lt;strong&gt;snd&lt;/strong&gt; group.&lt;/p&gt;

&lt;h3 id=&quot;preventing-pipeline-scripts-tampering&quot;&gt;Preventing pipeline scripts tampering&lt;/h3&gt;

&lt;p&gt;We had scripts that ran before the MR and they were approved and merged to perform preliminary checks or validations. They were also used to run the Terraform plan command. Users could modify these existing scripts to perform malicious actions. For example, they could bypass all validations and directly run the Terraform apply command to create unintended resources.&lt;/p&gt;

&lt;p&gt;This can be prevented by storing all of our scripts in the &lt;strong&gt;khone-admin&lt;/strong&gt; repository and cloning them in each stage of our pipeline using the &lt;strong&gt;before_script&lt;/strong&gt; clause.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;default:
  before_script:
    - rm -rf khone_admin
    - git clone --depth 1 --single-branch https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.myteksi.net/snd/khone-admin.git khone_admin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Even though this adds an overhead to each of our pipeline jobs and increases run time, the amount is insignificant as we have optimised the process by using shallow cloning. The Git clone command included in the above script with &lt;strong&gt;depth=1&lt;/strong&gt; and &lt;strong&gt;single-branch&lt;/strong&gt; flag has reduced the time it takes to clone the scripts down to only &lt;strong&gt;0.59 seconds&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;testing-our-pipeline&quot;&gt;Testing our pipeline&lt;/h3&gt;

&lt;p&gt;With all the security measures implemented for Khone, this raises a question of how did we test the pipeline? We have done this by setting up an additional repository called &lt;strong&gt;khone-dev&lt;/strong&gt;.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/repo-relationship.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 8 Repositories relationship&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h4 id=&quot;pipeline-config&quot;&gt;Pipeline config&lt;/h4&gt;

&lt;p&gt;Within this &lt;strong&gt;khone-dev&lt;/strong&gt; repository, we have set up a remote pipeline config file following this format:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;File Name&amp;gt;@&amp;lt;Repository Ref&amp;gt;:&amp;lt;Branch Name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/securing-gitops-pipeline/khone-dev-remote.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;&lt;i&gt;Fig. 9 Khone-dev's remote pipeline config&lt;/i&gt;&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;In Fig. 9, our configuration is set to a file called &lt;strong&gt;khone-gitlab-ci.yml&lt;/strong&gt; residing in the &lt;strong&gt;khone-admin&lt;/strong&gt; repository under the &lt;strong&gt;snd&lt;/strong&gt; group and under a branch named &lt;strong&gt;ci-test&lt;/strong&gt;. With this approach, we can test our pipeline config without having to merge it to master branch that affects the main Khone repository. As a security measure, we only allow users within a certain GitLab group to push changes to this branch.&lt;/p&gt;

&lt;h4 id=&quot;pipeline-scripts&quot;&gt;Pipeline scripts&lt;/h4&gt;

&lt;p&gt;Following the same method for pipeline scripts, instead of cloning from the master branch in the &lt;strong&gt;khone-admin&lt;/strong&gt; repository, we have implemented a logic to clone them from the branch matching our lightweight directory access protocol (LDAP) user account if it exists. We utilised the &lt;strong&gt;GITLAB_USER_LOGIN&lt;/strong&gt; environment variable that is injected by GitLab to each individual CI job to get the respective LDAP account to perform this logic.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;default:
  before_script:
    - rm -rf khone_admin
    - |
      if git ls-remote --exit-code --heads &quot;https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.myteksi.net/snd/khone-admin.git&quot; &quot;$GITLAB_USER_LOGIN&quot; &amp;gt; /dev/null; then
        echo &quot;Cloning khone-admin from dev branch ${GITLAB_USER_LOGIN}&quot;
        git clone --depth 1 --branch &quot;$GITLAB_USER_LOGIN&quot; --single-branch &quot;https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.myteksi.net/snd/khone-admin.git&quot; khone_admin
      else
        echo &quot;Dev branch ${GITLAB_USER_LOGIN} not found, cloning from master instead&quot;
        git clone --depth 1 --single-branch &quot;https://gitlab-ci-token:${CI_JOB_TOKEN}@gitlab.myteksi.net/snd/khone-admin.git&quot; khone_admin
      fi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;p&gt;With security being our main focus for our Khone GitOps pipeline, we plan to abide by the &lt;a href=&quot;https://en.wikipedia.org/wiki/Principle_of_least_privilege&quot;&gt;principle of least privilege&lt;/a&gt; and implement separate GitLab runners for different types of resources and assign them with just enough IAM roles and policies, and minimal network security group rules to access our Kafka or Kubernetes clusters.&lt;/p&gt;

&lt;p&gt;Furthermore, we also plan to maintain high standards and stability by including unit tests in our CI scripts to ensure that every change is well-tested before being deployed.&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/ee/ci/pipelines/settings.html#specify-a-custom-cicd-configuration-file&quot;&gt;Specify a custom CI/CD configuration file&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.aws.amazon.com/eks/latest/userguide/iam-roles-for-service-accounts.html&quot;&gt;IAM roles for service accounts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.gitlab.com/ee/user/project/code_owners.html&quot;&gt;GitLab code owners&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;small class=&quot;credits&quot;&gt;Special thanks to Fabrice Harbulot for kicking off this project and building a strong foundation for it.&lt;/small&gt;&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Wed, 01 Mar 2023 02:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/securing-gitops-pipeline</link>
        <guid isPermaLink="true">https://engineering.grab.com/securing-gitops-pipeline</guid>
        
        <category>Engineering</category>
        
        <category>Open source</category>
        
        <category>Pipelines</category>
        
        <category>Continuous Delivery</category>
        
        <category>Continuous Integration</category>
        
        <category>Optimisation</category>
        
        
        <category>Engineering</category>
        
      </item>
    
      <item>
        <title>New zoom freezing feature for Geohash plugin</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Geohash is an encoding system with a unique identifier for each region on the planet. Therefore, all geohash units can be associated with an individual set of digits and letters.&lt;/p&gt;

&lt;p&gt;Geohash is a plugin built by Grab that is available in the Java OpenStreetMap Editor (JOSM) tool, which comes in handy for those who work on precise areas based on geohash units.&lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;Up until recently, users of the Geohash JOSM plugin were unable to stop the displaying of new geohashes with every zoom-in or zoom-out. This meant that every time they changed the zoom, new geohashes would be displayed, and this became bothersome for many users when it was unneeded. The previous behaviour of the plugin when zooming in and out is depicted in the following short video:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/geohash-plugin/image7.gif&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;This led to the implementation of the zoom freeze feature, which helps users toggle between Enable zoom freeze and Disable zoom freeze, based on their needs.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;As you can see in the following image, a new label was created with the purpose of freezing or unfreezing the display of new geohashes with each zoom change:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/geohash-plugin/image3.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;By default, this label says “Enable zoom freeze”, and when zoom freezing is enabled, the label changes to “Disable zoom freeze”.&lt;/p&gt;

&lt;p&gt;In order to see how zoom freezing works, let’s consider the following example: a user wants to zoom inside the geohash with the code w886hu, without triggering the display of smaller geohashes inside of it. For this purpose, the user will enable the zoom freezing feature by clicking on the label, and then they will proceed with the zoom. The map will look like this:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/geohash-plugin/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;It is apparent from the image that no new geohashes were created. Now, let’s say the user has finished what they wanted to do, and wants to go back to the “normal” geohash visualisation mode, which means disabling the zoom freeze option. After clicking on the label that now says ‘Disable zoom freeze’, new, smaller geohashes will be displayed, according to the current zoom level:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/geohash-plugin/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The functionality is illustrated in the following short video:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/geohash-plugin/image5.gif&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Another effect that enabling zoom freeze has is that it disables the ‘Display larger geohashes’ and ‘Display smaller geohashes’ options, since the geohashes are now fixed. The following images show how these options work before and after disabling zoom freeze:&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/geohash-plugin/image6.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/geohash-plugin/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;To conclude, we believe that the release of this new feature will benefit users by making it more comfortable for them to zoom in and out of a map. By turning off the display of new geohashes when this is unwanted, map readability is improved, and this translates to a better user experience.&lt;/p&gt;

&lt;h2 id=&quot;impactlimitations&quot;&gt;Impact/Limitations&lt;/h2&gt;

&lt;p&gt;In order to start using this new feature, users need to update the Geohash JOSM plugin.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;p&gt;Grab has come a long way in map-making, from using open source map-making software and developing its own suite of map-making tools to contributing to the open-source map community and building and launching GrabMaps. To find out more, read &lt;a href=&quot;/kartacam-powers-grabmaps&quot;&gt;How KartaCam powers GrabMaps&lt;/a&gt; and &lt;a href=&quot;https://www.grab.com/sg/enterprise-blog/kartacam-delivers-comprehensive-cost-effective-mapping-data/&quot;&gt;KartaCam delivers comprehensive, cost-effective mapping data&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Tue, 21 Feb 2023 01:18:05 +0000</pubDate>
        <link>https://engineering.grab.com/geohash-plugin</link>
        <guid isPermaLink="true">https://engineering.grab.com/geohash-plugin</guid>
        
        <category>Engineering</category>
        
        <category>Geohash</category>
        
        <category>Maps</category>
        
        <category>Open source</category>
        
        
        <category>Engineering</category>
        
        <category>Product</category>
        
      </item>
    
      <item>
        <title>Graph service platform</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In earlier articles of this series, we covered the &lt;a href=&quot;/graph-networks&quot;&gt;importance of graph networks&lt;/a&gt;, &lt;a href=&quot;/graph-concepts&quot;&gt;graph concepts&lt;/a&gt;, &lt;a href=&quot;/graph-visualisation&quot;&gt;how graph visualisation makes fraud investigations easier and more effective&lt;/a&gt;, and &lt;a href=&quot;/graph-for-fraud-detection&quot;&gt;how graphs for fraud detection work&lt;/a&gt;. In this article, we elaborate on the need for a graph service platform and how it works.&lt;/p&gt;

&lt;p&gt;In the present age, data linkages can generate significant business value. Whether we want to learn about the relationships between users in online social networks, between users and products in e-commerce, or understand credit relationships in financial networks, the capability to understand and analyse large amounts of highly interrelated data is becoming more important to businesses.&lt;/p&gt;

&lt;p&gt;As the amount of consumer data grows, the GrabDefence team must continuously enhance fraud detection on mobile devices to proactively identify the presence of fraudulent or malicious users. Even simple financial transactions between users must be monitored for transaction loops and money laundering. To preemptively detect such scenarios, we need a graph service platform to help discover data linkages. &lt;/p&gt;

&lt;h2 id=&quot;background&quot;&gt;Background&lt;/h2&gt;

&lt;p&gt;As mentioned in an &lt;a href=&quot;/graph-concepts&quot;&gt;earlier article&lt;/a&gt;, a graph is a model representation of the association of entities and holds knowledge in a structured way by marginalising entities and relationships. In other words, graphs hold a natural interpretability of linked data and graph technology plays an important role. Since the early days, large tech companies started to create their own graph technology infrastructure, which is used for things like social relationship mining, web search, and sorting and recommendation systems with great commercial success.&lt;/p&gt;

&lt;p&gt;As graph technology was developed, the amount of data gathered from graphs started to grow as well, leading to a need for graph databases. Graph databases&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; are used to store, manipulate, and access graph data on the basis of graph models. It is similar to the relational database with the feature of Online Transactional Processing (OLTP), which supports transactions, persistence, and other features.&lt;/p&gt;

&lt;p&gt;A key concept of graphs is the edge or relationship between entities. The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes. These relationships allow data in the store to be linked directly and retrieved with one operation.&lt;/p&gt;

&lt;p&gt;With graph databases, relationships between data can be queried fast as they are perpetually stored in the database. Additionally, relationships can be intuitively visualised using graph databases, making them useful for heavily interconnected data. To have real-time graph search capabilities, we must leverage the graph service platform and graph databases.&lt;/p&gt;

&lt;h2 id=&quot;architecture-details&quot;&gt;Architecture details&lt;/h2&gt;

&lt;p&gt;Graph services with graph databases are Platforms as a Service (PaaS) that encapsulate the underlying implementation of graph technology and support easier discovery of data association relationships with graph technologies.&lt;/p&gt;

&lt;p&gt;They also provide universal graph operation APIs and service management for users. This means that users do not need to build graph runtime environments independently and can explore the value of data with graph service directly.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/graph-service-platform/image5.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 1 Graph service platform system architecture&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;As shown in Fig. 1, the system can be divided into four layers:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Storage backend&lt;/strong&gt; - Different forms of data (for example, CSV files) are stored in Amazon S3, graph data stores in Neptune and meta configuration stores in DynamoDB.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Driver&lt;/strong&gt; - Contains drivers such as Gremlin, Neptune, S3, and DynamoDB.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Service&lt;/strong&gt; - Manages clusters, instances, databases etc, provides management API, includes schema and data load management, graph operation logic, and other graph algorithms.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RESTful APIs&lt;/strong&gt; - Currently supports the standard and uniform formats provided by the system, the Management API, Search API for OLTP, and Analysis API for online analytical processing (OLAP).&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How it works&lt;/h2&gt;

&lt;h3 id=&quot;graph-flow&quot;&gt;Graph flow&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/graph-service-platform/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 2 Graph flow&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;CSV files stored in Amazon S3 are processed by extract, transform, and load (ETL) tools to generate graph data. This data is then managed by an Amazon Neptune DB cluster, which can only be accessed by users through graph service. Graph service converts user requests into asynchronous interactions with Neptune Cluster, which returns the results to users.&lt;/p&gt;

&lt;p&gt;When users launch data load tasks, graph service synchronises the entity and attribute information with the CSV file in S3, and the schema stored in DynamoDB. The data is only imported into Neptune if there are no inconsistencies.&lt;/p&gt;

&lt;p&gt;The most important component in the system is the graph service, which provides RESTful APIs for two scenarios: graph search for real-time streams and graph analysis for batch processing. At the same time, the graph service manages clusters, databases, instances, users, tasks, and meta configurations stored in DynamoDB, which implements features of service monitor and data loading offline or stream ingress online.&lt;/p&gt;

&lt;h3 id=&quot;use-casein-fraud-detection&quot;&gt;Use case in fraud detection&lt;/h3&gt;

&lt;p&gt;In Grab’s mobility business, we have come across situations where multiple accounts use shared physical devices to maximise their earning potential. With the graph capabilities provided by the graph service platform, we can clearly see the connections between multiple accounts and shared devices.&lt;/p&gt;

&lt;p&gt;Historical device and account data are stored in the graph service platform via offline data loading or online stream injection. If the device and account data exists in the graph service platform, we can find the adjacent account IDs or the shared device IDs by using the device ID or account ID respectively specified in the user request.&lt;/p&gt;

&lt;p&gt;In our experience, fraudsters tend to share physical resources to maximise their revenue. The following image shows a device that is shared by many users. With our Graph Visualisation platform based on graph service, you can see exactly what this pattern looks like.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/graph-service-platform/image3.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig 3. Example of a device being shared with many users&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;h3 id=&quot;data-injection&quot;&gt;Data injection&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/graph-service-platform/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 4 Data injection&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;Graph service also supports data injection features, including data load by request (task with a type of data load) and real-time stream write by Kafka.  &lt;/p&gt;

&lt;p&gt;When connected to GrabDefence’s infrastructure, Confluent with Kafka is used as the streaming engine.  The purpose of using Kafka as a streaming write engine is two-fold: to provide primary user authentication and to relieve the pressure on Neptune.&lt;/p&gt;

&lt;h2 id=&quot;impact&quot;&gt;Impact&lt;/h2&gt;

&lt;p&gt;Graph service supports data management of Labelled Property Graphs and provides the capability to add, delete, update, and get vertices, edges, and properties for some graph models. Graph traversal and searching relationships with RESTful APIs are also more convenient with graph service.&lt;/p&gt;

&lt;p&gt;Businesses usually do not need to focus on the underlying data storage, just designing graph schemas for model definition according to their needs. With the graph service platform, platforms or systems can be built for personalised search, intelligent Q&amp;amp;A, financial fraud, etc.&lt;/p&gt;

&lt;p&gt;For big organisations, extensive graph algorithms provide the power to mine various entity connectivity relationships in massive amounts of data. The growth and expansion of new businesses is driven by discovering the value of data.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/graph-service-platform/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Fig. 5 Graph-centric ecosystems&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We are building an integrated graph ecosystem inside and outside Grab. The infrastructure and service, or APIs are key components in graph-centric ecosystems; they provide graph arithmetic and basic capabilities of graphs in relation to search, computing, analysis etc. Besides that, we will also consider incorporating applications such as risk prediction and fraud detection in order to serve our current business needs.&lt;/p&gt;

&lt;h2 id=&quot;speak-to-us&quot;&gt;Speak to us&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.grab.com/sg/business/defence/&quot;&gt;GrabDefence&lt;/a&gt; is a proprietary fraud prevention platform built by Grab, Southeast Asia’s leading superapp. Since 2019, the GrabDefence team has shared its fraud management capabilities and platform with enterprises and startups to leverage Grab’s advanced AI/ML models, hyper local insights and patented device intelligence technologies.&lt;/p&gt;

&lt;p&gt;To learn more about GrabDefence or to speak to our fraud management experts, contact us at &lt;a href=&quot;mailto:gd.contact@grabtaxi.com&quot;&gt;gd.contact@grabtaxi.com&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://neo4j.com/developer/graph-database/&quot;&gt;What is a Graph Database? - Developer Guides&lt;/a&gt; &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Thu, 05 Jan 2023 01:18:05 +0000</pubDate>
        <link>https://engineering.grab.com/graph-service-platform</link>
        <guid isPermaLink="true">https://engineering.grab.com/graph-service-platform</guid>
        
        <category>Engineering</category>
        
        <category>Graph networks</category>
        
        <category>Graphs</category>
        
        <category>Graph visualisation</category>
        
        <category>Security</category>
        
        <category>Analytics</category>
        
        <category>Fraud detection</category>
        
        
        <category>Engineering</category>
        
        <category>Security</category>
        
        <category>Data Science</category>
        
      </item>
    
      <item>
        <title>Zero trust with Kafka</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Grab’s real-time data platform team, also known as Coban, has been operating large-scale Kafka clusters for all Grab verticals, with a strong focus on ensuring a best-in-class-performance and 99.99% availability.&lt;/p&gt;

&lt;p&gt;Security has always been one of Grab’s top priorities and as fraudsters continue to evolve, there is an increased need to continue strengthening the security of our data streaming platform. One of the ways of doing this is to move from a pure network-based access control to state-of-the-art security and zero trust by default, such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Authentication&lt;/strong&gt;: The identity of any remote systems - clients and servers - is established and ascertained first, prior to any further communications.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Authorisation&lt;/strong&gt;: Access to Kafka is granted based on the principle of least privilege; no access is given by default. Kafka clients are associated with the whitelisted Kafka topics and permissions - consume or produce - they strictly need. Also, granted access is auditable.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Confidentiality&lt;/strong&gt;: All in-transit traffic is encrypted.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;We decided to use mutual Transport Layer Security (mTLS) for authentication and encryption. mTLS enables clients to authenticate servers, and servers to reciprocally authenticate clients.&lt;/p&gt;

&lt;p&gt;Kafka supports other authentication mechanisms, like OAuth, or Salted Challenge Response Authentication Mechanism (SCRAM), but we chose mTLS because it is able to verify the peer’s identity offline. This verification ability means that systems do not need an active connection to an authentication server to ascertain the identity of a peer. This enables operating in disparate network environments, where all parties do not necessarily have access to such a central authority.&lt;/p&gt;

&lt;p&gt;We opted for &lt;a href=&quot;https://www.vaultproject.io/&quot;&gt;Hashicorp Vault&lt;/a&gt; and its &lt;a href=&quot;https://www.vaultproject.io/docs/secrets/pki&quot;&gt;PKI engine&lt;/a&gt; to dynamically generate clients and servers’ certificates. This enables us to enforce the usage of short-lived certificates for clients, which is a way to mitigate the potential impact of a client certificate being compromised or maliciously shared. We said zero trust, right?&lt;/p&gt;

&lt;p&gt;For authorisation, we chose Policy-Based Access Control (PBAC), a more scalable solution than Role-Based Access Control (RBAC), and the &lt;a href=&quot;https://www.openpolicyagent.org/&quot;&gt;Open Policy Agent&lt;/a&gt; (OPA) as our policy engine, for its wide community support.&lt;/p&gt;

&lt;p&gt;To integrate mTLS and the OPA with Kafka, we leveraged &lt;a href=&quot;https://strimzi.io/&quot;&gt;Strimzi&lt;/a&gt;, the Kafka on Kubernetes operator. In a previous &lt;a href=&quot;/exposing-kafka-cluster&quot;&gt;article&lt;/a&gt;, we have alluded to Strimzi and hinted at how it would help with scalability and cloud agnosticism. Built-in security is undoubtedly an additional driver of our adoption of Strimzi.&lt;/p&gt;

&lt;h3 id=&quot;server-authentication&quot;&gt;Server authentication&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/zero-trust-with-kafka/image4.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 1 - Server authentication process for internal cluster communications&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;We first set up a single Root Certificate Authority (CA) for each environment (staging, production, etc.). This Root CA, in blue on the diagram, is securely managed by the Hashicorp Vault cluster. Note that the color of the certificates, keys, signing arrows and signatures on the diagrams are consistent throughout this article.&lt;/p&gt;

&lt;p&gt;To secure the cluster’s internal communications, like the communications between the Kafka broker and Zookeeper pods, Strimzi sets up a Cluster CA, which is signed by the Root CA (step 1). The Cluster CA is then used to sign the individual Kafka broker and zookeeper certificates (step 2). Lastly, the Root CA’s public certificate is imported into the truststores of both the Kafka broker and Zookeeper (step 3), so that all pods can mutually verify their certificates when authenticating one with the other.&lt;/p&gt;

&lt;p&gt;Strimzi’s embedded Cluster CA dynamically generates valid individual certificates when spinning up new Kafka and Zookeeper pods. The signing operation (step 2) is handled automatically by Strimzi.&lt;/p&gt;

&lt;p&gt;For client access to Kafka brokers, Strimzi creates a different set of intermediate CA and server certificates, as shown in the next diagram.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/zero-trust-with-kafka/image5.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 2 - Server authentication process for client access to Kafka brokers&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;The same Root CA from Figure 1 now signs a different intermediate CA, which the Strimzi community calls the Client CA (step 1). This naming is misleading since it does not actually sign any client certificates, but only the server certificates (step 2) that are set up on the external listener of the Kafka brokers. These server certificates are for the Kafka clients to authenticate the servers. This time, the Root CA’s public certificate will be imported into the Kafka Client truststore (step 3).&lt;/p&gt;

&lt;h3 id=&quot;clientauthentication&quot;&gt;Client authentication&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/zero-trust-with-kafka/image1.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 3 - Client authentication process&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;For client authentication, the Kafka client first needs to authenticate to Hashicorp Vault and request an ephemeral certificate from the Vault PKI engine (step 1). Vault then issues a certificate and signs it using its Root CA (step 2). With this certificate, the client can now authenticate to Kafka brokers, who will use the Root CA’s public certificate already in their truststore, as previously described (step 3).&lt;/p&gt;

&lt;h3 id=&quot;ca-tree&quot;&gt;CA tree&lt;/h3&gt;
&lt;p&gt;Putting together the three different authentication processes we have just covered, the CA tree now looks like this. Note that this is a simplified view for a single environment, a single cluster, and two clients only.&lt;/p&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/zero-trust-with-kafka/image3.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 4 - Complete certificate authority tree&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;As mentioned earlier, each environment (staging, production, etc.) has its own Root CA. Within an environment, each Strimzi cluster has its own pair of intermediate CAs: the Cluster CA and the Client CA. At the leaf level, the Zookeeper and Kafka broker pods each have their own individual certificates.&lt;/p&gt;

&lt;p&gt;On the right side of the diagram, each Kafka client can get an ephemeral certificate from Hashicorp Vault whenever they need to connect to Kafka. Each team or application has a dedicated Vault PKI role in Hashicorp Vault, restricting what can be requested for its certificate (e.g., Subject, TTL, etc.).&lt;/p&gt;

&lt;h3 id=&quot;strimzi-deployment&quot;&gt;Strimzi deployment&lt;/h3&gt;

&lt;p&gt;We heavily use Terraform to manage and provision our Kafka and Kafka-related components. This enables us to quickly and reliably spin up new clusters and perform cluster scaling operations.&lt;/p&gt;

&lt;p&gt;Under the hood, Strimzi Kafka deployment is a Kubernetes deployment. To increase the performance and the reliability of the Kafka cluster, we create dedicated Kubernetes nodes for each Strimzi Kafka broker and each Zookeeper pod, using &lt;a href=&quot;https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/&quot;&gt;Kubernetes taints and tolerations&lt;/a&gt;. This ensures that all resources of a single node are dedicated solely to either a single Kafka broker or a single Zookeeper pod.&lt;/p&gt;

&lt;p&gt;We also decided to go with a single Kafka cluster by Kubernetes cluster to make the management easier.&lt;/p&gt;

&lt;h3 id=&quot;client-setup&quot;&gt;Client setup&lt;/h3&gt;

&lt;p&gt;Coban provides backend microservice teams from all Grab verticals with a popular Kafka SDK in Golang, to standardise how teams utilise Coban Kafka clusters. Adding mTLS support mostly boils down to upgrading our SDK.&lt;/p&gt;

&lt;p&gt;Our enhanced SDK provides a default mTLS configuration that works out of the box for most teams, while still allowing customisation, e.g., for teams that have their own Hashicorp Vault Infrastructure for compliance reasons. Similarly, clients can choose among various Vault auth methods such as &lt;a href=&quot;https://developer.hashicorp.com/vault/docs/auth/aws&quot;&gt;AWS&lt;/a&gt; or &lt;a href=&quot;https://developer.hashicorp.com/vault/docs/auth/kubernetes&quot;&gt;Kubernetes&lt;/a&gt; to authenticate to Hashicorp Vault, or even implement their own logic for getting a valid client certificate.&lt;/p&gt;

&lt;p&gt;To mitigate the potential risk of a user maliciously sharing their application’s certificate with other applications or users, we limit the maximum Time-To-Live (TTL) for any given certificate. This also removes the overhead of maintaining a Certificate Revocation List (CRL). Additionally, our SDK stores the certificate and its associated private key in memory only, never on disk, hence reducing the attack surface.&lt;/p&gt;

&lt;p&gt;In our case, Hashicorp Vault is a dependency. To prevent it from reducing the overall availability of our data streaming platform, we have added two features to our SDK – a configurable retry mechanism and automatic renewal of clients’ short-lived certificates when two thirds of their TTL is reached. The upgraded SDK also produces new metrics around this certificate renewal process, enabling better monitoring and alerting.&lt;/p&gt;

&lt;h3 id=&quot;authorisation&quot;&gt;Authorisation&lt;/h3&gt;

&lt;div class=&quot;post-image-section&quot;&gt;&lt;figure&gt;
  &lt;img src=&quot;/img/zero-trust-with-kafka/image2.png&quot; alt=&quot;&quot; style=&quot;width:70%&quot; /&gt;&lt;figcaption align=&quot;middle&quot;&gt;Figure 5 - Authorisation process before a client can access a Kafka record&lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;

&lt;p&gt;For authorisation, we set up the Open Policy Agent (OPA) as a standalone deployment in the Kubernetes cluster, and configured Strimzi to integrate the Kafka brokers with that OPA.&lt;/p&gt;

&lt;p&gt;OPA policies - written in the &lt;a href=&quot;https://www.openpolicyagent.org/docs/latest/policy-language/&quot;&gt;Rego&lt;/a&gt; language - describe the authorisation logic. They are created in a GitLab repository along with the authorisation rules, called data sources (step 1). Whenever there is a change, a GitLab CI pipeline automatically creates a bundle of the policies and data sources, and pushes it to an S3 bucket (step 2). From there, it is fetched by the OPA (step 3).&lt;/p&gt;

&lt;p&gt;When a client - identified by its TLS certificate’s Subject - attempts to consume or produce a Kafka record (step 4), the Kafka broker pod first issues an authorisation request to the OPA (step 5) before processing the client’s request. The outcome of the authorisation request is then cached by the Kafka broker pod to improve performance.&lt;/p&gt;

&lt;p&gt;As the core component of the authorisation process, the OPA is deployed with the same high availability as the Kafka cluster itself, i.e. spread across the same number of Availability Zones. Also, we decided to go with one dedicated OPA by Kafka cluster instead of having a unique global OPA shared between multiple clusters. This is to reduce the blast radius of any OPA incidents.&lt;/p&gt;

&lt;p&gt;For monitoring and alerting around authorisation, we submitted an &lt;a href=&quot;https://github.com/StyraInc/opa-kafka-plugin/pull/38&quot;&gt;Open Source contribution&lt;/a&gt; in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;opa-kafka-plugin&lt;/code&gt; project in order to enable the OPA authoriser to expose some metrics. Our contribution to the open source code allows us to monitor various aspects of the OPA, such as the number of authorised and unauthorised requests, as well as the cache hit-and-miss rates. Also, we set up alerts for suspicious activity such as unauthorised requests.&lt;/p&gt;

&lt;p&gt;Finally, as a platform team, we need to make authorisation a scalable, self-service process. Thus, we rely on the Git repository’s permissions to let Kafka topics’ owners approve the data source changes pertaining to their topics.&lt;/p&gt;

&lt;p&gt;Teams who need their applications to access a Kafka topic would write and submit a JSON data source as simple as this:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
 &quot;example_topic&quot;: {
   &quot;read&quot;: [
     &quot;clientA.grab&quot;,
     &quot;clientB.grab&quot;
   ],
   &quot;write&quot;: [
     &quot;clientB.grab&quot;
   ]
 }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;GitLab CI unit tests and business logic checks are set up in the Git repository to ensure that the submitted changes are valid. After that, the change would be submitted to the topic’s owner for review and approval.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h2&gt;

&lt;p&gt;The performance impact of this security design is significant compared to unauthenticated, unauthorised, plaintext Kafka. We observed a drop in throughput, mostly due to the low performance of encryption and decryption in Java, and are currently benchmarking different encryption ciphers to mitigate this.&lt;/p&gt;

&lt;p&gt;Also, on authorisation, our current PBAC design is pretty static, with a list of applications granted access for each topic. In the future, we plan to move to Attribute-Based Access Control (ABAC), creating dynamic policies based on teams and topics’ metadata. For example, teams could be granted read and write access to all of their own topics by default. Leveraging a versatile component such as the OPA as our authorisation controller enables this evolution.&lt;/p&gt;

&lt;h1 id=&quot;join-us&quot;&gt;Join us&lt;/h1&gt;

&lt;p&gt;Grab is the leading superapp platform in Southeast Asia, providing everyday services that matter to consumers. More than just a ride-hailing and food delivery app, Grab offers a wide range of on-demand services in the region, including mobility, food, package and grocery delivery services, mobile payments, and financial services across 428 cities in eight countries.&lt;/p&gt;

&lt;p&gt;Powered by technology and driven by heart, our mission is to drive Southeast Asia forward by creating economic empowerment for everyone. If this mission speaks to you, &lt;a href=&quot;https://grab.careers/&quot;&gt;join our team&lt;/a&gt; today!&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Dec 2022 00:23:05 +0000</pubDate>
        <link>https://engineering.grab.com/zero-trust-with-kafka</link>
        <guid isPermaLink="true">https://engineering.grab.com/zero-trust-with-kafka</guid>
        
        <category>Engineering</category>
        
        <category>Kafka</category>
        
        <category>Performance</category>
        
        <category>Zero trust</category>
        
        <category>Access control</category>
        
        
        <category>Engineering</category>
        
        <category>Security</category>
        
      </item>
    
  </channel>
</rss>
